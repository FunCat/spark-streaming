"C:\Program Files\Java\jdk1.8.0_171\bin\java.exe" "-javaagent:C:\Program Files\JetBrains\IntelliJ IDEA Community Edition 2018.1.4\lib\idea_rt.jar=61004:C:\Program Files\JetBrains\IntelliJ IDEA Community Edition 2018.1.4\bin" -Dfile.encoding=UTF-8 -classpath "C:\Program Files\Java\jdk1.8.0_171\jre\lib\charsets.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\deploy.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\access-bridge-64.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\cldrdata.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\dnsns.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\jaccess.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\jfxrt.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\localedata.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\nashorn.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunec.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunjce_provider.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunmscapi.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunpkcs11.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\zipfs.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\javaws.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jce.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jfr.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jfxswt.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jsse.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\management-agent.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\plugin.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\resources.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\rt.jar;C:\Users\serez\Desktop\bigdata-training-master-cb197815c41507f3ead62de529732ac73879a99a\dev\homeworks\spark-streaming\homework2\target\classes;C:\Users\serez\.m2\repository\org\numenta\htm.java\0.6.13\htm.java-0.6.13.jar;C:\Users\serez\.m2\repository\joda-time\joda-time\2.5\joda-time-2.5.jar;C:\Users\serez\.m2\repository\com\chaschev\chutils\1.4\chutils-1.4.jar;C:\Users\serez\.m2\repository\net\sf\trove4j\trove4j\3.0.3\trove4j-3.0.3.jar;C:\Users\serez\.m2\repository\org\slf4j\slf4j-api\1.7.10\slf4j-api-1.7.10.jar;C:\Users\serez\.m2\repository\io\reactivex\rxjava\1.0.10\rxjava-1.0.10.jar;C:\Users\serez\.m2\repository\com\cedarsoftware\java-util\1.19.3\java-util-1.19.3.jar;C:\Users\serez\.m2\repository\org\apache\logging\log4j\log4j-api\2.1\log4j-api-2.1.jar;C:\Users\serez\.m2\repository\org\apache\logging\log4j\log4j-core\2.1\log4j-core-2.1.jar;C:\Users\serez\.m2\repository\de\ruedigermoeller\fst\2.45\fst-2.45.jar;C:\Users\serez\.m2\repository\org\javassist\javassist\3.19.0-GA\javassist-3.19.0-GA.jar;C:\Users\serez\.m2\repository\org\objenesis\objenesis\2.1\objenesis-2.1.jar;C:\Users\serez\.m2\repository\org\openjdk\jmh\jmh-core\1.11.3\jmh-core-1.11.3.jar;C:\Users\serez\.m2\repository\net\sf\jopt-simple\jopt-simple\4.6\jopt-simple-4.6.jar;C:\Users\serez\.m2\repository\algorithmfoundry\algorithmfoundry-shade-culled\1.3\algorithmfoundry-shade-culled-1.3.jar;C:\Users\serez\.m2\repository\com\opencsv\opencsv\3.10\opencsv-3.10.jar;C:\Users\serez\.m2\repository\org\apache\commons\commons-lang3\3.5\commons-lang3-3.5.jar;C:\Users\serez\.m2\repository\commons-beanutils\commons-beanutils\1.9.3\commons-beanutils-1.9.3.jar;C:\Users\serez\.m2\repository\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;C:\Users\serez\.m2\repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;C:\Users\serez\.m2\repository\org\apache\spark\spark-core_2.11\2.3.0\spark-core_2.11-2.3.0.jar;C:\Users\serez\.m2\repository\org\apache\avro\avro\1.7.7\avro-1.7.7.jar;C:\Users\serez\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;C:\Users\serez\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;C:\Users\serez\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\serez\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\serez\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\serez\.m2\repository\org\apache\avro\avro-mapred\1.7.7\avro-mapred-1.7.7-hadoop2.jar;C:\Users\serez\.m2\repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7.jar;C:\Users\serez\.m2\repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7-tests.jar;C:\Users\serez\.m2\repository\com\twitter\chill_2.11\0.8.4\chill_2.11-0.8.4.jar;C:\Users\serez\.m2\repository\com\esotericsoftware\kryo-shaded\3.0.3\kryo-shaded-3.0.3.jar;C:\Users\serez\.m2\repository\com\esotericsoftware\minlog\1.3.0\minlog-1.3.0.jar;C:\Users\serez\.m2\repository\com\twitter\chill-java\0.8.4\chill-java-0.8.4.jar;C:\Users\serez\.m2\repository\org\apache\xbean\xbean-asm5-shaded\4.4\xbean-asm5-shaded-4.4.jar;C:\Users\serez\.m2\repository\org\apache\hadoop\hadoop-client\2.6.5\hadoop-client-2.6.5.jar;C:\Users\serez\.m2\repository\org\apache\hadoop\hadoop-common\2.6.5\hadoop-common-2.6.5.jar;C:\Users\serez\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\serez\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\serez\.m2\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;C:\Users\serez\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\serez\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\serez\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\serez\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\serez\.m2\repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;C:\Users\serez\.m2\repository\org\apache\hadoop\hadoop-auth\2.6.5\hadoop-auth-2.6.5.jar;C:\Users\serez\.m2\repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;C:\Users\serez\.m2\repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;C:\Users\serez\.m2\repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;C:\Users\serez\.m2\repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;C:\Users\serez\.m2\repository\org\apache\curator\curator-client\2.6.0\curator-client-2.6.0.jar;C:\Users\serez\.m2\repository\org\htrace\htrace-core\3.0.4\htrace-core-3.0.4.jar;C:\Users\serez\.m2\repository\org\apache\hadoop\hadoop-hdfs\2.6.5\hadoop-hdfs-2.6.5.jar;C:\Users\serez\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\serez\.m2\repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;C:\Users\serez\.m2\repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;C:\Users\serez\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.6.5\hadoop-mapreduce-client-app-2.6.5.jar;C:\Users\serez\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.6.5\hadoop-mapreduce-client-common-2.6.5.jar;C:\Users\serez\.m2\repository\org\apache\hadoop\hadoop-yarn-client\2.6.5\hadoop-yarn-client-2.6.5.jar;C:\Users\serez\.m2\repository\org\apache\hadoop\hadoop-yarn-server-common\2.6.5\hadoop-yarn-server-common-2.6.5.jar;C:\Users\serez\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.6.5\hadoop-mapreduce-client-shuffle-2.6.5.jar;C:\Users\serez\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.6.5\hadoop-yarn-api-2.6.5.jar;C:\Users\serez\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.6.5\hadoop-mapreduce-client-core-2.6.5.jar;C:\Users\serez\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.6.5\hadoop-yarn-common-2.6.5.jar;C:\Users\serez\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\serez\.m2\repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;C:\Users\serez\.m2\repository\org\codehaus\jackson\jackson-jaxrs\1.9.13\jackson-jaxrs-1.9.13.jar;C:\Users\serez\.m2\repository\org\codehaus\jackson\jackson-xc\1.9.13\jackson-xc-1.9.13.jar;C:\Users\serez\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.6.5\hadoop-mapreduce-client-jobclient-2.6.5.jar;C:\Users\serez\.m2\repository\org\apache\hadoop\hadoop-annotations\2.6.5\hadoop-annotations-2.6.5.jar;C:\Users\serez\.m2\repository\org\apache\spark\spark-launcher_2.11\2.3.0\spark-launcher_2.11-2.3.0.jar;C:\Users\serez\.m2\repository\org\apache\spark\spark-kvstore_2.11\2.3.0\spark-kvstore_2.11-2.3.0.jar;C:\Users\serez\.m2\repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;C:\Users\serez\.m2\repository\org\apache\spark\spark-network-common_2.11\2.3.0\spark-network-common_2.11-2.3.0.jar;C:\Users\serez\.m2\repository\org\apache\spark\spark-network-shuffle_2.11\2.3.0\spark-network-shuffle_2.11-2.3.0.jar;C:\Users\serez\.m2\repository\org\apache\spark\spark-unsafe_2.11\2.3.0\spark-unsafe_2.11-2.3.0.jar;C:\Users\serez\.m2\repository\net\java\dev\jets3t\jets3t\0.9.4\jets3t-0.9.4.jar;C:\Users\serez\.m2\repository\org\apache\httpcomponents\httpcore\4.4.1\httpcore-4.4.1.jar;C:\Users\serez\.m2\repository\org\apache\httpcomponents\httpclient\4.5\httpclient-4.5.jar;C:\Users\serez\.m2\repository\commons-codec\commons-codec\1.11\commons-codec-1.11.jar;C:\Users\serez\.m2\repository\javax\activation\activation\1.1.1\activation-1.1.1.jar;C:\Users\serez\.m2\repository\org\bouncycastle\bcprov-jdk15on\1.52\bcprov-jdk15on-1.52.jar;C:\Users\serez\.m2\repository\com\jamesmurty\utils\java-xmlbuilder\1.1\java-xmlbuilder-1.1.jar;C:\Users\serez\.m2\repository\net\iharder\base64\2.3.8\base64-2.3.8.jar;C:\Users\serez\.m2\repository\org\apache\curator\curator-recipes\2.6.0\curator-recipes-2.6.0.jar;C:\Users\serez\.m2\repository\org\apache\curator\curator-framework\2.6.0\curator-framework-2.6.0.jar;C:\Users\serez\.m2\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;C:\Users\serez\.m2\repository\com\google\guava\guava\16.0.1\guava-16.0.1.jar;C:\Users\serez\.m2\repository\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;C:\Users\serez\.m2\repository\org\apache\commons\commons-math3\3.4.1\commons-math3-3.4.1.jar;C:\Users\serez\.m2\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;C:\Users\serez\.m2\repository\org\slf4j\jul-to-slf4j\1.7.16\jul-to-slf4j-1.7.16.jar;C:\Users\serez\.m2\repository\org\slf4j\jcl-over-slf4j\1.7.16\jcl-over-slf4j-1.7.16.jar;C:\Users\serez\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\serez\.m2\repository\org\slf4j\slf4j-log4j12\1.7.16\slf4j-log4j12-1.7.16.jar;C:\Users\serez\.m2\repository\com\ning\compress-lzf\1.0.3\compress-lzf-1.0.3.jar;C:\Users\serez\.m2\repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;C:\Users\serez\.m2\repository\org\lz4\lz4-java\1.4.0\lz4-java-1.4.0.jar;C:\Users\serez\.m2\repository\com\github\luben\zstd-jni\1.3.2-2\zstd-jni-1.3.2-2.jar;C:\Users\serez\.m2\repository\org\roaringbitmap\RoaringBitmap\0.5.11\RoaringBitmap-0.5.11.jar;C:\Users\serez\.m2\repository\commons-net\commons-net\2.2\commons-net-2.2.jar;C:\Users\serez\.m2\repository\org\scala-lang\scala-library\2.11.8\scala-library-2.11.8.jar;C:\Users\serez\.m2\repository\org\json4s\json4s-jackson_2.11\3.2.11\json4s-jackson_2.11-3.2.11.jar;C:\Users\serez\.m2\repository\org\json4s\json4s-core_2.11\3.2.11\json4s-core_2.11-3.2.11.jar;C:\Users\serez\.m2\repository\org\json4s\json4s-ast_2.11\3.2.11\json4s-ast_2.11-3.2.11.jar;C:\Users\serez\.m2\repository\org\scala-lang\scalap\2.11.0\scalap-2.11.0.jar;C:\Users\serez\.m2\repository\org\scala-lang\scala-compiler\2.11.0\scala-compiler-2.11.0.jar;C:\Users\serez\.m2\repository\org\scala-lang\modules\scala-xml_2.11\1.0.1\scala-xml_2.11-1.0.1.jar;C:\Users\serez\.m2\repository\org\glassfish\jersey\core\jersey-client\2.22.2\jersey-client-2.22.2.jar;C:\Users\serez\.m2\repository\javax\ws\rs\javax.ws.rs-api\2.0.1\javax.ws.rs-api-2.0.1.jar;C:\Users\serez\.m2\repository\org\glassfish\hk2\hk2-api\2.4.0-b34\hk2-api-2.4.0-b34.jar;C:\Users\serez\.m2\repository\org\glassfish\hk2\hk2-utils\2.4.0-b34\hk2-utils-2.4.0-b34.jar;C:\Users\serez\.m2\repository\org\glassfish\hk2\external\aopalliance-repackaged\2.4.0-b34\aopalliance-repackaged-2.4.0-b34.jar;C:\Users\serez\.m2\repository\org\glassfish\hk2\external\javax.inject\2.4.0-b34\javax.inject-2.4.0-b34.jar;C:\Users\serez\.m2\repository\org\glassfish\hk2\hk2-locator\2.4.0-b34\hk2-locator-2.4.0-b34.jar;C:\Users\serez\.m2\repository\org\glassfish\jersey\core\jersey-common\2.22.2\jersey-common-2.22.2.jar;C:\Users\serez\.m2\repository\javax\annotation\javax.annotation-api\1.2\javax.annotation-api-1.2.jar;C:\Users\serez\.m2\repository\org\glassfish\jersey\bundles\repackaged\jersey-guava\2.22.2\jersey-guava-2.22.2.jar;C:\Users\serez\.m2\repository\org\glassfish\hk2\osgi-resource-locator\1.0.1\osgi-resource-locator-1.0.1.jar;C:\Users\serez\.m2\repository\org\glassfish\jersey\core\jersey-server\2.22.2\jersey-server-2.22.2.jar;C:\Users\serez\.m2\repository\org\glassfish\jersey\media\jersey-media-jaxb\2.22.2\jersey-media-jaxb-2.22.2.jar;C:\Users\serez\.m2\repository\javax\validation\validation-api\1.1.0.Final\validation-api-1.1.0.Final.jar;C:\Users\serez\.m2\repository\org\glassfish\jersey\containers\jersey-container-servlet\2.22.2\jersey-container-servlet-2.22.2.jar;C:\Users\serez\.m2\repository\org\glassfish\jersey\containers\jersey-container-servlet-core\2.22.2\jersey-container-servlet-core-2.22.2.jar;C:\Users\serez\.m2\repository\io\netty\netty-all\4.1.17.Final\netty-all-4.1.17.Final.jar;C:\Users\serez\.m2\repository\io\netty\netty\3.9.9.Final\netty-3.9.9.Final.jar;C:\Users\serez\.m2\repository\com\clearspring\analytics\stream\2.7.0\stream-2.7.0.jar;C:\Users\serez\.m2\repository\io\dropwizard\metrics\metrics-core\3.1.5\metrics-core-3.1.5.jar;C:\Users\serez\.m2\repository\io\dropwizard\metrics\metrics-jvm\3.1.5\metrics-jvm-3.1.5.jar;C:\Users\serez\.m2\repository\io\dropwizard\metrics\metrics-json\3.1.5\metrics-json-3.1.5.jar;C:\Users\serez\.m2\repository\io\dropwizard\metrics\metrics-graphite\3.1.5\metrics-graphite-3.1.5.jar;C:\Users\serez\.m2\repository\com\fasterxml\jackson\module\jackson-module-scala_2.11\2.6.7.1\jackson-module-scala_2.11-2.6.7.1.jar;C:\Users\serez\.m2\repository\org\scala-lang\scala-reflect\2.11.8\scala-reflect-2.11.8.jar;C:\Users\serez\.m2\repository\com\fasterxml\jackson\module\jackson-module-paranamer\2.7.9\jackson-module-paranamer-2.7.9.jar;C:\Users\serez\.m2\repository\org\apache\ivy\ivy\2.4.0\ivy-2.4.0.jar;C:\Users\serez\.m2\repository\oro\oro\2.0.8\oro-2.0.8.jar;C:\Users\serez\.m2\repository\net\razorvine\pyrolite\4.13\pyrolite-4.13.jar;C:\Users\serez\.m2\repository\net\sf\py4j\py4j\0.10.6\py4j-0.10.6.jar;C:\Users\serez\.m2\repository\org\apache\spark\spark-tags_2.11\2.3.0\spark-tags_2.11-2.3.0.jar;C:\Users\serez\.m2\repository\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;C:\Users\serez\.m2\repository\org\spark-project\spark\unused\1.0.0\unused-1.0.0.jar;C:\Users\serez\.m2\repository\org\apache\spark\spark-sql_2.11\2.3.0\spark-sql_2.11-2.3.0.jar;C:\Users\serez\.m2\repository\com\univocity\univocity-parsers\2.5.9\univocity-parsers-2.5.9.jar;C:\Users\serez\.m2\repository\org\apache\spark\spark-sketch_2.11\2.3.0\spark-sketch_2.11-2.3.0.jar;C:\Users\serez\.m2\repository\org\apache\spark\spark-catalyst_2.11\2.3.0\spark-catalyst_2.11-2.3.0.jar;C:\Users\serez\.m2\repository\org\codehaus\janino\janino\3.0.8\janino-3.0.8.jar;C:\Users\serez\.m2\repository\org\codehaus\janino\commons-compiler\3.0.8\commons-compiler-3.0.8.jar;C:\Users\serez\.m2\repository\org\antlr\antlr4-runtime\4.7\antlr4-runtime-4.7.jar;C:\Users\serez\.m2\repository\org\apache\orc\orc-core\1.4.1\orc-core-1.4.1-nohive.jar;C:\Users\serez\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\serez\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\serez\.m2\repository\io\airlift\aircompressor\0.8\aircompressor-0.8.jar;C:\Users\serez\.m2\repository\org\apache\orc\orc-mapreduce\1.4.1\orc-mapreduce-1.4.1-nohive.jar;C:\Users\serez\.m2\repository\org\apache\parquet\parquet-column\1.8.2\parquet-column-1.8.2.jar;C:\Users\serez\.m2\repository\org\apache\parquet\parquet-common\1.8.2\parquet-common-1.8.2.jar;C:\Users\serez\.m2\repository\org\apache\parquet\parquet-encoding\1.8.2\parquet-encoding-1.8.2.jar;C:\Users\serez\.m2\repository\org\apache\parquet\parquet-hadoop\1.8.2\parquet-hadoop-1.8.2.jar;C:\Users\serez\.m2\repository\org\apache\parquet\parquet-format\2.3.1\parquet-format-2.3.1.jar;C:\Users\serez\.m2\repository\org\apache\parquet\parquet-jackson\1.8.2\parquet-jackson-1.8.2.jar;C:\Users\serez\.m2\repository\org\apache\arrow\arrow-vector\0.8.0\arrow-vector-0.8.0.jar;C:\Users\serez\.m2\repository\org\apache\arrow\arrow-format\0.8.0\arrow-format-0.8.0.jar;C:\Users\serez\.m2\repository\org\apache\arrow\arrow-memory\0.8.0\arrow-memory-0.8.0.jar;C:\Users\serez\.m2\repository\com\carrotsearch\hppc\0.7.2\hppc-0.7.2.jar;C:\Users\serez\.m2\repository\com\vlkan\flatbuffers\1.2.0-3f79e055\flatbuffers-1.2.0-3f79e055.jar;C:\Users\serez\.m2\repository\org\scala-lang\modules\scala-parser-combinators_2.11\1.0.4\scala-parser-combinators_2.11-1.0.4.jar;C:\Users\serez\.m2\repository\org\apache\spark\spark-streaming_2.11\2.3.0\spark-streaming_2.11-2.3.0.jar;C:\Users\serez\.m2\repository\org\apache\spark\spark-streaming-kafka-0-10_2.11\2.3.0\spark-streaming-kafka-0-10_2.11-2.3.0.jar;C:\Users\serez\.m2\repository\org\apache\kafka\kafka-clients\0.10.0.1\kafka-clients-0.10.0.1.jar;C:\Users\serez\.m2\repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;C:\Users\serez\.m2\repository\com\fasterxml\jackson\core\jackson-core\2.6.7\jackson-core-2.6.7.jar;C:\Users\serez\.m2\repository\com\fasterxml\jackson\core\jackson-databind\2.6.7\jackson-databind-2.6.7.jar;C:\Users\serez\.m2\repository\com\fasterxml\jackson\core\jackson-annotations\2.6.7\jackson-annotations-2.6.7.jar" com.epam.bdcc.spark.AnomalyDetector
18/09/28 21:40:08 INFO PropertiesLoader: {enriched.topic=monitoringEnriched2, retries=0, sample.file=./data/one_device_2015-2017.csv, acks=all, app.name=AnomalyDetector, buffer.memory=33554432, enable.auto.commit=true, checkpoint.dir=./checkpoint, batch.size=100, window.duration=600000, skip.header=true, batch.duration=10000, group.id=detector_group, auto.offset.reset=latest, raw.topic=monitoring20, linger.ms=1, bootstrap.servers=localhost:9092, checkpoint.interval=60000, batch.sleep=0}
18/09/28 21:40:08 INFO SparkContext: Running Spark version 2.3.0
18/09/28 21:40:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/09/28 21:40:09 INFO SparkContext: Submitted application: AnomalyDetector
18/09/28 21:40:09 INFO SecurityManager: Changing view acls to: serez
18/09/28 21:40:09 INFO SecurityManager: Changing modify acls to: serez
18/09/28 21:40:09 INFO SecurityManager: Changing view acls groups to: 
18/09/28 21:40:09 INFO SecurityManager: Changing modify acls groups to: 
18/09/28 21:40:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(serez); groups with view permissions: Set(); users  with modify permissions: Set(serez); groups with modify permissions: Set()
18/09/28 21:40:10 INFO Utils: Successfully started service 'sparkDriver' on port 61041.
18/09/28 21:40:10 INFO SparkEnv: Registering MapOutputTracker
18/09/28 21:40:10 INFO SparkEnv: Registering BlockManagerMaster
18/09/28 21:40:10 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/09/28 21:40:10 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/09/28 21:40:10 INFO DiskBlockManager: Created local directory at C:\Users\serez\AppData\Local\Temp\blockmgr-df5b529e-1c3c-440f-bbc8-60e108ee231f
18/09/28 21:40:10 INFO MemoryStore: MemoryStore started with capacity 1994.1 MB
18/09/28 21:40:10 INFO SparkEnv: Registering OutputCommitCoordinator
18/09/28 21:40:10 INFO log: Logging initialized @3098ms
18/09/28 21:40:10 INFO Server: jetty-9.3.z-SNAPSHOT
18/09/28 21:40:10 INFO Server: Started @3166ms
18/09/28 21:40:10 INFO AbstractConnector: Started ServerConnector@37c1939c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
18/09/28 21:40:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/09/28 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@7fd4acee{/jobs,null,AVAILABLE,@Spark}
18/09/28 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@78aea4b9{/jobs/json,null,AVAILABLE,@Spark}
18/09/28 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@2a65bb85{/jobs/job,null,AVAILABLE,@Spark}
18/09/28 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4215838f{/jobs/job/json,null,AVAILABLE,@Spark}
18/09/28 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@452ba1db{/stages,null,AVAILABLE,@Spark}
18/09/28 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@2289aca5{/stages/json,null,AVAILABLE,@Spark}
18/09/28 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@76a36b71{/stages/stage,null,AVAILABLE,@Spark}
18/09/28 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@6ffab045{/stages/stage/json,null,AVAILABLE,@Spark}
18/09/28 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@26fb628{/stages/pool,null,AVAILABLE,@Spark}
18/09/28 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@3e2943ab{/stages/pool/json,null,AVAILABLE,@Spark}
18/09/28 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@70dd7e15{/storage,null,AVAILABLE,@Spark}
18/09/28 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4a9f80d3{/storage/json,null,AVAILABLE,@Spark}
18/09/28 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@35beb15e{/storage/rdd,null,AVAILABLE,@Spark}
18/09/28 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@41fe9859{/storage/rdd/json,null,AVAILABLE,@Spark}
18/09/28 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5ac86ba5{/environment,null,AVAILABLE,@Spark}
18/09/28 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@6c67e137{/environment/json,null,AVAILABLE,@Spark}
18/09/28 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@2c9399a4{/executors,null,AVAILABLE,@Spark}
18/09/28 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@191ae03f{/executors/json,null,AVAILABLE,@Spark}
18/09/28 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@9635fa{/executors/threadDump,null,AVAILABLE,@Spark}
18/09/28 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@53ab0286{/executors/threadDump/json,null,AVAILABLE,@Spark}
18/09/28 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@63c5efee{/static,null,AVAILABLE,@Spark}
18/09/28 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@69c79f09{/,null,AVAILABLE,@Spark}
18/09/28 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1ca25c47{/api,null,AVAILABLE,@Spark}
18/09/28 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@89ff02e{/jobs/job/kill,null,AVAILABLE,@Spark}
18/09/28 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@6865c751{/stages/stage/kill,null,AVAILABLE,@Spark}
18/09/28 21:40:10 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-30M8NBP.mshome.net:4040
18/09/28 21:40:10 INFO Executor: Starting executor ID driver on host localhost
18/09/28 21:40:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61066.
18/09/28 21:40:10 INFO NettyBlockTransferService: Server created on DESKTOP-30M8NBP.mshome.net:61066
18/09/28 21:40:10 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/09/28 21:40:10 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-30M8NBP.mshome.net, 61066, None)
18/09/28 21:40:10 INFO BlockManagerMasterEndpoint: Registering block manager DESKTOP-30M8NBP.mshome.net:61066 with 1994.1 MB RAM, BlockManagerId(driver, DESKTOP-30M8NBP.mshome.net, 61066, None)
18/09/28 21:40:10 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, DESKTOP-30M8NBP.mshome.net, 61066, None)
18/09/28 21:40:10 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, DESKTOP-30M8NBP.mshome.net, 61066, None)
18/09/28 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@710b30ef{/metrics/json,null,AVAILABLE,@Spark}
18/09/28 21:40:11 WARN KafkaUtils: overriding enable.auto.commit to false for executor
18/09/28 21:40:11 WARN KafkaUtils: overriding auto.offset.reset to none for executor
18/09/28 21:40:11 WARN KafkaUtils: overriding executor group.id to spark-executor-detector_group
18/09/28 21:40:11 WARN KafkaUtils: overriding receive.buffer.bytes to 65536 see KAFKA-3135
18/09/28 21:40:11 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Recovered 2 write ahead log files from file:/C:/Users/serez/Desktop/bigdata-training-master-cb197815c41507f3ead62de529732ac73879a99a/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata
18/09/28 21:40:11 INFO MappedDStream: Duration for remembering RDDs set to 200000 ms for org.apache.spark.streaming.dstream.MappedDStream@60acd609
18/09/28 21:40:11 INFO MappedDStream: Duration for remembering RDDs set to 200000 ms for org.apache.spark.streaming.dstream.MappedDStream@3ac8cf9b
18/09/28 21:40:11 INFO DirectKafkaInputDStream: Duration for remembering RDDs set to 200000 ms for org.apache.spark.streaming.kafka010.DirectKafkaInputDStream@73ad4ecc
18/09/28 21:40:11 INFO DirectKafkaInputDStream: Slide time = 10000 ms
18/09/28 21:40:11 INFO DirectKafkaInputDStream: Storage level = Serialized 1x Replicated
18/09/28 21:40:11 INFO DirectKafkaInputDStream: Checkpoint interval = null
18/09/28 21:40:11 INFO DirectKafkaInputDStream: Remember interval = 200000 ms
18/09/28 21:40:11 INFO DirectKafkaInputDStream: Initialized and validated org.apache.spark.streaming.kafka010.DirectKafkaInputDStream@73ad4ecc
18/09/28 21:40:11 INFO MappedDStream: Slide time = 10000 ms
18/09/28 21:40:11 INFO MappedDStream: Storage level = Memory Serialized 1x Replicated
18/09/28 21:40:11 INFO MappedDStream: Checkpoint interval = 60000 ms
18/09/28 21:40:11 INFO MappedDStream: Remember interval = 200000 ms
18/09/28 21:40:11 INFO MappedDStream: Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@3ac8cf9b
18/09/28 21:40:11 INFO MappedDStream: Slide time = 10000 ms
18/09/28 21:40:11 INFO MappedDStream: Storage level = Serialized 1x Replicated
18/09/28 21:40:11 INFO MappedDStream: Checkpoint interval = null
18/09/28 21:40:11 INFO MappedDStream: Remember interval = 200000 ms
18/09/28 21:40:11 INFO MappedDStream: Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@60acd609
18/09/28 21:40:11 INFO InternalMapWithStateDStream: Slide time = 10000 ms
18/09/28 21:40:11 INFO InternalMapWithStateDStream: Storage level = Memory Deserialized 1x Replicated
18/09/28 21:40:11 INFO InternalMapWithStateDStream: Checkpoint interval = 100000 ms
18/09/28 21:40:11 INFO InternalMapWithStateDStream: Remember interval = 200000 ms
18/09/28 21:40:11 INFO InternalMapWithStateDStream: Initialized and validated org.apache.spark.streaming.dstream.InternalMapWithStateDStream@7f572c37
18/09/28 21:40:11 INFO MapWithStateDStreamImpl: Slide time = 10000 ms
18/09/28 21:40:11 INFO MapWithStateDStreamImpl: Storage level = Serialized 1x Replicated
18/09/28 21:40:11 INFO MapWithStateDStreamImpl: Checkpoint interval = null
18/09/28 21:40:11 INFO MapWithStateDStreamImpl: Remember interval = 10000 ms
18/09/28 21:40:11 INFO MapWithStateDStreamImpl: Initialized and validated org.apache.spark.streaming.dstream.MapWithStateDStreamImpl@4dbad37
18/09/28 21:40:11 INFO ForEachDStream: Slide time = 10000 ms
18/09/28 21:40:11 INFO ForEachDStream: Storage level = Serialized 1x Replicated
18/09/28 21:40:11 INFO ForEachDStream: Checkpoint interval = null
18/09/28 21:40:11 INFO ForEachDStream: Remember interval = 10000 ms
18/09/28 21:40:11 INFO ForEachDStream: Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@30501e60
18/09/28 21:40:11 INFO ConsumerConfig: ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	group.id = detector_group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

18/09/28 21:40:11 INFO ConsumerConfig: ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	group.id = detector_group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

18/09/28 21:40:11 INFO AppInfoParser: Kafka version : 0.10.0.1
18/09/28 21:40:11 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/09/28 21:40:13 INFO AbstractCoordinator: Discovered coordinator DESKTOP-30M8NBP.mshome.net:9092 (id: 2147483647 rack: null) for group detector_group.
18/09/28 21:40:13 INFO ConsumerCoordinator: Revoking previously assigned partitions [] for group detector_group
18/09/28 21:40:13 INFO AbstractCoordinator: (Re-)joining group detector_group
18/09/28 21:40:13 INFO AbstractCoordinator: Successfully joined group detector_group with generation 1
18/09/28 21:40:13 INFO ConsumerCoordinator: Setting newly assigned partitions [monitoring20-9, monitoring20-8, monitoring20-3, monitoring20-2, monitoring20-1, monitoring20-0, monitoring20-7, monitoring20-6, monitoring20-5, monitoring20-4] for group detector_group
18/09/28 21:40:13 INFO RecurringTimer: Started timer for JobGenerator at time 1538160020000
18/09/28 21:40:13 INFO JobGenerator: Started JobGenerator at 1538160020000 ms
18/09/28 21:40:13 INFO JobScheduler: Started JobScheduler
18/09/28 21:40:13 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@6601cc93{/streaming,null,AVAILABLE,@Spark}
18/09/28 21:40:13 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@54d901aa{/streaming/json,null,AVAILABLE,@Spark}
18/09/28 21:40:13 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@23f72d88{/streaming/batch,null,AVAILABLE,@Spark}
18/09/28 21:40:13 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4bafe935{/streaming/batch/json,null,AVAILABLE,@Spark}
18/09/28 21:40:13 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@507b79f7{/static/streaming,null,AVAILABLE,@Spark}
18/09/28 21:40:13 INFO StreamingContext: StreamingContext started
18/09/28 21:40:20 INFO InternalMapWithStateDStream: Time 1538160010000 ms is invalid as zeroTime is 1538160010000 ms , slideDuration is 10000 ms and difference is 0 ms
18/09/28 21:40:20 INFO JobScheduler: Added jobs for time 1538160020000 ms
18/09/28 21:40:20 INFO JobGenerator: Checkpointing graph for time 1538160020000 ms
18/09/28 21:40:20 INFO DStreamGraph: Updating checkpoint data for time 1538160020000 ms
18/09/28 21:40:20 INFO JobScheduler: Starting job streaming job 1538160020000 ms.0 from job set of time 1538160020000 ms
18/09/28 21:40:20 INFO DStreamGraph: Updated checkpoint data for time 1538160020000 ms
18/09/28 21:40:20 INFO CheckpointWriter: Submitted checkpoint of time 1538160020000 ms to writer queue
18/09/28 21:40:20 INFO CheckpointWriter: Saving checkpoint for time 1538160020000 ms to file 'file:/C:/Users/serez/Desktop/bigdata-training-master-cb197815c41507f3ead62de529732ac73879a99a/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1538160020000'
18/09/28 21:40:20 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:63
18/09/28 21:40:20 INFO DAGScheduler: Registering RDD 3 (mapWithState at AnomalyDetector.java:61)
18/09/28 21:40:20 INFO DAGScheduler: Registering RDD 0 (mapWithState at AnomalyDetector.java:61)
18/09/28 21:40:20 INFO DAGScheduler: Registering RDD 8 (mapToPair at AnomalyDetector.java:58)
18/09/28 21:40:20 INFO DAGScheduler: Got job 0 (foreachPartition at AnomalyDetector.java:63) with 4 output partitions
18/09/28 21:40:20 INFO DAGScheduler: Final stage: ResultStage 3 (foreachPartition at AnomalyDetector.java:63)
18/09/28 21:40:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0, ShuffleMapStage 1, ShuffleMapStage 2)
18/09/28 21:40:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
18/09/28 21:40:20 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[8] at mapToPair at AnomalyDetector.java:58), which has no missing parents
18/09/28 21:40:20 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.3 KB, free 1994.1 MB)
18/09/28 21:40:20 INFO CheckpointWriter: Deleting file:/C:/Users/serez/Desktop/bigdata-training-master-cb197815c41507f3ead62de529732ac73879a99a/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1538159810000
18/09/28 21:40:20 INFO CheckpointWriter: Checkpoint for time 1538160020000 ms saved to file 'file:/C:/Users/serez/Desktop/bigdata-training-master-cb197815c41507f3ead62de529732ac73879a99a/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1538160020000', took 6153 bytes and 117 ms
18/09/28 21:40:20 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.1 KB, free 1994.1 MB)
18/09/28 21:40:20 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 3.1 KB, free: 1994.1 MB)
18/09/28 21:40:20 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1039
18/09/28 21:40:20 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[8] at mapToPair at AnomalyDetector.java:58) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
18/09/28 21:40:20 INFO TaskSchedulerImpl: Adding task set 2.0 with 10 tasks
18/09/28 21:40:20 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:20 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:20 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:20 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:20 INFO Executor: Running task 0.0 in stage 2.0 (TID 0)
18/09/28 21:40:20 INFO Executor: Running task 2.0 in stage 2.0 (TID 2)
18/09/28 21:40:20 INFO Executor: Running task 3.0 in stage 2.0 (TID 3)
18/09/28 21:40:20 INFO Executor: Running task 1.0 in stage 2.0 (TID 1)
18/09/28 21:40:20 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping monitoring20 6
18/09/28 21:40:20 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping monitoring20 4
18/09/28 21:40:20 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping monitoring20 3
18/09/28 21:40:20 INFO KafkaRDD: Beginning offset 1 is the same as ending offset skipping monitoring20 9
18/09/28 21:40:20 INFO MemoryStore: Block rdd_7_2 stored as bytes in memory (estimated size 4.0 B, free 1994.1 MB)
18/09/28 21:40:20 INFO MemoryStore: Block rdd_7_3 stored as bytes in memory (estimated size 4.0 B, free 1994.1 MB)
18/09/28 21:40:20 INFO MemoryStore: Block rdd_7_0 stored as bytes in memory (estimated size 4.0 B, free 1994.1 MB)
18/09/28 21:40:20 INFO MemoryStore: Block rdd_7_1 stored as bytes in memory (estimated size 4.0 B, free 1994.1 MB)
18/09/28 21:40:20 INFO BlockManagerInfo: Added rdd_7_2 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1994.1 MB)
18/09/28 21:40:20 INFO BlockManagerInfo: Added rdd_7_3 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1994.1 MB)
18/09/28 21:40:20 INFO BlockManagerInfo: Added rdd_7_0 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1994.1 MB)
18/09/28 21:40:20 INFO BlockManagerInfo: Added rdd_7_1 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1994.1 MB)
18/09/28 21:40:20 INFO Executor: Finished task 2.0 in stage 2.0 (TID 2). 826 bytes result sent to driver
18/09/28 21:40:20 INFO Executor: Finished task 3.0 in stage 2.0 (TID 3). 869 bytes result sent to driver
18/09/28 21:40:20 INFO Executor: Finished task 0.0 in stage 2.0 (TID 0). 869 bytes result sent to driver
18/09/28 21:40:20 INFO Executor: Finished task 1.0 in stage 2.0 (TID 1). 869 bytes result sent to driver
18/09/28 21:40:20 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 4, localhost, executor driver, partition 4, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:20 INFO Executor: Running task 4.0 in stage 2.0 (TID 4)
18/09/28 21:40:20 INFO TaskSetManager: Starting task 5.0 in stage 2.0 (TID 5, localhost, executor driver, partition 5, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:20 INFO Executor: Running task 5.0 in stage 2.0 (TID 5)
18/09/28 21:40:20 INFO TaskSetManager: Starting task 6.0 in stage 2.0 (TID 6, localhost, executor driver, partition 6, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:20 INFO Executor: Running task 6.0 in stage 2.0 (TID 6)
18/09/28 21:40:20 INFO TaskSetManager: Starting task 7.0 in stage 2.0 (TID 7, localhost, executor driver, partition 7, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:20 INFO Executor: Running task 7.0 in stage 2.0 (TID 7)
18/09/28 21:40:20 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 2) in 130 ms on localhost (executor driver) (1/10)
18/09/28 21:40:20 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping monitoring20 7
18/09/28 21:40:20 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 0) in 144 ms on localhost (executor driver) (2/10)
18/09/28 21:40:20 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 3) in 133 ms on localhost (executor driver) (3/10)
18/09/28 21:40:20 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping monitoring20 8
18/09/28 21:40:20 INFO MemoryStore: Block rdd_7_5 stored as bytes in memory (estimated size 4.0 B, free 1994.1 MB)
18/09/28 21:40:20 INFO MemoryStore: Block rdd_7_4 stored as bytes in memory (estimated size 4.0 B, free 1994.1 MB)
18/09/28 21:40:20 INFO BlockManagerInfo: Added rdd_7_5 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1994.1 MB)
18/09/28 21:40:20 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping monitoring20 2
18/09/28 21:40:20 INFO MemoryStore: Block rdd_7_7 stored as bytes in memory (estimated size 4.0 B, free 1994.1 MB)
18/09/28 21:40:20 INFO BlockManagerInfo: Added rdd_7_4 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1994.1 MB)
18/09/28 21:40:20 INFO BlockManagerInfo: Added rdd_7_7 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1994.1 MB)
18/09/28 21:40:20 INFO KafkaRDD: Computing topic monitoring20, partition 0 offsets 23202 -> 25983
18/09/28 21:40:20 INFO Executor: Finished task 7.0 in stage 2.0 (TID 7). 740 bytes result sent to driver
18/09/28 21:40:20 INFO TaskSetManager: Starting task 8.0 in stage 2.0 (TID 8, localhost, executor driver, partition 8, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:20 INFO Executor: Running task 8.0 in stage 2.0 (TID 8)
18/09/28 21:40:20 INFO CachedKafkaConsumer: Initializing cache 16 64 0.75
18/09/28 21:40:20 INFO TaskSetManager: Finished task 7.0 in stage 2.0 (TID 7) in 18 ms on localhost (executor driver) (4/10)
18/09/28 21:40:20 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 1) in 146 ms on localhost (executor driver) (5/10)
18/09/28 21:40:20 INFO CachedKafkaConsumer: Cache miss for CacheKey(spark-executor-detector_group,monitoring20,0)
18/09/28 21:40:20 INFO ConsumerConfig: ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	group.id = spark-executor-detector_group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = none

18/09/28 21:40:20 INFO Executor: Finished task 5.0 in stage 2.0 (TID 5). 740 bytes result sent to driver
18/09/28 21:40:20 INFO TaskSetManager: Starting task 9.0 in stage 2.0 (TID 9, localhost, executor driver, partition 9, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:20 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping monitoring20 1
18/09/28 21:40:20 INFO Executor: Running task 9.0 in stage 2.0 (TID 9)
18/09/28 21:40:20 INFO TaskSetManager: Finished task 5.0 in stage 2.0 (TID 5) in 28 ms on localhost (executor driver) (6/10)
18/09/28 21:40:20 INFO Executor: Finished task 4.0 in stage 2.0 (TID 4). 697 bytes result sent to driver
18/09/28 21:40:20 INFO MemoryStore: Block rdd_7_8 stored as bytes in memory (estimated size 4.0 B, free 1994.1 MB)
18/09/28 21:40:20 INFO BlockManagerInfo: Added rdd_7_8 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1994.1 MB)
18/09/28 21:40:20 INFO ConsumerConfig: ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	group.id = spark-executor-detector_group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = none

18/09/28 21:40:20 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 4) in 34 ms on localhost (executor driver) (7/10)
18/09/28 21:40:20 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping monitoring20 5
18/09/28 21:40:20 INFO AppInfoParser: Kafka version : 0.10.0.1
18/09/28 21:40:20 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/09/28 21:40:20 INFO MemoryStore: Block rdd_7_9 stored as bytes in memory (estimated size 4.0 B, free 1994.1 MB)
18/09/28 21:40:20 INFO BlockManagerInfo: Added rdd_7_9 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1994.1 MB)
18/09/28 21:40:20 INFO Executor: Finished task 8.0 in stage 2.0 (TID 8). 740 bytes result sent to driver
18/09/28 21:40:20 INFO TaskSetManager: Finished task 8.0 in stage 2.0 (TID 8) in 18 ms on localhost (executor driver) (8/10)
18/09/28 21:40:20 INFO CachedKafkaConsumer: Initial fetch for spark-executor-detector_group monitoring20 0 23202
18/09/28 21:40:20 INFO Executor: Finished task 9.0 in stage 2.0 (TID 9). 740 bytes result sent to driver
18/09/28 21:40:20 INFO TaskSetManager: Finished task 9.0 in stage 2.0 (TID 9) in 15 ms on localhost (executor driver) (9/10)
18/09/28 21:40:20 INFO AbstractCoordinator: Discovered coordinator DESKTOP-30M8NBP.mshome.net:9092 (id: 2147483647 rack: null) for group spark-executor-detector_group.
18/09/28 21:40:20 INFO MemoryStore: Block rdd_7_6 stored as bytes in memory (estimated size 742.3 KB, free 1993.4 MB)
18/09/28 21:40:20 INFO BlockManagerInfo: Added rdd_7_6 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 742.3 KB, free: 1993.4 MB)
18/09/28 21:40:21 INFO Executor: Finished task 6.0 in stage 2.0 (TID 6). 869 bytes result sent to driver
18/09/28 21:40:21 INFO TaskSetManager: Finished task 6.0 in stage 2.0 (TID 6) in 560 ms on localhost (executor driver) (10/10)
18/09/28 21:40:21 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/09/28 21:40:21 INFO DAGScheduler: ShuffleMapStage 2 (mapToPair at AnomalyDetector.java:58) finished in 0,800 s
18/09/28 21:40:21 INFO DAGScheduler: looking for newly runnable stages
18/09/28 21:40:21 INFO DAGScheduler: running: Set()
18/09/28 21:40:21 INFO DAGScheduler: waiting: Set(ResultStage 3)
18/09/28 21:40:21 INFO DAGScheduler: failed: Set()
18/09/28 21:40:21 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[11] at mapWithState at AnomalyDetector.java:61), which has no missing parents
18/09/28 21:40:21 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.0 KB, free 1993.4 MB)
18/09/28 21:40:21 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.1 KB, free 1993.4 MB)
18/09/28 21:40:21 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 3.1 KB, free: 1993.4 MB)
18/09/28 21:40:21 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1039
18/09/28 21:40:21 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at mapWithState at AnomalyDetector.java:61) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/09/28 21:40:21 INFO TaskSchedulerImpl: Adding task set 3.0 with 4 tasks
18/09/28 21:40:21 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 7843 bytes)
18/09/28 21:40:21 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 11, localhost, executor driver, partition 1, PROCESS_LOCAL, 7843 bytes)
18/09/28 21:40:21 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 12, localhost, executor driver, partition 3, PROCESS_LOCAL, 7843 bytes)
18/09/28 21:40:21 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 13, localhost, executor driver, partition 2, ANY, 7843 bytes)
18/09/28 21:40:21 INFO Executor: Running task 0.0 in stage 3.0 (TID 10)
18/09/28 21:40:21 INFO Executor: Running task 1.0 in stage 3.0 (TID 11)
18/09/28 21:40:21 INFO Executor: Running task 2.0 in stage 3.0 (TID 13)
18/09/28 21:40:21 INFO Executor: Running task 3.0 in stage 3.0 (TID 12)
18/09/28 21:40:21 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 0 blocks
18/09/28 21:40:21 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 0 blocks
18/09/28 21:40:21 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 0 blocks
18/09/28 21:40:21 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 0 blocks
18/09/28 21:40:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
18/09/28 21:40:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
18/09/28 21:40:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
18/09/28 21:40:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
18/09/28 21:40:21 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 0 blocks
18/09/28 21:40:21 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 0 blocks
18/09/28 21:40:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/09/28 21:40:21 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 0 blocks
18/09/28 21:40:21 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 0 blocks
18/09/28 21:40:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/09/28 21:40:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/09/28 21:40:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/09/28 21:40:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 10 blocks
18/09/28 21:40:21 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 10 blocks
18/09/28 21:40:21 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 10 blocks
18/09/28 21:40:21 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 10 blocks
18/09/28 21:40:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/09/28 21:40:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
18/09/28 21:40:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/09/28 21:40:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/09/28 21:40:21 INFO MemoryStore: Block rdd_10_0 stored as values in memory (estimated size 2.5 KB, free 1993.4 MB)
18/09/28 21:40:21 INFO MemoryStore: Block rdd_10_3 stored as values in memory (estimated size 2.5 KB, free 1993.4 MB)
18/09/28 21:40:21 INFO MemoryStore: Block rdd_10_1 stored as values in memory (estimated size 2.5 KB, free 1993.4 MB)
18/09/28 21:40:21 INFO BlockManagerInfo: Added rdd_10_0 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 2.5 KB, free: 1993.4 MB)
18/09/28 21:40:21 INFO BlockManagerInfo: Added rdd_10_3 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 2.5 KB, free: 1993.4 MB)
18/09/28 21:40:21 INFO BlockManagerInfo: Added rdd_10_1 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 2.5 KB, free: 1993.4 MB)
18/09/28 21:40:21 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/09/28 21:40:21 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/09/28 21:40:21 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/09/28 21:40:21 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-2
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/09/28 21:40:21 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-3
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/09/28 21:40:21 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/09/28 21:40:21 INFO AppInfoParser: Kafka version : 0.10.0.1
18/09/28 21:40:21 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/09/28 21:40:21 INFO AppInfoParser: Kafka version : 0.10.0.1
18/09/28 21:40:21 INFO AppInfoParser: Kafka version : 0.10.0.1
18/09/28 21:40:21 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/09/28 21:40:21 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/09/28 21:40:21 INFO KafkaProducer: Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/09/28 21:40:21 INFO KafkaProducer: Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/09/28 21:40:21 INFO KafkaProducer: Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/09/28 21:40:21 INFO Executor: Finished task 0.0 in stage 3.0 (TID 10). 1009 bytes result sent to driver
18/09/28 21:40:21 INFO Executor: Finished task 3.0 in stage 3.0 (TID 12). 1009 bytes result sent to driver
18/09/28 21:40:21 INFO Executor: Finished task 1.0 in stage 3.0 (TID 11). 1009 bytes result sent to driver
18/09/28 21:40:21 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 12) in 85 ms on localhost (executor driver) (1/4)
18/09/28 21:40:21 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 10) in 88 ms on localhost (executor driver) (2/4)
18/09/28 21:40:21 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 11) in 86 ms on localhost (executor driver) (3/4)
18/09/28 21:40:21 WARN Layer: The number of Input Dimensions (1) != number of Column Dimensions (1) --OR-- Encoder width (275) != product of dimensions (500) -- now attempting to fix it.
18/09/28 21:40:21 INFO Layer: Input dimension fix successful!
18/09/28 21:40:21 INFO Layer: Using calculated input dimensions: [275]
18/09/28 21:40:21 INFO Layer: Not classifying "DT" input field
18/09/28 21:40:21 INFO Layer: Classifying "Measurement" input field with SDRClassifier
18/09/28 21:40:21 INFO BlockManagerInfo: Removed broadcast_0_piece0 on DESKTOP-30M8NBP.mshome.net:61066 in memory (size: 3.1 KB, free: 1993.4 MB)
18/09/28 21:40:30 INFO JobScheduler: Added jobs for time 1538160030000 ms
18/09/28 21:40:30 INFO JobGenerator: Checkpointing graph for time 1538160030000 ms
18/09/28 21:40:30 INFO DStreamGraph: Updating checkpoint data for time 1538160030000 ms
18/09/28 21:40:30 INFO DStreamGraph: Updated checkpoint data for time 1538160030000 ms
18/09/28 21:40:30 INFO CheckpointWriter: Submitted checkpoint of time 1538160030000 ms to writer queue
18/09/28 21:40:30 INFO CheckpointWriter: Saving checkpoint for time 1538160030000 ms to file 'file:/C:/Users/serez/Desktop/bigdata-training-master-cb197815c41507f3ead62de529732ac73879a99a/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1538160030000'
18/09/28 21:40:30 INFO CheckpointWriter: Deleting file:/C:/Users/serez/Desktop/bigdata-training-master-cb197815c41507f3ead62de529732ac73879a99a/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1538159820000
18/09/28 21:40:30 INFO CheckpointWriter: Checkpoint for time 1538160030000 ms saved to file 'file:/C:/Users/serez/Desktop/bigdata-training-master-cb197815c41507f3ead62de529732ac73879a99a/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1538160030000', took 6250 bytes and 109 ms
18/09/28 21:40:33 INFO MemoryStore: Block rdd_10_2 stored as values in memory (estimated size 244.0 MB, free 1749.3 MB)
18/09/28 21:40:33 INFO BlockManagerInfo: Added rdd_10_2 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 244.0 MB, free: 1749.3 MB)
18/09/28 21:40:33 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/09/28 21:40:33 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-4
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/09/28 21:40:33 INFO AppInfoParser: Kafka version : 0.10.0.1
18/09/28 21:40:33 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
monitoringEnriched2-0@0
monitoringEnriched2-0@1
monitoringEnriched2-0@2
monitoringEnriched2-0@3
monitoringEnriched2-0@4
monitoringEnriched2-0@5
monitoringEnriched2-0@6
monitoringEnriched2-0@7
monitoringEnriched2-0@8
monitoringEnriched2-0@9
monitoringEnriched2-0@10
monitoringEnriched2-0@11
monitoringEnriched2-0@12
monitoringEnriched2-0@13
monitoringEnriched2-0@14
monitoringEnriched2-0@15
monitoringEnriched2-0@16
monitoringEnriched2-0@17
monitoringEnriched2-0@18
monitoringEnriched2-0@19
monitoringEnriched2-0@20
monitoringEnriched2-0@21
monitoringEnriched2-0@22
monitoringEnriched2-0@23
monitoringEnriched2-0@24
monitoringEnriched2-0@25
monitoringEnriched2-0@26
monitoringEnriched2-0@27
monitoringEnriched2-0@28
monitoringEnriched2-0@29
monitoringEnriched2-0@30
monitoringEnriched2-0@31
monitoringEnriched2-0@32
monitoringEnriched2-0@33
monitoringEnriched2-0@34
monitoringEnriched2-0@35
monitoringEnriched2-0@36
monitoringEnriched2-0@37
monitoringEnriched2-0@38
monitoringEnriched2-0@39
monitoringEnriched2-0@40
monitoringEnriched2-0@41
monitoringEnriched2-0@42
monitoringEnriched2-0@43
monitoringEnriched2-0@44
monitoringEnriched2-0@45
monitoringEnriched2-0@46
monitoringEnriched2-0@47
monitoringEnriched2-0@48
monitoringEnriched2-0@49
monitoringEnriched2-0@50
monitoringEnriched2-0@51
monitoringEnriched2-0@52
monitoringEnriched2-0@53
monitoringEnriched2-0@54
monitoringEnriched2-0@55
monitoringEnriched2-0@56
monitoringEnriched2-0@57
monitoringEnriched2-0@58
monitoringEnriched2-0@59
monitoringEnriched2-0@60
monitoringEnriched2-0@61
monitoringEnriched2-0@62
monitoringEnriched2-0@63
monitoringEnriched2-0@64
monitoringEnriched2-0@65
monitoringEnriched2-0@66
monitoringEnriched2-0@67
monitoringEnriched2-0@68
monitoringEnriched2-0@69
monitoringEnriched2-0@70
monitoringEnriched2-0@71
monitoringEnriched2-0@72
monitoringEnriched2-0@73
monitoringEnriched2-0@74
monitoringEnriched2-0@75
monitoringEnriched2-0@76
monitoringEnriched2-0@77
monitoringEnriched2-0@78
monitoringEnriched2-0@79
monitoringEnriched2-0@80
monitoringEnriched2-0@81
monitoringEnriched2-0@82
monitoringEnriched2-0@83
monitoringEnriched2-0@84
monitoringEnriched2-0@85
monitoringEnriched2-0@86
monitoringEnriched2-0@87
monitoringEnriched2-0@88
monitoringEnriched2-0@89
monitoringEnriched2-0@90
monitoringEnriched2-0@91
monitoringEnriched2-0@92
monitoringEnriched2-0@93
monitoringEnriched2-0@94
monitoringEnriched2-0@95
monitoringEnriched2-0@96
monitoringEnriched2-0@97
monitoringEnriched2-0@98
monitoringEnriched2-0@99
monitoringEnriched2-0@100
monitoringEnriched2-0@101
monitoringEnriched2-0@102
monitoringEnriched2-0@103
monitoringEnriched2-0@104
monitoringEnriched2-0@105
monitoringEnriched2-0@106
monitoringEnriched2-0@107
monitoringEnriched2-0@108
monitoringEnriched2-0@109
monitoringEnriched2-0@110
monitoringEnriched2-0@111
monitoringEnriched2-0@112
monitoringEnriched2-0@113
monitoringEnriched2-0@114
monitoringEnriched2-0@115
monitoringEnriched2-0@116
monitoringEnriched2-0@117
monitoringEnriched2-0@118
monitoringEnriched2-0@119
monitoringEnriched2-0@120
monitoringEnriched2-0@121
monitoringEnriched2-0@122
monitoringEnriched2-0@123
monitoringEnriched2-0@124
monitoringEnriched2-0@125
monitoringEnriched2-0@126
monitoringEnriched2-0@127
monitoringEnriched2-0@128
monitoringEnriched2-0@129
monitoringEnriched2-0@130
monitoringEnriched2-0@131
monitoringEnriched2-0@132
monitoringEnriched2-0@133
monitoringEnriched2-0@134
monitoringEnriched2-0@135
monitoringEnriched2-0@136
monitoringEnriched2-0@137
monitoringEnriched2-0@138
monitoringEnriched2-0@139
monitoringEnriched2-0@140
monitoringEnriched2-0@141
monitoringEnriched2-0@142
monitoringEnriched2-0@143
monitoringEnriched2-0@144
monitoringEnriched2-0@145
monitoringEnriched2-0@146
monitoringEnriched2-0@147
monitoringEnriched2-0@148
monitoringEnriched2-0@149
monitoringEnriched2-0@150
monitoringEnriched2-0@151
monitoringEnriched2-0@152
monitoringEnriched2-0@153
monitoringEnriched2-0@154
monitoringEnriched2-0@155
monitoringEnriched2-0@156
monitoringEnriched2-0@157
monitoringEnriched2-0@158
monitoringEnriched2-0@159
monitoringEnriched2-0@160
monitoringEnriched2-0@161
monitoringEnriched2-0@162
monitoringEnriched2-0@163
monitoringEnriched2-0@164
monitoringEnriched2-0@165
monitoringEnriched2-0@166
monitoringEnriched2-0@167
monitoringEnriched2-0@168
monitoringEnriched2-0@169
monitoringEnriched2-0@170
monitoringEnriched2-0@171
monitoringEnriched2-0@172
monitoringEnriched2-0@173
monitoringEnriched2-0@174
monitoringEnriched2-0@175
monitoringEnriched2-0@176
monitoringEnriched2-0@177
monitoringEnriched2-0@178
monitoringEnriched2-0@179
monitoringEnriched2-0@180
monitoringEnriched2-0@181
monitoringEnriched2-0@182
monitoringEnriched2-0@183
monitoringEnriched2-0@184
monitoringEnriched2-0@185
monitoringEnriched2-0@186
monitoringEnriched2-0@187
monitoringEnriched2-0@188
monitoringEnriched2-0@189
monitoringEnriched2-0@190
monitoringEnriched2-0@191
monitoringEnriched2-0@192
monitoringEnriched2-0@193
monitoringEnriched2-0@194
monitoringEnriched2-0@195
monitoringEnriched2-0@196
monitoringEnriched2-0@197
monitoringEnriched2-0@198
monitoringEnriched2-0@199
monitoringEnriched2-0@200
monitoringEnriched2-0@201
monitoringEnriched2-0@202
monitoringEnriched2-0@203
monitoringEnriched2-0@204
monitoringEnriched2-0@205
monitoringEnriched2-0@206
monitoringEnriched2-0@207
monitoringEnriched2-0@208
monitoringEnriched2-0@209
monitoringEnriched2-0@210
monitoringEnriched2-0@211
monitoringEnriched2-0@212
monitoringEnriched2-0@213
monitoringEnriched2-0@214
monitoringEnriched2-0@215
monitoringEnriched2-0@216
monitoringEnriched2-0@217
monitoringEnriched2-0@218
monitoringEnriched2-0@219
monitoringEnriched2-0@220
monitoringEnriched2-0@221
monitoringEnriched2-0@222
monitoringEnriched2-0@223
monitoringEnriched2-0@224
monitoringEnriched2-0@225
monitoringEnriched2-0@226
monitoringEnriched2-0@227
monitoringEnriched2-0@228
monitoringEnriched2-0@229
monitoringEnriched2-0@230
monitoringEnriched2-0@231
monitoringEnriched2-0@232
monitoringEnriched2-0@233
monitoringEnriched2-0@234
monitoringEnriched2-0@235
monitoringEnriched2-0@236
monitoringEnriched2-0@237
monitoringEnriched2-0@238
monitoringEnriched2-0@239
monitoringEnriched2-0@240
monitoringEnriched2-0@241
monitoringEnriched2-0@242
monitoringEnriched2-0@243
monitoringEnriched2-0@244
monitoringEnriched2-0@245
monitoringEnriched2-0@246
monitoringEnriched2-0@247
monitoringEnriched2-0@248
monitoringEnriched2-0@249
monitoringEnriched2-0@250
monitoringEnriched2-0@251
monitoringEnriched2-0@252
monitoringEnriched2-0@253
monitoringEnriched2-0@254
monitoringEnriched2-0@255
monitoringEnriched2-0@256
monitoringEnriched2-0@257
monitoringEnriched2-0@258
monitoringEnriched2-0@259
monitoringEnriched2-0@260
monitoringEnriched2-0@261
monitoringEnriched2-0@262
monitoringEnriched2-0@263
monitoringEnriched2-0@264
monitoringEnriched2-0@265
monitoringEnriched2-0@266
monitoringEnriched2-0@267
monitoringEnriched2-0@268
monitoringEnriched2-0@269
monitoringEnriched2-0@270
monitoringEnriched2-0@271
monitoringEnriched2-0@272
monitoringEnriched2-0@273
monitoringEnriched2-0@274
monitoringEnriched2-0@275
monitoringEnriched2-0@276
monitoringEnriched2-0@277
monitoringEnriched2-0@278
monitoringEnriched2-0@279
monitoringEnriched2-0@280
monitoringEnriched2-0@281
monitoringEnriched2-0@282
monitoringEnriched2-0@283
monitoringEnriched2-0@284
monitoringEnriched2-0@285
monitoringEnriched2-0@286
monitoringEnriched2-0@287
monitoringEnriched2-0@288
monitoringEnriched2-0@289
monitoringEnriched2-0@290
monitoringEnriched2-0@291
monitoringEnriched2-0@292
monitoringEnriched2-0@293
monitoringEnriched2-0@294
monitoringEnriched2-0@295
monitoringEnriched2-0@296
monitoringEnriched2-0@297
monitoringEnriched2-0@298
monitoringEnriched2-0@299
monitoringEnriched2-0@300
monitoringEnriched2-0@301
monitoringEnriched2-0@302
monitoringEnriched2-0@303
monitoringEnriched2-0@304
monitoringEnriched2-0@305
monitoringEnriched2-0@306
monitoringEnriched2-0@307
monitoringEnriched2-0@308
monitoringEnriched2-0@309
monitoringEnriched2-0@310
monitoringEnriched2-0@311
monitoringEnriched2-0@312
monitoringEnriched2-0@313
monitoringEnriched2-0@314
monitoringEnriched2-0@315
monitoringEnriched2-0@316
monitoringEnriched2-0@317
monitoringEnriched2-0@318
monitoringEnriched2-0@319
monitoringEnriched2-0@320
monitoringEnriched2-0@321
monitoringEnriched2-0@322
monitoringEnriched2-0@323
monitoringEnriched2-0@324
monitoringEnriched2-0@325
monitoringEnriched2-0@326
monitoringEnriched2-0@327
monitoringEnriched2-0@328
monitoringEnriched2-0@329
monitoringEnriched2-0@330
monitoringEnriched2-0@331
monitoringEnriched2-0@332
monitoringEnriched2-0@333
monitoringEnriched2-0@334
monitoringEnriched2-0@335
monitoringEnriched2-0@336
monitoringEnriched2-0@337
monitoringEnriched2-0@338
monitoringEnriched2-0@339
monitoringEnriched2-0@340
monitoringEnriched2-0@341
monitoringEnriched2-0@342
monitoringEnriched2-0@343
monitoringEnriched2-0@344
monitoringEnriched2-0@345
monitoringEnriched2-0@346
monitoringEnriched2-0@347
monitoringEnriched2-0@348
monitoringEnriched2-0@349
monitoringEnriched2-0@350
monitoringEnriched2-0@351
monitoringEnriched2-0@352
monitoringEnriched2-0@353
monitoringEnriched2-0@354
monitoringEnriched2-0@355
monitoringEnriched2-0@356
monitoringEnriched2-0@357
monitoringEnriched2-0@358
monitoringEnriched2-0@359
monitoringEnriched2-0@360
monitoringEnriched2-0@361
monitoringEnriched2-0@362
monitoringEnriched2-0@363
monitoringEnriched2-0@364
monitoringEnriched2-0@365
monitoringEnriched2-0@366
monitoringEnriched2-0@367
monitoringEnriched2-0@368
monitoringEnriched2-0@369
monitoringEnriched2-0@370
monitoringEnriched2-0@371
monitoringEnriched2-0@372
monitoringEnriched2-0@373
monitoringEnriched2-0@374
monitoringEnriched2-0@375
monitoringEnriched2-0@376
monitoringEnriched2-0@377
monitoringEnriched2-0@378
monitoringEnriched2-0@379
monitoringEnriched2-0@380
monitoringEnriched2-0@381
monitoringEnriched2-0@382
monitoringEnriched2-0@383
monitoringEnriched2-0@384
monitoringEnriched2-0@385
monitoringEnriched2-0@386
monitoringEnriched2-0@387
monitoringEnriched2-0@388
monitoringEnriched2-0@389
monitoringEnriched2-0@390
monitoringEnriched2-0@391
monitoringEnriched2-0@392
monitoringEnriched2-0@393
monitoringEnriched2-0@394
monitoringEnriched2-0@395
monitoringEnriched2-0@396
monitoringEnriched2-0@397
monitoringEnriched2-0@398
monitoringEnriched2-0@399
monitoringEnriched2-0@400
monitoringEnriched2-0@401
monitoringEnriched2-0@402
monitoringEnriched2-0@403
monitoringEnriched2-0@404
monitoringEnriched2-0@405
monitoringEnriched2-0@406
monitoringEnriched2-0@407
monitoringEnriched2-0@408
monitoringEnriched2-0@409
monitoringEnriched2-0@410
monitoringEnriched2-0@411
monitoringEnriched2-0@412
monitoringEnriched2-0@413
monitoringEnriched2-0@414
monitoringEnriched2-0@415
monitoringEnriched2-0@416
monitoringEnriched2-0@417
monitoringEnriched2-0@418
monitoringEnriched2-0@419
monitoringEnriched2-0@420
monitoringEnriched2-0@421
monitoringEnriched2-0@422
monitoringEnriched2-0@423
monitoringEnriched2-0@424
monitoringEnriched2-0@425
monitoringEnriched2-0@426
monitoringEnriched2-0@427
monitoringEnriched2-0@428
monitoringEnriched2-0@429
monitoringEnriched2-0@430
monitoringEnriched2-0@431
monitoringEnriched2-0@432
monitoringEnriched2-0@433
monitoringEnriched2-0@434
monitoringEnriched2-0@435
monitoringEnriched2-0@436
monitoringEnriched2-0@437
monitoringEnriched2-0@438
monitoringEnriched2-0@439
monitoringEnriched2-0@440
monitoringEnriched2-0@441
monitoringEnriched2-0@442
monitoringEnriched2-0@443
monitoringEnriched2-0@444
monitoringEnriched2-0@445
monitoringEnriched2-0@446
monitoringEnriched2-0@447
monitoringEnriched2-0@448
monitoringEnriched2-0@449
monitoringEnriched2-0@450
monitoringEnriched2-0@451
monitoringEnriched2-0@452
monitoringEnriched2-0@453
monitoringEnriched2-0@454
monitoringEnriched2-0@455
monitoringEnriched2-0@456
monitoringEnriched2-0@457
monitoringEnriched2-0@458
monitoringEnriched2-0@459
monitoringEnriched2-0@460
monitoringEnriched2-0@461
monitoringEnriched2-0@462
monitoringEnriched2-0@463
monitoringEnriched2-0@464
monitoringEnriched2-0@465
monitoringEnriched2-0@466
monitoringEnriched2-0@467
monitoringEnriched2-0@468
monitoringEnriched2-0@469
monitoringEnriched2-0@470
monitoringEnriched2-0@471
monitoringEnriched2-0@472
monitoringEnriched2-0@473
monitoringEnriched2-0@474
monitoringEnriched2-0@475
monitoringEnriched2-0@476
monitoringEnriched2-0@477
monitoringEnriched2-0@478
monitoringEnriched2-0@479
monitoringEnriched2-0@480
monitoringEnriched2-0@481
monitoringEnriched2-0@482
monitoringEnriched2-0@483
monitoringEnriched2-0@484
monitoringEnriched2-0@485
monitoringEnriched2-0@486
monitoringEnriched2-0@487
monitoringEnriched2-0@488
monitoringEnriched2-0@489
monitoringEnriched2-0@490
monitoringEnriched2-0@491
monitoringEnriched2-0@492
monitoringEnriched2-0@493
monitoringEnriched2-0@494
monitoringEnriched2-0@495
monitoringEnriched2-0@496
monitoringEnriched2-0@497
monitoringEnriched2-0@498
monitoringEnriched2-0@499
monitoringEnriched2-0@500
monitoringEnriched2-0@501
monitoringEnriched2-0@502
monitoringEnriched2-0@503
monitoringEnriched2-0@504
monitoringEnriched2-0@505
monitoringEnriched2-0@506
monitoringEnriched2-0@507
monitoringEnriched2-0@508
monitoringEnriched2-0@509
monitoringEnriched2-0@510
monitoringEnriched2-0@511
monitoringEnriched2-0@512
monitoringEnriched2-0@513
monitoringEnriched2-0@514
monitoringEnriched2-0@515
monitoringEnriched2-0@516
monitoringEnriched2-0@517
monitoringEnriched2-0@518
monitoringEnriched2-0@519
monitoringEnriched2-0@520
monitoringEnriched2-0@521
monitoringEnriched2-0@522
monitoringEnriched2-0@523
monitoringEnriched2-0@524
monitoringEnriched2-0@525
monitoringEnriched2-0@526
monitoringEnriched2-0@527
monitoringEnriched2-0@528
monitoringEnriched2-0@529
monitoringEnriched2-0@530
monitoringEnriched2-0@531
monitoringEnriched2-0@532
monitoringEnriched2-0@533
monitoringEnriched2-0@534
monitoringEnriched2-0@535
monitoringEnriched2-0@536
monitoringEnriched2-0@537
monitoringEnriched2-0@538
monitoringEnriched2-0@539
monitoringEnriched2-0@540
monitoringEnriched2-0@541
monitoringEnriched2-0@542
monitoringEnriched2-0@543
monitoringEnriched2-0@544
monitoringEnriched2-0@545
monitoringEnriched2-0@546
monitoringEnriched2-0@547
monitoringEnriched2-0@548
monitoringEnriched2-0@549
monitoringEnriched2-0@550
monitoringEnriched2-0@551
monitoringEnriched2-0@552
monitoringEnriched2-0@553
monitoringEnriched2-0@554
monitoringEnriched2-0@555
monitoringEnriched2-0@556
monitoringEnriched2-0@557
monitoringEnriched2-0@558
monitoringEnriched2-0@559
monitoringEnriched2-0@560
monitoringEnriched2-0@561
monitoringEnriched2-0@562
monitoringEnriched2-0@563
monitoringEnriched2-0@564
monitoringEnriched2-0@565
monitoringEnriched2-0@566
monitoringEnriched2-0@567
monitoringEnriched2-0@568
monitoringEnriched2-0@569
monitoringEnriched2-0@570
monitoringEnriched2-0@571
monitoringEnriched2-0@572
monitoringEnriched2-0@573
monitoringEnriched2-0@574
monitoringEnriched2-0@575
monitoringEnriched2-0@576
monitoringEnriched2-0@577
monitoringEnriched2-0@578
monitoringEnriched2-0@579
monitoringEnriched2-0@580
monitoringEnriched2-0@581
monitoringEnriched2-0@582
monitoringEnriched2-0@583
monitoringEnriched2-0@584
monitoringEnriched2-0@585
monitoringEnriched2-0@586
monitoringEnriched2-0@587
monitoringEnriched2-0@588
monitoringEnriched2-0@589
monitoringEnriched2-0@590
monitoringEnriched2-0@591
monitoringEnriched2-0@592
monitoringEnriched2-0@593
monitoringEnriched2-0@594
monitoringEnriched2-0@595
monitoringEnriched2-0@596
monitoringEnriched2-0@597
monitoringEnriched2-0@598
monitoringEnriched2-0@599
monitoringEnriched2-0@600
monitoringEnriched2-0@601
monitoringEnriched2-0@602
monitoringEnriched2-0@603
monitoringEnriched2-0@604
monitoringEnriched2-0@605
monitoringEnriched2-0@606
monitoringEnriched2-0@607
monitoringEnriched2-0@608
monitoringEnriched2-0@609
monitoringEnriched2-0@610
monitoringEnriched2-0@611
monitoringEnriched2-0@612
monitoringEnriched2-0@613
monitoringEnriched2-0@614
monitoringEnriched2-0@615
monitoringEnriched2-0@616
monitoringEnriched2-0@617
monitoringEnriched2-0@618
monitoringEnriched2-0@619
monitoringEnriched2-0@620
monitoringEnriched2-0@621
monitoringEnriched2-0@622
monitoringEnriched2-0@623
monitoringEnriched2-0@624
monitoringEnriched2-0@625
monitoringEnriched2-0@626
monitoringEnriched2-0@627
monitoringEnriched2-0@628
monitoringEnriched2-0@629
monitoringEnriched2-0@630
monitoringEnriched2-0@631
monitoringEnriched2-0@632
monitoringEnriched2-0@633
monitoringEnriched2-0@634
monitoringEnriched2-0@635
monitoringEnriched2-0@636
monitoringEnriched2-0@637
monitoringEnriched2-0@638
monitoringEnriched2-0@639
monitoringEnriched2-0@640
monitoringEnriched2-0@641
monitoringEnriched2-0@642
monitoringEnriched2-0@643
monitoringEnriched2-0@644
monitoringEnriched2-0@645
monitoringEnriched2-0@646
monitoringEnriched2-0@647
monitoringEnriched2-0@648
monitoringEnriched2-0@649
monitoringEnriched2-0@650
monitoringEnriched2-0@651
monitoringEnriched2-0@652
monitoringEnriched2-0@653
monitoringEnriched2-0@654
monitoringEnriched2-0@655
monitoringEnriched2-0@656
monitoringEnriched2-0@657
monitoringEnriched2-0@658
monitoringEnriched2-0@659
monitoringEnriched2-0@660
monitoringEnriched2-0@661
monitoringEnriched2-0@662
monitoringEnriched2-0@663
monitoringEnriched2-0@664
monitoringEnriched2-0@665
monitoringEnriched2-0@666
monitoringEnriched2-0@667
monitoringEnriched2-0@668
monitoringEnriched2-0@669
monitoringEnriched2-0@670
monitoringEnriched2-0@671
monitoringEnriched2-0@672
monitoringEnriched2-0@673
monitoringEnriched2-0@674
monitoringEnriched2-0@675
monitoringEnriched2-0@676
monitoringEnriched2-0@677
monitoringEnriched2-0@678
monitoringEnriched2-0@679
monitoringEnriched2-0@680
monitoringEnriched2-0@681
monitoringEnriched2-0@682
monitoringEnriched2-0@683
monitoringEnriched2-0@684
monitoringEnriched2-0@685
monitoringEnriched2-0@686
monitoringEnriched2-0@687
monitoringEnriched2-0@688
monitoringEnriched2-0@689
monitoringEnriched2-0@690
monitoringEnriched2-0@691
monitoringEnriched2-0@692
monitoringEnriched2-0@693
monitoringEnriched2-0@694
monitoringEnriched2-0@695
monitoringEnriched2-0@696
monitoringEnriched2-0@697
monitoringEnriched2-0@698
monitoringEnriched2-0@699
monitoringEnriched2-0@700
monitoringEnriched2-0@701
monitoringEnriched2-0@702
monitoringEnriched2-0@703
monitoringEnriched2-0@704
monitoringEnriched2-0@705
monitoringEnriched2-0@706
monitoringEnriched2-0@707
monitoringEnriched2-0@708
monitoringEnriched2-0@709
monitoringEnriched2-0@710
monitoringEnriched2-0@711
monitoringEnriched2-0@712
monitoringEnriched2-0@713
monitoringEnriched2-0@714
monitoringEnriched2-0@715
monitoringEnriched2-0@716
monitoringEnriched2-0@717
monitoringEnriched2-0@718
monitoringEnriched2-0@719
monitoringEnriched2-0@720
monitoringEnriched2-0@721
monitoringEnriched2-0@722
monitoringEnriched2-0@723
monitoringEnriched2-0@724
monitoringEnriched2-0@725
monitoringEnriched2-0@726
monitoringEnriched2-0@727
monitoringEnriched2-0@728
monitoringEnriched2-0@729
monitoringEnriched2-0@730
monitoringEnriched2-0@731
monitoringEnriched2-0@732
monitoringEnriched2-0@733
monitoringEnriched2-0@734
monitoringEnriched2-0@735
monitoringEnriched2-0@736
monitoringEnriched2-0@737
monitoringEnriched2-0@738
monitoringEnriched2-0@739
monitoringEnriched2-0@740
monitoringEnriched2-0@741
monitoringEnriched2-0@742
monitoringEnriched2-0@743
monitoringEnriched2-0@744
monitoringEnriched2-0@745
monitoringEnriched2-0@746
monitoringEnriched2-0@747
monitoringEnriched2-0@748
monitoringEnriched2-0@749
monitoringEnriched2-0@750
monitoringEnriched2-0@751
monitoringEnriched2-0@752
monitoringEnriched2-0@753
monitoringEnriched2-0@754
monitoringEnriched2-0@755
monitoringEnriched2-0@756
monitoringEnriched2-0@757
monitoringEnriched2-0@758
monitoringEnriched2-0@759
monitoringEnriched2-0@760
monitoringEnriched2-0@761
monitoringEnriched2-0@762
monitoringEnriched2-0@763
monitoringEnriched2-0@764
monitoringEnriched2-0@765
monitoringEnriched2-0@766
monitoringEnriched2-0@767
monitoringEnriched2-0@768
monitoringEnriched2-0@769
monitoringEnriched2-0@770
monitoringEnriched2-0@771
monitoringEnriched2-0@772
monitoringEnriched2-0@773
monitoringEnriched2-0@774
monitoringEnriched2-0@775
monitoringEnriched2-0@776
monitoringEnriched2-0@777
monitoringEnriched2-0@778
monitoringEnriched2-0@779
monitoringEnriched2-0@780
monitoringEnriched2-0@781
monitoringEnriched2-0@782
monitoringEnriched2-0@783
monitoringEnriched2-0@784
monitoringEnriched2-0@785
monitoringEnriched2-0@786
monitoringEnriched2-0@787
monitoringEnriched2-0@788
monitoringEnriched2-0@789
monitoringEnriched2-0@790
monitoringEnriched2-0@791
monitoringEnriched2-0@792
monitoringEnriched2-0@793
monitoringEnriched2-0@794
monitoringEnriched2-0@795
monitoringEnriched2-0@796
monitoringEnriched2-0@797
monitoringEnriched2-0@798
monitoringEnriched2-0@799
monitoringEnriched2-0@800
monitoringEnriched2-0@801
monitoringEnriched2-0@802
monitoringEnriched2-0@803
monitoringEnriched2-0@804
monitoringEnriched2-0@805
monitoringEnriched2-0@806
monitoringEnriched2-0@807
monitoringEnriched2-0@808
monitoringEnriched2-0@809
monitoringEnriched2-0@810
monitoringEnriched2-0@811
monitoringEnriched2-0@812
monitoringEnriched2-0@813
monitoringEnriched2-0@814
monitoringEnriched2-0@815
monitoringEnriched2-0@816
monitoringEnriched2-0@817
monitoringEnriched2-0@818
monitoringEnriched2-0@819
monitoringEnriched2-0@820
monitoringEnriched2-0@821
monitoringEnriched2-0@822
monitoringEnriched2-0@823
monitoringEnriched2-0@824
monitoringEnriched2-0@825
monitoringEnriched2-0@826
monitoringEnriched2-0@827
monitoringEnriched2-0@828
monitoringEnriched2-0@829
monitoringEnriched2-0@830
monitoringEnriched2-0@831
monitoringEnriched2-0@832
monitoringEnriched2-0@833
monitoringEnriched2-0@834
monitoringEnriched2-0@835
monitoringEnriched2-0@836
monitoringEnriched2-0@837
monitoringEnriched2-0@838
monitoringEnriched2-0@839
monitoringEnriched2-0@840
monitoringEnriched2-0@841
monitoringEnriched2-0@842
monitoringEnriched2-0@843
monitoringEnriched2-0@844
monitoringEnriched2-0@845
monitoringEnriched2-0@846
monitoringEnriched2-0@847
monitoringEnriched2-0@848
monitoringEnriched2-0@849
monitoringEnriched2-0@850
monitoringEnriched2-0@851
monitoringEnriched2-0@852
monitoringEnriched2-0@853
monitoringEnriched2-0@854
monitoringEnriched2-0@855
monitoringEnriched2-0@856
monitoringEnriched2-0@857
monitoringEnriched2-0@858
monitoringEnriched2-0@859
monitoringEnriched2-0@860
monitoringEnriched2-0@861
monitoringEnriched2-0@862
monitoringEnriched2-0@863
monitoringEnriched2-0@864
monitoringEnriched2-0@865
monitoringEnriched2-0@866
monitoringEnriched2-0@867
monitoringEnriched2-0@868
monitoringEnriched2-0@869
monitoringEnriched2-0@870
monitoringEnriched2-0@871
monitoringEnriched2-0@872
monitoringEnriched2-0@873
monitoringEnriched2-0@874
monitoringEnriched2-0@875
monitoringEnriched2-0@876
monitoringEnriched2-0@877
monitoringEnriched2-0@878
monitoringEnriched2-0@879
monitoringEnriched2-0@880
monitoringEnriched2-0@881
monitoringEnriched2-0@882
monitoringEnriched2-0@883
monitoringEnriched2-0@884
monitoringEnriched2-0@885
monitoringEnriched2-0@886
monitoringEnriched2-0@887
monitoringEnriched2-0@888
monitoringEnriched2-0@889
monitoringEnriched2-0@890
monitoringEnriched2-0@891
monitoringEnriched2-0@892
monitoringEnriched2-0@893
monitoringEnriched2-0@894
monitoringEnriched2-0@895
monitoringEnriched2-0@896
monitoringEnriched2-0@897
monitoringEnriched2-0@898
monitoringEnriched2-0@899
monitoringEnriched2-0@900
monitoringEnriched2-0@901
monitoringEnriched2-0@902
monitoringEnriched2-0@903
monitoringEnriched2-0@904
monitoringEnriched2-0@905
monitoringEnriched2-0@906
monitoringEnriched2-0@907
monitoringEnriched2-0@908
monitoringEnriched2-0@909
monitoringEnriched2-0@910
monitoringEnriched2-0@911
monitoringEnriched2-0@912
monitoringEnriched2-0@913
monitoringEnriched2-0@914
monitoringEnriched2-0@915
monitoringEnriched2-0@916
monitoringEnriched2-0@917
monitoringEnriched2-0@918
monitoringEnriched2-0@919
monitoringEnriched2-0@920
monitoringEnriched2-0@921
monitoringEnriched2-0@922
monitoringEnriched2-0@923
monitoringEnriched2-0@924
monitoringEnriched2-0@925
monitoringEnriched2-0@926
monitoringEnriched2-0@927
monitoringEnriched2-0@928
monitoringEnriched2-0@929
monitoringEnriched2-0@930
monitoringEnriched2-0@931
monitoringEnriched2-0@932
monitoringEnriched2-0@933
monitoringEnriched2-0@934
monitoringEnriched2-0@935
monitoringEnriched2-0@936
monitoringEnriched2-0@937
monitoringEnriched2-0@938
monitoringEnriched2-0@939
monitoringEnriched2-0@940
monitoringEnriched2-0@941
monitoringEnriched2-0@942
monitoringEnriched2-0@943
monitoringEnriched2-0@944
monitoringEnriched2-0@945
monitoringEnriched2-0@946
monitoringEnriched2-0@947
monitoringEnriched2-0@948
monitoringEnriched2-0@949
monitoringEnriched2-0@950
monitoringEnriched2-0@951
monitoringEnriched2-0@952
monitoringEnriched2-0@953
monitoringEnriched2-0@954
monitoringEnriched2-0@955
monitoringEnriched2-0@956
monitoringEnriched2-0@957
monitoringEnriched2-0@958
monitoringEnriched2-0@959
monitoringEnriched2-0@960
monitoringEnriched2-0@961
monitoringEnriched2-0@962
monitoringEnriched2-0@963
monitoringEnriched2-0@964
monitoringEnriched2-0@965
monitoringEnriched2-0@966
monitoringEnriched2-0@967
monitoringEnriched2-0@968
monitoringEnriched2-0@969
monitoringEnriched2-0@970
monitoringEnriched2-0@971
monitoringEnriched2-0@972
monitoringEnriched2-0@973
monitoringEnriched2-0@974
monitoringEnriched2-0@975
monitoringEnriched2-0@976
monitoringEnriched2-0@977
monitoringEnriched2-0@978
monitoringEnriched2-0@979
monitoringEnriched2-0@980
monitoringEnriched2-0@981
monitoringEnriched2-0@982
monitoringEnriched2-0@983
monitoringEnriched2-0@984
monitoringEnriched2-0@985
monitoringEnriched2-0@986
monitoringEnriched2-0@987
monitoringEnriched2-0@988
monitoringEnriched2-0@989
monitoringEnriched2-0@990
monitoringEnriched2-0@991
monitoringEnriched2-0@992
monitoringEnriched2-0@993
monitoringEnriched2-0@994
monitoringEnriched2-0@995
monitoringEnriched2-0@996
monitoringEnriched2-0@997
monitoringEnriched2-0@998
monitoringEnriched2-0@999
monitoringEnriched2-0@1000
monitoringEnriched2-0@1001
monitoringEnriched2-0@1002
monitoringEnriched2-0@1003
monitoringEnriched2-0@1004
monitoringEnriched2-0@1005
monitoringEnriched2-0@1006
monitoringEnriched2-0@1007
monitoringEnriched2-0@1008
monitoringEnriched2-0@1009
monitoringEnriched2-0@1010
monitoringEnriched2-0@1011
monitoringEnriched2-0@1012
monitoringEnriched2-0@1013
monitoringEnriched2-0@1014
monitoringEnriched2-0@1015
monitoringEnriched2-0@1016
monitoringEnriched2-0@1017
monitoringEnriched2-0@1018
monitoringEnriched2-0@1019
monitoringEnriched2-0@1020
monitoringEnriched2-0@1021
monitoringEnriched2-0@1022
monitoringEnriched2-0@1023
monitoringEnriched2-0@1024
monitoringEnriched2-0@1025
monitoringEnriched2-0@1026
monitoringEnriched2-0@1027
monitoringEnriched2-0@1028
monitoringEnriched2-0@1029
monitoringEnriched2-0@1030
monitoringEnriched2-0@1031
monitoringEnriched2-0@1032
monitoringEnriched2-0@1033
monitoringEnriched2-0@1034
monitoringEnriched2-0@1035
monitoringEnriched2-0@1036
monitoringEnriched2-0@1037
monitoringEnriched2-0@1038
monitoringEnriched2-0@1039
monitoringEnriched2-0@1040
monitoringEnriched2-0@1041
monitoringEnriched2-0@1042
monitoringEnriched2-0@1043
monitoringEnriched2-0@1044
monitoringEnriched2-0@1045
monitoringEnriched2-0@1046
monitoringEnriched2-0@1047
monitoringEnriched2-0@1048
monitoringEnriched2-0@1049
monitoringEnriched2-0@1050
monitoringEnriched2-0@1051
monitoringEnriched2-0@1052
monitoringEnriched2-0@1053
monitoringEnriched2-0@1054
monitoringEnriched2-0@1055
monitoringEnriched2-0@1056
monitoringEnriched2-0@1057
monitoringEnriched2-0@1058
monitoringEnriched2-0@1059
monitoringEnriched2-0@1060
monitoringEnriched2-0@1061
monitoringEnriched2-0@1062
monitoringEnriched2-0@1063
monitoringEnriched2-0@1064
monitoringEnriched2-0@1065
monitoringEnriched2-0@1066
monitoringEnriched2-0@1067
monitoringEnriched2-0@1068
monitoringEnriched2-0@1069
monitoringEnriched2-0@1070
monitoringEnriched2-0@1071
monitoringEnriched2-0@1072
monitoringEnriched2-0@1073
monitoringEnriched2-0@1074
monitoringEnriched2-0@1075
monitoringEnriched2-0@1076
monitoringEnriched2-0@1077
monitoringEnriched2-0@1078
monitoringEnriched2-0@1079
monitoringEnriched2-0@1080
monitoringEnriched2-0@1081
monitoringEnriched2-0@1082
monitoringEnriched2-0@1083
monitoringEnriched2-0@1084
monitoringEnriched2-0@1085
monitoringEnriched2-0@1086
monitoringEnriched2-0@1087
monitoringEnriched2-0@1088
monitoringEnriched2-0@1089
monitoringEnriched2-0@1090
monitoringEnriched2-0@1091
monitoringEnriched2-0@1092
monitoringEnriched2-0@1093
monitoringEnriched2-0@1094
monitoringEnriched2-0@1095
monitoringEnriched2-0@1096
monitoringEnriched2-0@1097
monitoringEnriched2-0@1098
monitoringEnriched2-0@1099
monitoringEnriched2-0@1100
monitoringEnriched2-0@1101
monitoringEnriched2-0@1102
monitoringEnriched2-0@1103
monitoringEnriched2-0@1104
monitoringEnriched2-0@1105
monitoringEnriched2-0@1106
monitoringEnriched2-0@1107
monitoringEnriched2-0@1108
monitoringEnriched2-0@1109
monitoringEnriched2-0@1110
monitoringEnriched2-0@1111
monitoringEnriched2-0@1112
monitoringEnriched2-0@1113
monitoringEnriched2-0@1114
monitoringEnriched2-0@1115
monitoringEnriched2-0@1116
monitoringEnriched2-0@1117
monitoringEnriched2-0@1118
monitoringEnriched2-0@1119
monitoringEnriched2-0@1120
monitoringEnriched2-0@1121
monitoringEnriched2-0@1122
monitoringEnriched2-0@1123
monitoringEnriched2-0@1124
monitoringEnriched2-0@1125
monitoringEnriched2-0@1126
monitoringEnriched2-0@1127
monitoringEnriched2-0@1128
monitoringEnriched2-0@1129
monitoringEnriched2-0@1130
monitoringEnriched2-0@1131
monitoringEnriched2-0@1132
monitoringEnriched2-0@1133
monitoringEnriched2-0@1134
monitoringEnriched2-0@1135
monitoringEnriched2-0@1136
monitoringEnriched2-0@1137
monitoringEnriched2-0@1138
monitoringEnriched2-0@1139
monitoringEnriched2-0@1140
monitoringEnriched2-0@1141
monitoringEnriched2-0@1142
monitoringEnriched2-0@1143
monitoringEnriched2-0@1144
monitoringEnriched2-0@1145
monitoringEnriched2-0@1146
monitoringEnriched2-0@1147
monitoringEnriched2-0@1148
monitoringEnriched2-0@1149
monitoringEnriched2-0@1150
monitoringEnriched2-0@1151
monitoringEnriched2-0@1152
monitoringEnriched2-0@1153
monitoringEnriched2-0@1154
monitoringEnriched2-0@1155
monitoringEnriched2-0@1156
monitoringEnriched2-0@1157
monitoringEnriched2-0@1158
monitoringEnriched2-0@1159
monitoringEnriched2-0@1160
monitoringEnriched2-0@1161
monitoringEnriched2-0@1162
monitoringEnriched2-0@1163
monitoringEnriched2-0@1164
monitoringEnriched2-0@1165
monitoringEnriched2-0@1166
monitoringEnriched2-0@1167
monitoringEnriched2-0@1168
monitoringEnriched2-0@1169
monitoringEnriched2-0@1170
monitoringEnriched2-0@1171
monitoringEnriched2-0@1172
monitoringEnriched2-0@1173
monitoringEnriched2-0@1174
monitoringEnriched2-0@1175
monitoringEnriched2-0@1176
monitoringEnriched2-0@1177
monitoringEnriched2-0@1178
monitoringEnriched2-0@1179
monitoringEnriched2-0@1180
monitoringEnriched2-0@1181
monitoringEnriched2-0@1182
monitoringEnriched2-0@1183
monitoringEnriched2-0@1184
monitoringEnriched2-0@1185
monitoringEnriched2-0@1186
monitoringEnriched2-0@1187
monitoringEnriched2-0@1188
monitoringEnriched2-0@1189
monitoringEnriched2-0@1190
monitoringEnriched2-0@1191
monitoringEnriched2-0@1192
monitoringEnriched2-0@1193
monitoringEnriched2-0@1194
monitoringEnriched2-0@1195
monitoringEnriched2-0@1196
monitoringEnriched2-0@1197
monitoringEnriched2-0@1198
monitoringEnriched2-0@1199
monitoringEnriched2-0@1200
monitoringEnriched2-0@1201
monitoringEnriched2-0@1202
monitoringEnriched2-0@1203
monitoringEnriched2-0@1204
monitoringEnriched2-0@1205
monitoringEnriched2-0@1206
monitoringEnriched2-0@1207
monitoringEnriched2-0@1208
monitoringEnriched2-0@1209
monitoringEnriched2-0@1210
monitoringEnriched2-0@1211
monitoringEnriched2-0@1212
monitoringEnriched2-0@1213
monitoringEnriched2-0@1214
monitoringEnriched2-0@1215
monitoringEnriched2-0@1216
monitoringEnriched2-0@1217
monitoringEnriched2-0@1218
monitoringEnriched2-0@1219
monitoringEnriched2-0@1220
monitoringEnriched2-0@1221
monitoringEnriched2-0@1222
monitoringEnriched2-0@1223
monitoringEnriched2-0@1224
monitoringEnriched2-0@1225
monitoringEnriched2-0@1226
monitoringEnriched2-0@1227
monitoringEnriched2-0@1228
monitoringEnriched2-0@1229
monitoringEnriched2-0@1230
monitoringEnriched2-0@1231
monitoringEnriched2-0@1232
monitoringEnriched2-0@1233
monitoringEnriched2-0@1234
monitoringEnriched2-0@1235
monitoringEnriched2-0@1236
monitoringEnriched2-0@1237
monitoringEnriched2-0@1238
monitoringEnriched2-0@1239
monitoringEnriched2-0@1240
monitoringEnriched2-0@1241
monitoringEnriched2-0@1242
monitoringEnriched2-0@1243
monitoringEnriched2-0@1244
monitoringEnriched2-0@1245
monitoringEnriched2-0@1246
monitoringEnriched2-0@1247
monitoringEnriched2-0@1248
monitoringEnriched2-0@1249
monitoringEnriched2-0@1250
monitoringEnriched2-0@1251
monitoringEnriched2-0@1252
monitoringEnriched2-0@1253
monitoringEnriched2-0@1254
monitoringEnriched2-0@1255
monitoringEnriched2-0@1256
monitoringEnriched2-0@1257
monitoringEnriched2-0@1258
monitoringEnriched2-0@1259
monitoringEnriched2-0@1260
monitoringEnriched2-0@1261
monitoringEnriched2-0@1262
monitoringEnriched2-0@1263
monitoringEnriched2-0@1264
monitoringEnriched2-0@1265
monitoringEnriched2-0@1266
monitoringEnriched2-0@1267
monitoringEnriched2-0@1268
monitoringEnriched2-0@1269
monitoringEnriched2-0@1270
monitoringEnriched2-0@1271
monitoringEnriched2-0@1272
monitoringEnriched2-0@1273
monitoringEnriched2-0@1274
monitoringEnriched2-0@1275
monitoringEnriched2-0@1276
monitoringEnriched2-0@1277
monitoringEnriched2-0@1278
monitoringEnriched2-0@1279
monitoringEnriched2-0@1280
monitoringEnriched2-0@1281
monitoringEnriched2-0@1282
monitoringEnriched2-0@1283
monitoringEnriched2-0@1284
monitoringEnriched2-0@1285
monitoringEnriched2-0@1286
monitoringEnriched2-0@1287
monitoringEnriched2-0@1288
monitoringEnriched2-0@1289
monitoringEnriched2-0@1290
monitoringEnriched2-0@1291
monitoringEnriched2-0@1292
monitoringEnriched2-0@1293
monitoringEnriched2-0@1294
monitoringEnriched2-0@1295
monitoringEnriched2-0@1296
monitoringEnriched2-0@1297
monitoringEnriched2-0@1298
monitoringEnriched2-0@1299
monitoringEnriched2-0@1300
monitoringEnriched2-0@1301
monitoringEnriched2-0@1302
monitoringEnriched2-0@1303
monitoringEnriched2-0@1304
monitoringEnriched2-0@1305
monitoringEnriched2-0@1306
monitoringEnriched2-0@1307
monitoringEnriched2-0@1308
monitoringEnriched2-0@1309
monitoringEnriched2-0@1310
monitoringEnriched2-0@1311
monitoringEnriched2-0@1312
monitoringEnriched2-0@1313
monitoringEnriched2-0@1314
monitoringEnriched2-0@1315
monitoringEnriched2-0@1316
monitoringEnriched2-0@1317
monitoringEnriched2-0@1318
monitoringEnriched2-0@1319
monitoringEnriched2-0@1320
monitoringEnriched2-0@1321
monitoringEnriched2-0@1322
monitoringEnriched2-0@1323
monitoringEnriched2-0@1324
monitoringEnriched2-0@1325
monitoringEnriched2-0@1326
monitoringEnriched2-0@1327
monitoringEnriched2-0@1328
monitoringEnriched2-0@1329
monitoringEnriched2-0@1330
monitoringEnriched2-0@1331
monitoringEnriched2-0@1332
monitoringEnriched2-0@1333
monitoringEnriched2-0@1334
monitoringEnriched2-0@1335
monitoringEnriched2-0@1336
monitoringEnriched2-0@1337
monitoringEnriched2-0@1338
monitoringEnriched2-0@1339
monitoringEnriched2-0@1340
monitoringEnriched2-0@1341
monitoringEnriched2-0@1342
monitoringEnriched2-0@1343
monitoringEnriched2-0@1344
monitoringEnriched2-0@1345
monitoringEnriched2-0@1346
monitoringEnriched2-0@1347
monitoringEnriched2-0@1348
monitoringEnriched2-0@1349
monitoringEnriched2-0@1350
monitoringEnriched2-0@1351
monitoringEnriched2-0@1352
monitoringEnriched2-0@1353
monitoringEnriched2-0@1354
monitoringEnriched2-0@1355
monitoringEnriched2-0@1356
monitoringEnriched2-0@1357
monitoringEnriched2-0@1358
monitoringEnriched2-0@1359
monitoringEnriched2-0@1360
monitoringEnriched2-0@1361
monitoringEnriched2-0@1362
monitoringEnriched2-0@1363
monitoringEnriched2-0@1364
monitoringEnriched2-0@1365
monitoringEnriched2-0@1366
monitoringEnriched2-0@1367
monitoringEnriched2-0@1368
monitoringEnriched2-0@1369
monitoringEnriched2-0@1370
monitoringEnriched2-0@1371
monitoringEnriched2-0@1372
monitoringEnriched2-0@1373
monitoringEnriched2-0@1374
monitoringEnriched2-0@1375
monitoringEnriched2-0@1376
monitoringEnriched2-0@1377
monitoringEnriched2-0@1378
monitoringEnriched2-0@1379
monitoringEnriched2-0@1380
monitoringEnriched2-0@1381
monitoringEnriched2-0@1382
monitoringEnriched2-0@1383
monitoringEnriched2-0@1384
monitoringEnriched2-0@1385
monitoringEnriched2-0@1386
monitoringEnriched2-0@1387
monitoringEnriched2-0@1388
monitoringEnriched2-0@1389
monitoringEnriched2-0@1390
monitoringEnriched2-0@1391
monitoringEnriched2-0@1392
monitoringEnriched2-0@1393
monitoringEnriched2-0@1394
monitoringEnriched2-0@1395
monitoringEnriched2-0@1396
monitoringEnriched2-0@1397
monitoringEnriched2-0@1398
monitoringEnriched2-0@1399
monitoringEnriched2-0@1400
monitoringEnriched2-0@1401
monitoringEnriched2-0@1402
monitoringEnriched2-0@1403
monitoringEnriched2-0@1404
monitoringEnriched2-0@1405
monitoringEnriched2-0@1406
monitoringEnriched2-0@1407
monitoringEnriched2-0@1408
monitoringEnriched2-0@1409
monitoringEnriched2-0@1410
monitoringEnriched2-0@1411
monitoringEnriched2-0@1412
monitoringEnriched2-0@1413
monitoringEnriched2-0@1414
monitoringEnriched2-0@1415
monitoringEnriched2-0@1416
monitoringEnriched2-0@1417
monitoringEnriched2-0@1418
monitoringEnriched2-0@1419
monitoringEnriched2-0@1420
monitoringEnriched2-0@1421
monitoringEnriched2-0@1422
monitoringEnriched2-0@1423
monitoringEnriched2-0@1424
monitoringEnriched2-0@1425
monitoringEnriched2-0@1426
monitoringEnriched2-0@1427
monitoringEnriched2-0@1428
monitoringEnriched2-0@1429
monitoringEnriched2-0@1430
monitoringEnriched2-0@1431
monitoringEnriched2-0@1432
monitoringEnriched2-0@1433
monitoringEnriched2-0@1434
monitoringEnriched2-0@1435
monitoringEnriched2-0@1436
monitoringEnriched2-0@1437
monitoringEnriched2-0@1438
monitoringEnriched2-0@1439
monitoringEnriched2-0@1440
monitoringEnriched2-0@1441
monitoringEnriched2-0@1442
monitoringEnriched2-0@1443
monitoringEnriched2-0@1444
monitoringEnriched2-0@1445
monitoringEnriched2-0@1446
monitoringEnriched2-0@1447
monitoringEnriched2-0@1448
monitoringEnriched2-0@1449
monitoringEnriched2-0@1450
monitoringEnriched2-0@1451
monitoringEnriched2-0@1452
monitoringEnriched2-0@1453
monitoringEnriched2-0@1454
monitoringEnriched2-0@1455
monitoringEnriched2-0@1456
monitoringEnriched2-0@1457
monitoringEnriched2-0@1458
monitoringEnriched2-0@1459
monitoringEnriched2-0@1460
monitoringEnriched2-0@1461
monitoringEnriched2-0@1462
monitoringEnriched2-0@1463
monitoringEnriched2-0@1464
monitoringEnriched2-0@1465
monitoringEnriched2-0@1466
monitoringEnriched2-0@1467
monitoringEnriched2-0@1468
monitoringEnriched2-0@1469
monitoringEnriched2-0@1470
monitoringEnriched2-0@1471
monitoringEnriched2-0@1472
monitoringEnriched2-0@1473
monitoringEnriched2-0@1474
monitoringEnriched2-0@1475
monitoringEnriched2-0@1476
monitoringEnriched2-0@1477
monitoringEnriched2-0@1478
monitoringEnriched2-0@1479
monitoringEnriched2-0@1480
monitoringEnriched2-0@1481
monitoringEnriched2-0@1482
monitoringEnriched2-0@1483
monitoringEnriched2-0@1484
monitoringEnriched2-0@1485
monitoringEnriched2-0@1486
monitoringEnriched2-0@1487
monitoringEnriched2-0@1488
monitoringEnriched2-0@1489
monitoringEnriched2-0@1490
monitoringEnriched2-0@1491
monitoringEnriched2-0@1492
monitoringEnriched2-0@1493
monitoringEnriched2-0@1494
monitoringEnriched2-0@1495
monitoringEnriched2-0@1496
monitoringEnriched2-0@1497
monitoringEnriched2-0@1498
monitoringEnriched2-0@1499
monitoringEnriched2-0@1500
monitoringEnriched2-0@1501
monitoringEnriched2-0@1502
monitoringEnriched2-0@1503
monitoringEnriched2-0@1504
monitoringEnriched2-0@1505
monitoringEnriched2-0@1506
monitoringEnriched2-0@1507
monitoringEnriched2-0@1508
monitoringEnriched2-0@1509
monitoringEnriched2-0@1510
monitoringEnriched2-0@1511
monitoringEnriched2-0@1512
monitoringEnriched2-0@1513
monitoringEnriched2-0@1514
monitoringEnriched2-0@1515
monitoringEnriched2-0@1516
monitoringEnriched2-0@1517
monitoringEnriched2-0@1518
monitoringEnriched2-0@1519
monitoringEnriched2-0@1520
monitoringEnriched2-0@1521
monitoringEnriched2-0@1522
monitoringEnriched2-0@1523
monitoringEnriched2-0@1524
monitoringEnriched2-0@1525
monitoringEnriched2-0@1526
monitoringEnriched2-0@1527
monitoringEnriched2-0@1528
monitoringEnriched2-0@1529
monitoringEnriched2-0@1530
monitoringEnriched2-0@1531
monitoringEnriched2-0@1532
monitoringEnriched2-0@1533
monitoringEnriched2-0@1534
monitoringEnriched2-0@1535
monitoringEnriched2-0@1536
monitoringEnriched2-0@1537
monitoringEnriched2-0@1538
monitoringEnriched2-0@1539
monitoringEnriched2-0@1540
monitoringEnriched2-0@1541
monitoringEnriched2-0@1542
monitoringEnriched2-0@1543
monitoringEnriched2-0@1544
monitoringEnriched2-0@1545
monitoringEnriched2-0@1546
monitoringEnriched2-0@1547
monitoringEnriched2-0@1548
monitoringEnriched2-0@1549
monitoringEnriched2-0@1550
monitoringEnriched2-0@1551
monitoringEnriched2-0@1552
monitoringEnriched2-0@1553
monitoringEnriched2-0@1554
monitoringEnriched2-0@1555
monitoringEnriched2-0@1556
monitoringEnriched2-0@1557
monitoringEnriched2-0@1558
monitoringEnriched2-0@1559
monitoringEnriched2-0@1560
monitoringEnriched2-0@1561
monitoringEnriched2-0@1562
monitoringEnriched2-0@1563
monitoringEnriched2-0@1564
monitoringEnriched2-0@1565
monitoringEnriched2-0@1566
monitoringEnriched2-0@1567
monitoringEnriched2-0@1568
monitoringEnriched2-0@1569
monitoringEnriched2-0@1570
monitoringEnriched2-0@1571
monitoringEnriched2-0@1572
monitoringEnriched2-0@1573
monitoringEnriched2-0@1574
monitoringEnriched2-0@1575
monitoringEnriched2-0@1576
monitoringEnriched2-0@1577
monitoringEnriched2-0@1578
monitoringEnriched2-0@1579
monitoringEnriched2-0@1580
monitoringEnriched2-0@1581
monitoringEnriched2-0@1582
monitoringEnriched2-0@1583
monitoringEnriched2-0@1584
monitoringEnriched2-0@1585
monitoringEnriched2-0@1586
monitoringEnriched2-0@1587
monitoringEnriched2-0@1588
monitoringEnriched2-0@1589
monitoringEnriched2-0@1590
monitoringEnriched2-0@1591
monitoringEnriched2-0@1592
monitoringEnriched2-0@1593
monitoringEnriched2-0@1594
monitoringEnriched2-0@1595
monitoringEnriched2-0@1596
monitoringEnriched2-0@1597
monitoringEnriched2-0@1598
monitoringEnriched2-0@1599
monitoringEnriched2-0@1600
monitoringEnriched2-0@1601
monitoringEnriched2-0@1602
monitoringEnriched2-0@1603
monitoringEnriched2-0@1604
monitoringEnriched2-0@1605
monitoringEnriched2-0@1606
monitoringEnriched2-0@1607
monitoringEnriched2-0@1608
monitoringEnriched2-0@1609
monitoringEnriched2-0@1610
monitoringEnriched2-0@1611
monitoringEnriched2-0@1612
monitoringEnriched2-0@1613
monitoringEnriched2-0@1614
monitoringEnriched2-0@1615
monitoringEnriched2-0@1616
monitoringEnriched2-0@1617
monitoringEnriched2-0@1618
monitoringEnriched2-0@1619
monitoringEnriched2-0@1620
monitoringEnriched2-0@1621
monitoringEnriched2-0@1622
monitoringEnriched2-0@1623
monitoringEnriched2-0@1624
monitoringEnriched2-0@1625
monitoringEnriched2-0@1626
monitoringEnriched2-0@1627
monitoringEnriched2-0@1628
monitoringEnriched2-0@1629
monitoringEnriched2-0@1630
monitoringEnriched2-0@1631
monitoringEnriched2-0@1632
monitoringEnriched2-0@1633
monitoringEnriched2-0@1634
monitoringEnriched2-0@1635
monitoringEnriched2-0@1636
monitoringEnriched2-0@1637
monitoringEnriched2-0@1638
monitoringEnriched2-0@1639
monitoringEnriched2-0@1640
monitoringEnriched2-0@1641
monitoringEnriched2-0@1642
monitoringEnriched2-0@1643
monitoringEnriched2-0@1644
monitoringEnriched2-0@1645
monitoringEnriched2-0@1646
monitoringEnriched2-0@1647
monitoringEnriched2-0@1648
monitoringEnriched2-0@1649
monitoringEnriched2-0@1650
monitoringEnriched2-0@1651
monitoringEnriched2-0@1652
monitoringEnriched2-0@1653
monitoringEnriched2-0@1654
monitoringEnriched2-0@1655
monitoringEnriched2-0@1656
monitoringEnriched2-0@1657
monitoringEnriched2-0@1658
monitoringEnriched2-0@1659
monitoringEnriched2-0@1660
monitoringEnriched2-0@1661
monitoringEnriched2-0@1662
monitoringEnriched2-0@1663
monitoringEnriched2-0@1664
monitoringEnriched2-0@1665
monitoringEnriched2-0@1666
monitoringEnriched2-0@1667
monitoringEnriched2-0@1668
monitoringEnriched2-0@1669
monitoringEnriched2-0@1670
monitoringEnriched2-0@1671
monitoringEnriched2-0@1672
monitoringEnriched2-0@1673
monitoringEnriched2-0@1674
monitoringEnriched2-0@1675
monitoringEnriched2-0@1676
monitoringEnriched2-0@1677
monitoringEnriched2-0@1678
monitoringEnriched2-0@1679
monitoringEnriched2-0@1680
monitoringEnriched2-0@1681
monitoringEnriched2-0@1682
monitoringEnriched2-0@1683
monitoringEnriched2-0@1684
monitoringEnriched2-0@1685
monitoringEnriched2-0@1686
monitoringEnriched2-0@1687
monitoringEnriched2-0@1688
monitoringEnriched2-0@1689
monitoringEnriched2-0@1690
monitoringEnriched2-0@1691
monitoringEnriched2-0@1692
monitoringEnriched2-0@1693
monitoringEnriched2-0@1694
monitoringEnriched2-0@1695
monitoringEnriched2-0@1696
monitoringEnriched2-0@1697
monitoringEnriched2-0@1698
monitoringEnriched2-0@1699
monitoringEnriched2-0@1700
monitoringEnriched2-0@1701
monitoringEnriched2-0@1702
monitoringEnriched2-0@1703
monitoringEnriched2-0@1704
monitoringEnriched2-0@1705
monitoringEnriched2-0@1706
monitoringEnriched2-0@1707
monitoringEnriched2-0@1708
monitoringEnriched2-0@1709
monitoringEnriched2-0@1710
monitoringEnriched2-0@1711
monitoringEnriched2-0@1712
monitoringEnriched2-0@1713
monitoringEnriched2-0@1714
monitoringEnriched2-0@1715
monitoringEnriched2-0@1716
monitoringEnriched2-0@1717
monitoringEnriched2-0@1718
monitoringEnriched2-0@1719
monitoringEnriched2-0@1720
monitoringEnriched2-0@1721
monitoringEnriched2-0@1722
monitoringEnriched2-0@1723
monitoringEnriched2-0@1724
monitoringEnriched2-0@1725
monitoringEnriched2-0@1726
monitoringEnriched2-0@1727
monitoringEnriched2-0@1728
monitoringEnriched2-0@1729
monitoringEnriched2-0@1730
monitoringEnriched2-0@1731
monitoringEnriched2-0@1732
monitoringEnriched2-0@1733
monitoringEnriched2-0@1734
monitoringEnriched2-0@1735
monitoringEnriched2-0@1736
monitoringEnriched2-0@1737
monitoringEnriched2-0@1738
monitoringEnriched2-0@1739
monitoringEnriched2-0@1740
monitoringEnriched2-0@1741
monitoringEnriched2-0@1742
monitoringEnriched2-0@1743
monitoringEnriched2-0@1744
monitoringEnriched2-0@1745
monitoringEnriched2-0@1746
monitoringEnriched2-0@1747
monitoringEnriched2-0@1748
monitoringEnriched2-0@1749
monitoringEnriched2-0@1750
monitoringEnriched2-0@1751
monitoringEnriched2-0@1752
monitoringEnriched2-0@1753
monitoringEnriched2-0@1754
monitoringEnriched2-0@1755
monitoringEnriched2-0@1756
monitoringEnriched2-0@1757
monitoringEnriched2-0@1758
monitoringEnriched2-0@1759
monitoringEnriched2-0@1760
monitoringEnriched2-0@1761
monitoringEnriched2-0@1762
monitoringEnriched2-0@1763
monitoringEnriched2-0@1764
monitoringEnriched2-0@1765
monitoringEnriched2-0@1766
monitoringEnriched2-0@1767
monitoringEnriched2-0@1768
monitoringEnriched2-0@1769
monitoringEnriched2-0@1770
monitoringEnriched2-0@1771
monitoringEnriched2-0@1772
monitoringEnriched2-0@1773
monitoringEnriched2-0@1774
monitoringEnriched2-0@1775
monitoringEnriched2-0@1776
monitoringEnriched2-0@1777
monitoringEnriched2-0@1778
monitoringEnriched2-0@1779
monitoringEnriched2-0@1780
monitoringEnriched2-0@1781
monitoringEnriched2-0@1782
monitoringEnriched2-0@1783
monitoringEnriched2-0@1784
monitoringEnriched2-0@1785
monitoringEnriched2-0@1786
monitoringEnriched2-0@1787
monitoringEnriched2-0@1788
monitoringEnriched2-0@1789
monitoringEnriched2-0@1790
monitoringEnriched2-0@1791
monitoringEnriched2-0@1792
monitoringEnriched2-0@1793
monitoringEnriched2-0@1794
monitoringEnriched2-0@1795
monitoringEnriched2-0@1796
monitoringEnriched2-0@1797
monitoringEnriched2-0@1798
monitoringEnriched2-0@1799
monitoringEnriched2-0@1800
monitoringEnriched2-0@1801
monitoringEnriched2-0@1802
monitoringEnriched2-0@1803
monitoringEnriched2-0@1804
monitoringEnriched2-0@1805
monitoringEnriched2-0@1806
monitoringEnriched2-0@1807
monitoringEnriched2-0@1808
monitoringEnriched2-0@1809
monitoringEnriched2-0@1810
monitoringEnriched2-0@1811
monitoringEnriched2-0@1812
monitoringEnriched2-0@1813
monitoringEnriched2-0@1814
monitoringEnriched2-0@1815
monitoringEnriched2-0@1816
monitoringEnriched2-0@1817
monitoringEnriched2-0@1818
monitoringEnriched2-0@1819
monitoringEnriched2-0@1820
monitoringEnriched2-0@1821
monitoringEnriched2-0@1822
monitoringEnriched2-0@1823
monitoringEnriched2-0@1824
monitoringEnriched2-0@1825
monitoringEnriched2-0@1826
monitoringEnriched2-0@1827
monitoringEnriched2-0@1828
monitoringEnriched2-0@1829
monitoringEnriched2-0@1830
monitoringEnriched2-0@1831
monitoringEnriched2-0@1832
monitoringEnriched2-0@1833
monitoringEnriched2-0@1834
monitoringEnriched2-0@1835
monitoringEnriched2-0@1836
monitoringEnriched2-0@1837
monitoringEnriched2-0@1838
monitoringEnriched2-0@1839
monitoringEnriched2-0@1840
monitoringEnriched2-0@1841
monitoringEnriched2-0@1842
monitoringEnriched2-0@1843
monitoringEnriched2-0@1844
monitoringEnriched2-0@1845
monitoringEnriched2-0@1846
monitoringEnriched2-0@1847
monitoringEnriched2-0@1848
monitoringEnriched2-0@1849
monitoringEnriched2-0@1850
monitoringEnriched2-0@1851
monitoringEnriched2-0@1852
monitoringEnriched2-0@1853
monitoringEnriched2-0@1854
monitoringEnriched2-0@1855
monitoringEnriched2-0@1856
monitoringEnriched2-0@1857
monitoringEnriched2-0@1858
monitoringEnriched2-0@1859
monitoringEnriched2-0@1860
monitoringEnriched2-0@1861
monitoringEnriched2-0@1862
monitoringEnriched2-0@1863
monitoringEnriched2-0@1864
monitoringEnriched2-0@1865
monitoringEnriched2-0@1866
monitoringEnriched2-0@1867
monitoringEnriched2-0@1868
monitoringEnriched2-0@1869
monitoringEnriched2-0@1870
monitoringEnriched2-0@1871
monitoringEnriched2-0@1872
monitoringEnriched2-0@1873
monitoringEnriched2-0@1874
monitoringEnriched2-0@1875
monitoringEnriched2-0@1876
monitoringEnriched2-0@1877
monitoringEnriched2-0@1878
monitoringEnriched2-0@1879
monitoringEnriched2-0@1880
monitoringEnriched2-0@1881
monitoringEnriched2-0@1882
monitoringEnriched2-0@1883
monitoringEnriched2-0@1884
monitoringEnriched2-0@1885
monitoringEnriched2-0@1886
monitoringEnriched2-0@1887
monitoringEnriched2-0@1888
monitoringEnriched2-0@1889
monitoringEnriched2-0@1890
monitoringEnriched2-0@1891
monitoringEnriched2-0@1892
monitoringEnriched2-0@1893
monitoringEnriched2-0@1894
monitoringEnriched2-0@1895
monitoringEnriched2-0@1896
monitoringEnriched2-0@1897
monitoringEnriched2-0@1898
monitoringEnriched2-0@1899
monitoringEnriched2-0@1900
monitoringEnriched2-0@1901
monitoringEnriched2-0@1902
monitoringEnriched2-0@1903
monitoringEnriched2-0@1904
monitoringEnriched2-0@1905
monitoringEnriched2-0@1906
monitoringEnriched2-0@1907
monitoringEnriched2-0@1908
monitoringEnriched2-0@1909
monitoringEnriched2-0@1910
monitoringEnriched2-0@1911
monitoringEnriched2-0@1912
monitoringEnriched2-0@1913
monitoringEnriched2-0@1914
monitoringEnriched2-0@1915
monitoringEnriched2-0@1916
monitoringEnriched2-0@1917
monitoringEnriched2-0@1918
monitoringEnriched2-0@1919
monitoringEnriched2-0@1920
monitoringEnriched2-0@1921
monitoringEnriched2-0@1922
monitoringEnriched2-0@1923
monitoringEnriched2-0@1924
monitoringEnriched2-0@1925
monitoringEnriched2-0@1926
monitoringEnriched2-0@1927
monitoringEnriched2-0@1928
monitoringEnriched2-0@1929
monitoringEnriched2-0@1930
monitoringEnriched2-0@1931
monitoringEnriched2-0@1932
monitoringEnriched2-0@1933
monitoringEnriched2-0@1934
monitoringEnriched2-0@1935
monitoringEnriched2-0@1936
monitoringEnriched2-0@1937
monitoringEnriched2-0@1938
monitoringEnriched2-0@1939
monitoringEnriched2-0@1940
monitoringEnriched2-0@1941
monitoringEnriched2-0@1942
monitoringEnriched2-0@1943
monitoringEnriched2-0@1944
monitoringEnriched2-0@1945
monitoringEnriched2-0@1946
monitoringEnriched2-0@1947
monitoringEnriched2-0@1948
monitoringEnriched2-0@1949
monitoringEnriched2-0@1950
monitoringEnriched2-0@1951
monitoringEnriched2-0@1952
monitoringEnriched2-0@1953
monitoringEnriched2-0@1954
monitoringEnriched2-0@1955
monitoringEnriched2-0@1956
monitoringEnriched2-0@1957
monitoringEnriched2-0@1958
monitoringEnriched2-0@1959
monitoringEnriched2-0@1960
monitoringEnriched2-0@1961
monitoringEnriched2-0@1962
monitoringEnriched2-0@1963
monitoringEnriched2-0@1964
monitoringEnriched2-0@1965
monitoringEnriched2-0@1966
monitoringEnriched2-0@1967
monitoringEnriched2-0@1968
monitoringEnriched2-0@1969
monitoringEnriched2-0@1970
monitoringEnriched2-0@1971
monitoringEnriched2-0@1972
monitoringEnriched2-0@1973
monitoringEnriched2-0@1974
monitoringEnriched2-0@1975
monitoringEnriched2-0@1976
monitoringEnriched2-0@1977
monitoringEnriched2-0@1978
monitoringEnriched2-0@1979
monitoringEnriched2-0@1980
monitoringEnriched2-0@1981
monitoringEnriched2-0@1982
monitoringEnriched2-0@1983
monitoringEnriched2-0@1984
monitoringEnriched2-0@1985
monitoringEnriched2-0@1986
monitoringEnriched2-0@1987
monitoringEnriched2-0@1988
monitoringEnriched2-0@1989
monitoringEnriched2-0@1990
monitoringEnriched2-0@1991
monitoringEnriched2-0@1992
monitoringEnriched2-0@1993
monitoringEnriched2-0@1994
monitoringEnriched2-0@1995
monitoringEnriched2-0@1996
monitoringEnriched2-0@1997
monitoringEnriched2-0@1998
monitoringEnriched2-0@1999
monitoringEnriched2-0@2000
monitoringEnriched2-0@2001
monitoringEnriched2-0@2002
monitoringEnriched2-0@2003
monitoringEnriched2-0@2004
monitoringEnriched2-0@2005
monitoringEnriched2-0@2006
monitoringEnriched2-0@2007
monitoringEnriched2-0@2008
monitoringEnriched2-0@2009
monitoringEnriched2-0@2010
monitoringEnriched2-0@2011
monitoringEnriched2-0@2012
monitoringEnriched2-0@2013
monitoringEnriched2-0@2014
monitoringEnriched2-0@2015
monitoringEnriched2-0@2016
monitoringEnriched2-0@2017
monitoringEnriched2-0@2018
monitoringEnriched2-0@2019
monitoringEnriched2-0@2020
monitoringEnriched2-0@2021
monitoringEnriched2-0@2022
monitoringEnriched2-0@2023
monitoringEnriched2-0@2024
monitoringEnriched2-0@2025
monitoringEnriched2-0@2026
monitoringEnriched2-0@2027
monitoringEnriched2-0@2028
monitoringEnriched2-0@2029
monitoringEnriched2-0@2030
monitoringEnriched2-0@2031
monitoringEnriched2-0@2032
monitoringEnriched2-0@2033
monitoringEnriched2-0@2034
monitoringEnriched2-0@2035
monitoringEnriched2-0@2036
monitoringEnriched2-0@2037
monitoringEnriched2-0@2038
monitoringEnriched2-0@2039
monitoringEnriched2-0@2040
monitoringEnriched2-0@2041
monitoringEnriched2-0@2042
monitoringEnriched2-0@2043
monitoringEnriched2-0@2044
monitoringEnriched2-0@2045
monitoringEnriched2-0@2046
monitoringEnriched2-0@2047
monitoringEnriched2-0@2048
monitoringEnriched2-0@2049
monitoringEnriched2-0@2050
monitoringEnriched2-0@2051
monitoringEnriched2-0@2052
monitoringEnriched2-0@2053
monitoringEnriched2-0@2054
monitoringEnriched2-0@2055
monitoringEnriched2-0@2056
monitoringEnriched2-0@2057
monitoringEnriched2-0@2058
monitoringEnriched2-0@2059
monitoringEnriched2-0@2060
monitoringEnriched2-0@2061
monitoringEnriched2-0@2062
monitoringEnriched2-0@2063
monitoringEnriched2-0@2064
monitoringEnriched2-0@2065
monitoringEnriched2-0@2066
monitoringEnriched2-0@2067
monitoringEnriched2-0@2068
monitoringEnriched2-0@2069
monitoringEnriched2-0@2070
monitoringEnriched2-0@2071
monitoringEnriched2-0@2072
monitoringEnriched2-0@2073
monitoringEnriched2-0@2074
monitoringEnriched2-0@2075
monitoringEnriched2-0@2076
monitoringEnriched2-0@2077
monitoringEnriched2-0@2078
monitoringEnriched2-0@2079
monitoringEnriched2-0@2080
monitoringEnriched2-0@2081
monitoringEnriched2-0@2082
monitoringEnriched2-0@2083
monitoringEnriched2-0@2084
monitoringEnriched2-0@2085
monitoringEnriched2-0@2086
monitoringEnriched2-0@2087
monitoringEnriched2-0@2088
monitoringEnriched2-0@2089
monitoringEnriched2-0@2090
monitoringEnriched2-0@2091
monitoringEnriched2-0@2092
monitoringEnriched2-0@2093
monitoringEnriched2-0@2094
monitoringEnriched2-0@2095
monitoringEnriched2-0@2096
monitoringEnriched2-0@2097
monitoringEnriched2-0@2098
monitoringEnriched2-0@2099
monitoringEnriched2-0@2100
monitoringEnriched2-0@2101
monitoringEnriched2-0@2102
monitoringEnriched2-0@2103
monitoringEnriched2-0@2104
monitoringEnriched2-0@2105
monitoringEnriched2-0@2106
monitoringEnriched2-0@2107
monitoringEnriched2-0@2108
monitoringEnriched2-0@2109
monitoringEnriched2-0@2110
monitoringEnriched2-0@2111
monitoringEnriched2-0@2112
monitoringEnriched2-0@2113
monitoringEnriched2-0@2114
monitoringEnriched2-0@2115
monitoringEnriched2-0@2116
monitoringEnriched2-0@2117
monitoringEnriched2-0@2118
monitoringEnriched2-0@2119
monitoringEnriched2-0@2120
monitoringEnriched2-0@2121
monitoringEnriched2-0@2122
monitoringEnriched2-0@2123
monitoringEnriched2-0@2124
monitoringEnriched2-0@2125
monitoringEnriched2-0@2126
monitoringEnriched2-0@2127
monitoringEnriched2-0@2128
monitoringEnriched2-0@2129
monitoringEnriched2-0@2130
monitoringEnriched2-0@2131
monitoringEnriched2-0@2132
monitoringEnriched2-0@2133
monitoringEnriched2-0@2134
monitoringEnriched2-0@2135
monitoringEnriched2-0@2136
monitoringEnriched2-0@2137
monitoringEnriched2-0@2138
monitoringEnriched2-0@2139
monitoringEnriched2-0@2140
monitoringEnriched2-0@2141
monitoringEnriched2-0@2142
monitoringEnriched2-0@2143
monitoringEnriched2-0@2144
monitoringEnriched2-0@2145
monitoringEnriched2-0@2146
monitoringEnriched2-0@2147
monitoringEnriched2-0@2148
monitoringEnriched2-0@2149
monitoringEnriched2-0@2150
monitoringEnriched2-0@2151
monitoringEnriched2-0@2152
monitoringEnriched2-0@2153
monitoringEnriched2-0@2154
monitoringEnriched2-0@2155
monitoringEnriched2-0@2156
monitoringEnriched2-0@2157
monitoringEnriched2-0@2158
monitoringEnriched2-0@2159
monitoringEnriched2-0@2160
monitoringEnriched2-0@2161
monitoringEnriched2-0@2162
monitoringEnriched2-0@2163
monitoringEnriched2-0@2164
monitoringEnriched2-0@2165
monitoringEnriched2-0@2166
monitoringEnriched2-0@2167
monitoringEnriched2-0@2168
monitoringEnriched2-0@2169
monitoringEnriched2-0@2170
monitoringEnriched2-0@2171
monitoringEnriched2-0@2172
monitoringEnriched2-0@2173
monitoringEnriched2-0@2174
monitoringEnriched2-0@2175
monitoringEnriched2-0@2176
monitoringEnriched2-0@2177
monitoringEnriched2-0@2178
monitoringEnriched2-0@2179
monitoringEnriched2-0@2180
monitoringEnriched2-0@2181
monitoringEnriched2-0@2182
monitoringEnriched2-0@2183
monitoringEnriched2-0@2184
monitoringEnriched2-0@2185
monitoringEnriched2-0@2186
monitoringEnriched2-0@2187
monitoringEnriched2-0@2188
monitoringEnriched2-0@2189
monitoringEnriched2-0@2190
monitoringEnriched2-0@2191
monitoringEnriched2-0@2192
monitoringEnriched2-0@2193
monitoringEnriched2-0@2194
monitoringEnriched2-0@2195
monitoringEnriched2-0@2196
monitoringEnriched2-0@2197
monitoringEnriched2-0@2198
monitoringEnriched2-0@2199
monitoringEnriched2-0@2200
monitoringEnriched2-0@2201
monitoringEnriched2-0@2202
monitoringEnriched2-0@2203
monitoringEnriched2-0@2204
monitoringEnriched2-0@2205
monitoringEnriched2-0@2206
monitoringEnriched2-0@2207
monitoringEnriched2-0@2208
monitoringEnriched2-0@2209
monitoringEnriched2-0@2210
monitoringEnriched2-0@2211
monitoringEnriched2-0@2212
monitoringEnriched2-0@2213
monitoringEnriched2-0@2214
monitoringEnriched2-0@2215
monitoringEnriched2-0@2216
monitoringEnriched2-0@2217
monitoringEnriched2-0@2218
monitoringEnriched2-0@2219
monitoringEnriched2-0@2220
monitoringEnriched2-0@2221
monitoringEnriched2-0@2222
monitoringEnriched2-0@2223
monitoringEnriched2-0@2224
monitoringEnriched2-0@2225
monitoringEnriched2-0@2226
monitoringEnriched2-0@2227
monitoringEnriched2-0@2228
monitoringEnriched2-0@2229
monitoringEnriched2-0@2230
monitoringEnriched2-0@2231
monitoringEnriched2-0@2232
monitoringEnriched2-0@2233
monitoringEnriched2-0@2234
monitoringEnriched2-0@2235
monitoringEnriched2-0@2236
monitoringEnriched2-0@2237
monitoringEnriched2-0@2238
monitoringEnriched2-0@2239
monitoringEnriched2-0@2240
monitoringEnriched2-0@2241
monitoringEnriched2-0@2242
monitoringEnriched2-0@2243
monitoringEnriched2-0@2244
monitoringEnriched2-0@2245
monitoringEnriched2-0@2246
monitoringEnriched2-0@2247
monitoringEnriched2-0@2248
monitoringEnriched2-0@2249
monitoringEnriched2-0@2250
monitoringEnriched2-0@2251
monitoringEnriched2-0@2252
monitoringEnriched2-0@2253
monitoringEnriched2-0@2254
monitoringEnriched2-0@2255
monitoringEnriched2-0@2256
monitoringEnriched2-0@2257
monitoringEnriched2-0@2258
monitoringEnriched2-0@2259
monitoringEnriched2-0@2260
monitoringEnriched2-0@2261
monitoringEnriched2-0@2262
monitoringEnriched2-0@2263
monitoringEnriched2-0@2264
monitoringEnriched2-0@2265
monitoringEnriched2-0@2266
monitoringEnriched2-0@2267
monitoringEnriched2-0@2268
monitoringEnriched2-0@2269
monitoringEnriched2-0@2270
monitoringEnriched2-0@2271
monitoringEnriched2-0@2272
monitoringEnriched2-0@2273
monitoringEnriched2-0@2274
monitoringEnriched2-0@2275
monitoringEnriched2-0@2276
monitoringEnriched2-0@2277
monitoringEnriched2-0@2278
monitoringEnriched2-0@2279
monitoringEnriched2-0@2280
monitoringEnriched2-0@2281
monitoringEnriched2-0@2282
monitoringEnriched2-0@2283
monitoringEnriched2-0@2284
monitoringEnriched2-0@2285
monitoringEnriched2-0@2286
monitoringEnriched2-0@2287
monitoringEnriched2-0@2288
monitoringEnriched2-0@2289
monitoringEnriched2-0@2290
monitoringEnriched2-0@2291
monitoringEnriched2-0@2292
monitoringEnriched2-0@2293
monitoringEnriched2-0@2294
monitoringEnriched2-0@2295
monitoringEnriched2-0@2296
monitoringEnriched2-0@2297
monitoringEnriched2-0@2298
monitoringEnriched2-0@2299
monitoringEnriched2-0@2300
monitoringEnriched2-0@2301
monitoringEnriched2-0@2302
monitoringEnriched2-0@2303
monitoringEnriched2-0@2304
monitoringEnriched2-0@2305
monitoringEnriched2-0@2306
monitoringEnriched2-0@2307
monitoringEnriched2-0@2308
monitoringEnriched2-0@2309
monitoringEnriched2-0@2310
monitoringEnriched2-0@2311
monitoringEnriched2-0@2312
monitoringEnriched2-0@2313
monitoringEnriched2-0@2314
monitoringEnriched2-0@2315
monitoringEnriched2-0@2316
monitoringEnriched2-0@2317
monitoringEnriched2-0@2318
monitoringEnriched2-0@2319
monitoringEnriched2-0@2320
monitoringEnriched2-0@2321
monitoringEnriched2-0@2322
monitoringEnriched2-0@2323
monitoringEnriched2-0@2324
monitoringEnriched2-0@2325
monitoringEnriched2-0@2326
monitoringEnriched2-0@2327
monitoringEnriched2-0@2328
monitoringEnriched2-0@2329
monitoringEnriched2-0@2330
monitoringEnriched2-0@2331
monitoringEnriched2-0@2332
monitoringEnriched2-0@2333
monitoringEnriched2-0@2334
monitoringEnriched2-0@2335
monitoringEnriched2-0@2336
monitoringEnriched2-0@2337
monitoringEnriched2-0@2338
monitoringEnriched2-0@2339
monitoringEnriched2-0@2340
monitoringEnriched2-0@2341
monitoringEnriched2-0@2342
monitoringEnriched2-0@2343
monitoringEnriched2-0@2344
monitoringEnriched2-0@2345
monitoringEnriched2-0@2346
monitoringEnriched2-0@2347
monitoringEnriched2-0@2348
monitoringEnriched2-0@2349
monitoringEnriched2-0@2350
monitoringEnriched2-0@2351
monitoringEnriched2-0@2352
monitoringEnriched2-0@2353
monitoringEnriched2-0@2354
monitoringEnriched2-0@2355
monitoringEnriched2-0@2356
monitoringEnriched2-0@2357
monitoringEnriched2-0@2358
monitoringEnriched2-0@2359
monitoringEnriched2-0@2360
monitoringEnriched2-0@2361
monitoringEnriched2-0@2362
monitoringEnriched2-0@2363
monitoringEnriched2-0@2364
monitoringEnriched2-0@2365
monitoringEnriched2-0@2366
monitoringEnriched2-0@2367
monitoringEnriched2-0@2368
monitoringEnriched2-0@2369
monitoringEnriched2-0@2370
monitoringEnriched2-0@2371
monitoringEnriched2-0@2372
monitoringEnriched2-0@2373
monitoringEnriched2-0@2374
monitoringEnriched2-0@2375
monitoringEnriched2-0@2376
monitoringEnriched2-0@2377
monitoringEnriched2-0@2378
monitoringEnriched2-0@2379
monitoringEnriched2-0@2380
monitoringEnriched2-0@2381
monitoringEnriched2-0@2382
monitoringEnriched2-0@2383
monitoringEnriched2-0@2384
monitoringEnriched2-0@2385
monitoringEnriched2-0@2386
monitoringEnriched2-0@2387
monitoringEnriched2-0@2388
monitoringEnriched2-0@2389
monitoringEnriched2-0@2390
monitoringEnriched2-0@2391
monitoringEnriched2-0@2392
monitoringEnriched2-0@2393
monitoringEnriched2-0@2394
monitoringEnriched2-0@2395
monitoringEnriched2-0@2396
monitoringEnriched2-0@2397
monitoringEnriched2-0@2398
monitoringEnriched2-0@2399
monitoringEnriched2-0@2400
monitoringEnriched2-0@2401
monitoringEnriched2-0@2402
monitoringEnriched2-0@2403
monitoringEnriched2-0@2404
monitoringEnriched2-0@2405
monitoringEnriched2-0@2406
monitoringEnriched2-0@2407
monitoringEnriched2-0@2408
monitoringEnriched2-0@2409
monitoringEnriched2-0@2410
monitoringEnriched2-0@2411
monitoringEnriched2-0@2412
monitoringEnriched2-0@2413
monitoringEnriched2-0@2414
monitoringEnriched2-0@2415
monitoringEnriched2-0@2416
monitoringEnriched2-0@2417
monitoringEnriched2-0@2418
monitoringEnriched2-0@2419
monitoringEnriched2-0@2420
monitoringEnriched2-0@2421
monitoringEnriched2-0@2422
monitoringEnriched2-0@2423
monitoringEnriched2-0@2424
monitoringEnriched2-0@2425
monitoringEnriched2-0@2426
monitoringEnriched2-0@2427
monitoringEnriched2-0@2428
monitoringEnriched2-0@2429
monitoringEnriched2-0@2430
monitoringEnriched2-0@2431
monitoringEnriched2-0@2432
monitoringEnriched2-0@2433
monitoringEnriched2-0@2434
monitoringEnriched2-0@2435
monitoringEnriched2-0@2436
monitoringEnriched2-0@2437
monitoringEnriched2-0@2438
monitoringEnriched2-0@2439
monitoringEnriched2-0@2440
monitoringEnriched2-0@2441
monitoringEnriched2-0@2442
monitoringEnriched2-0@2443
monitoringEnriched2-0@2444
monitoringEnriched2-0@2445
monitoringEnriched2-0@2446
monitoringEnriched2-0@2447
monitoringEnriched2-0@2448
monitoringEnriched2-0@2449
monitoringEnriched2-0@2450
monitoringEnriched2-0@2451
monitoringEnriched2-0@2452
monitoringEnriched2-0@2453
monitoringEnriched2-0@2454
monitoringEnriched2-0@2455
monitoringEnriched2-0@2456
monitoringEnriched2-0@2457
monitoringEnriched2-0@2458
monitoringEnriched2-0@2459
monitoringEnriched2-0@2460
monitoringEnriched2-0@2461
monitoringEnriched2-0@2462
monitoringEnriched2-0@2463
monitoringEnriched2-0@2464
monitoringEnriched2-0@2465
monitoringEnriched2-0@2466
monitoringEnriched2-0@2467
monitoringEnriched2-0@2468
monitoringEnriched2-0@2469
monitoringEnriched2-0@2470
monitoringEnriched2-0@2471
monitoringEnriched2-0@2472
monitoringEnriched2-0@2473
monitoringEnriched2-0@2474
monitoringEnriched2-0@2475
monitoringEnriched2-0@2476
monitoringEnriched2-0@2477
monitoringEnriched2-0@2478
monitoringEnriched2-0@2479
monitoringEnriched2-0@2480
monitoringEnriched2-0@2481
monitoringEnriched2-0@2482
monitoringEnriched2-0@2483
monitoringEnriched2-0@2484
monitoringEnriched2-0@2485
monitoringEnriched2-0@2486
monitoringEnriched2-0@2487
monitoringEnriched2-0@2488
monitoringEnriched2-0@2489
monitoringEnriched2-0@2490
monitoringEnriched2-0@2491
monitoringEnriched2-0@2492
monitoringEnriched2-0@2493
monitoringEnriched2-0@2494
monitoringEnriched2-0@2495
monitoringEnriched2-0@2496
monitoringEnriched2-0@2497
monitoringEnriched2-0@2498
monitoringEnriched2-0@2499
monitoringEnriched2-0@2500
monitoringEnriched2-0@2501
monitoringEnriched2-0@2502
monitoringEnriched2-0@2503
monitoringEnriched2-0@2504
monitoringEnriched2-0@2505
monitoringEnriched2-0@2506
monitoringEnriched2-0@2507
monitoringEnriched2-0@2508
monitoringEnriched2-0@2509
monitoringEnriched2-0@2510
monitoringEnriched2-0@2511
monitoringEnriched2-0@2512
monitoringEnriched2-0@2513
monitoringEnriched2-0@2514
monitoringEnriched2-0@2515
monitoringEnriched2-0@2516
monitoringEnriched2-0@2517
monitoringEnriched2-0@2518
monitoringEnriched2-0@2519
monitoringEnriched2-0@2520
monitoringEnriched2-0@2521
monitoringEnriched2-0@2522
monitoringEnriched2-0@2523
monitoringEnriched2-0@2524
monitoringEnriched2-0@2525
monitoringEnriched2-0@2526
monitoringEnriched2-0@2527
monitoringEnriched2-0@2528
monitoringEnriched2-0@2529
monitoringEnriched2-0@2530
monitoringEnriched2-0@2531
monitoringEnriched2-0@2532
monitoringEnriched2-0@2533
monitoringEnriched2-0@2534
monitoringEnriched2-0@2535
monitoringEnriched2-0@2536
monitoringEnriched2-0@2537
monitoringEnriched2-0@2538
monitoringEnriched2-0@2539
monitoringEnriched2-0@2540
monitoringEnriched2-0@2541
monitoringEnriched2-0@2542
monitoringEnriched2-0@2543
monitoringEnriched2-0@2544
monitoringEnriched2-0@2545
monitoringEnriched2-0@2546
monitoringEnriched2-0@2547
monitoringEnriched2-0@2548
monitoringEnriched2-0@2549
monitoringEnriched2-0@2550
monitoringEnriched2-0@2551
monitoringEnriched2-0@2552
monitoringEnriched2-0@2553
monitoringEnriched2-0@2554
monitoringEnriched2-0@2555
monitoringEnriched2-0@2556
monitoringEnriched2-0@2557
monitoringEnriched2-0@2558
monitoringEnriched2-0@2559
monitoringEnriched2-0@2560
monitoringEnriched2-0@2561
monitoringEnriched2-0@2562
monitoringEnriched2-0@2563
monitoringEnriched2-0@2564
monitoringEnriched2-0@2565
monitoringEnriched2-0@2566
monitoringEnriched2-0@2567
monitoringEnriched2-0@2568
monitoringEnriched2-0@2569
monitoringEnriched2-0@2570
monitoringEnriched2-0@2571
monitoringEnriched2-0@2572
monitoringEnriched2-0@2573
monitoringEnriched2-0@2574
monitoringEnriched2-0@2575
monitoringEnriched2-0@2576
monitoringEnriched2-0@2577
monitoringEnriched2-0@2578
monitoringEnriched2-0@2579
monitoringEnriched2-0@2580
monitoringEnriched2-0@2581
monitoringEnriched2-0@2582
monitoringEnriched2-0@2583
monitoringEnriched2-0@2584
monitoringEnriched2-0@2585
monitoringEnriched2-0@2586
monitoringEnriched2-0@2587
monitoringEnriched2-0@2588
monitoringEnriched2-0@2589
monitoringEnriched2-0@2590
monitoringEnriched2-0@2591
monitoringEnriched2-0@2592
monitoringEnriched2-0@2593
monitoringEnriched2-0@2594
monitoringEnriched2-0@2595
monitoringEnriched2-0@2596
monitoringEnriched2-0@2597
monitoringEnriched2-0@2598
monitoringEnriched2-0@2599
monitoringEnriched2-0@2600
monitoringEnriched2-0@2601
monitoringEnriched2-0@2602
monitoringEnriched2-0@2603
monitoringEnriched2-0@2604
monitoringEnriched2-0@2605
monitoringEnriched2-0@2606
monitoringEnriched2-0@2607
monitoringEnriched2-0@2608
monitoringEnriched2-0@2609
monitoringEnriched2-0@2610
monitoringEnriched2-0@2611
monitoringEnriched2-0@2612
monitoringEnriched2-0@2613
monitoringEnriched2-0@2614
monitoringEnriched2-0@2615
monitoringEnriched2-0@2616
monitoringEnriched2-0@2617
monitoringEnriched2-0@2618
monitoringEnriched2-0@2619
monitoringEnriched2-0@2620
monitoringEnriched2-0@2621
monitoringEnriched2-0@2622
monitoringEnriched2-0@2623
monitoringEnriched2-0@2624
monitoringEnriched2-0@2625
monitoringEnriched2-0@2626
monitoringEnriched2-0@2627
monitoringEnriched2-0@2628
monitoringEnriched2-0@2629
monitoringEnriched2-0@2630
monitoringEnriched2-0@2631
monitoringEnriched2-0@2632
monitoringEnriched2-0@2633
monitoringEnriched2-0@2634
monitoringEnriched2-0@2635
monitoringEnriched2-0@2636
monitoringEnriched2-0@2637
monitoringEnriched2-0@2638
monitoringEnriched2-0@2639
monitoringEnriched2-0@2640
monitoringEnriched2-0@2641
monitoringEnriched2-0@2642
monitoringEnriched2-0@2643
monitoringEnriched2-0@2644
monitoringEnriched2-0@2645
monitoringEnriched2-0@2646
monitoringEnriched2-0@2647
monitoringEnriched2-0@2648
monitoringEnriched2-0@2649
monitoringEnriched2-0@2650
monitoringEnriched2-0@2651
monitoringEnriched2-0@2652
monitoringEnriched2-0@2653
monitoringEnriched2-0@2654
monitoringEnriched2-0@2655
monitoringEnriched2-0@2656
monitoringEnriched2-0@2657
monitoringEnriched2-0@2658
monitoringEnriched2-0@2659
monitoringEnriched2-0@2660
monitoringEnriched2-0@2661
monitoringEnriched2-0@2662
monitoringEnriched2-0@2663
monitoringEnriched2-0@2664
monitoringEnriched2-0@2665
monitoringEnriched2-0@2666
monitoringEnriched2-0@2667
monitoringEnriched2-0@2668
monitoringEnriched2-0@2669
monitoringEnriched2-0@2670
monitoringEnriched2-0@2671
monitoringEnriched2-0@2672
monitoringEnriched2-0@2673
monitoringEnriched2-0@2674
monitoringEnriched2-0@2675
monitoringEnriched2-0@2676
monitoringEnriched2-0@2677
monitoringEnriched2-0@2678
monitoringEnriched2-0@2679
monitoringEnriched2-0@2680
monitoringEnriched2-0@2681
monitoringEnriched2-0@2682
monitoringEnriched2-0@2683
monitoringEnriched2-0@2684
monitoringEnriched2-0@2685
monitoringEnriched2-0@2686
monitoringEnriched2-0@2687
monitoringEnriched2-0@2688
monitoringEnriched2-0@2689
monitoringEnriched2-0@2690
monitoringEnriched2-0@2691
monitoringEnriched2-0@2692
monitoringEnriched2-0@2693
monitoringEnriched2-0@2694
monitoringEnriched2-0@2695
monitoringEnriched2-0@2696
monitoringEnriched2-0@2697
monitoringEnriched2-0@2698
monitoringEnriched2-0@2699
monitoringEnriched2-0@2700
monitoringEnriched2-0@2701
monitoringEnriched2-0@2702
monitoringEnriched2-0@2703
monitoringEnriched2-0@2704
monitoringEnriched2-0@2705
monitoringEnriched2-0@2706
monitoringEnriched2-0@2707
monitoringEnriched2-0@2708
monitoringEnriched2-0@2709
monitoringEnriched2-0@2710
monitoringEnriched2-0@2711
monitoringEnriched2-0@2712
monitoringEnriched2-0@2713
monitoringEnriched2-0@2714
monitoringEnriched2-0@2715
monitoringEnriched2-0@2716
monitoringEnriched2-0@2717
monitoringEnriched2-0@2718
monitoringEnriched2-0@2719
monitoringEnriched2-0@2720
monitoringEnriched2-0@2721
monitoringEnriched2-0@2722
monitoringEnriched2-0@2723
monitoringEnriched2-0@2724
monitoringEnriched2-0@2725
monitoringEnriched2-0@2726
monitoringEnriched2-0@2727
monitoringEnriched2-0@2728
monitoringEnriched2-0@2729
monitoringEnriched2-0@2730
monitoringEnriched2-0@2731
monitoringEnriched2-0@2732
monitoringEnriched2-0@2733
monitoringEnriched2-0@2734
monitoringEnriched2-0@2735
monitoringEnriched2-0@2736
monitoringEnriched2-0@2737
monitoringEnriched2-0@2738
monitoringEnriched2-0@2739
monitoringEnriched2-0@2740
monitoringEnriched2-0@2741
monitoringEnriched2-0@2742
monitoringEnriched2-0@2743
monitoringEnriched2-0@2744
monitoringEnriched2-0@2745
monitoringEnriched2-0@2746
monitoringEnriched2-0@2747
monitoringEnriched2-0@2748
monitoringEnriched2-0@2749
monitoringEnriched2-0@2750
monitoringEnriched2-0@2751
monitoringEnriched2-0@2752
monitoringEnriched2-0@2753
monitoringEnriched2-0@2754
monitoringEnriched2-0@2755
monitoringEnriched2-0@2756
monitoringEnriched2-0@2757
monitoringEnriched2-0@2758
monitoringEnriched2-0@2759
monitoringEnriched2-0@2760
monitoringEnriched2-0@2761
monitoringEnriched2-0@2762
monitoringEnriched2-0@2763
monitoringEnriched2-0@2764
monitoringEnriched2-0@2765
monitoringEnriched2-0@2766
monitoringEnriched2-0@2767
monitoringEnriched2-0@2768
monitoringEnriched2-0@2769
monitoringEnriched2-0@2770
monitoringEnriched2-0@2771
monitoringEnriched2-0@2772
monitoringEnriched2-0@2773
monitoringEnriched2-0@2774
monitoringEnriched2-0@2775
monitoringEnriched2-0@2776
monitoringEnriched2-0@2777
monitoringEnriched2-0@2778
monitoringEnriched2-0@2779
monitoringEnriched2-0@2780
18/09/28 21:40:36 INFO KafkaProducer: Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/09/28 21:40:36 INFO Executor: Finished task 2.0 in stage 3.0 (TID 13). 1052 bytes result sent to driver
18/09/28 21:40:36 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 13) in 14983 ms on localhost (executor driver) (4/4)
18/09/28 21:40:36 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
18/09/28 21:40:36 INFO DAGScheduler: ResultStage 3 (foreachPartition at AnomalyDetector.java:63) finished in 15,004 s
18/09/28 21:40:36 INFO DAGScheduler: Job 0 finished: foreachPartition at AnomalyDetector.java:63, took 15,884762 s
18/09/28 21:40:36 INFO JobScheduler: Finished job streaming job 1538160020000 ms.0 from job set of time 1538160020000 ms
18/09/28 21:40:36 INFO JobScheduler: Total delay: 16,041 s for time 1538160020000 ms (execution: 15,914 s)
18/09/28 21:40:36 INFO JobScheduler: Starting job streaming job 1538160030000 ms.0 from job set of time 1538160030000 ms
18/09/28 21:40:36 INFO JobGenerator: Checkpointing graph for time 1538160020000 ms
18/09/28 21:40:36 INFO DStreamGraph: Updating checkpoint data for time 1538160020000 ms
18/09/28 21:40:36 INFO DStreamGraph: Updated checkpoint data for time 1538160020000 ms
18/09/28 21:40:36 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:63
18/09/28 21:40:36 INFO DAGScheduler: Registering RDD 14 (mapToPair at AnomalyDetector.java:58)
18/09/28 21:40:36 INFO CheckpointWriter: Submitted checkpoint of time 1538160020000 ms to writer queue
18/09/28 21:40:36 INFO CheckpointWriter: Saving checkpoint for time 1538160020000 ms to file 'file:/C:/Users/serez/Desktop/bigdata-training-master-cb197815c41507f3ead62de529732ac73879a99a/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1538160030000'
18/09/28 21:40:36 INFO DAGScheduler: Got job 1 (foreachPartition at AnomalyDetector.java:63) with 4 output partitions
18/09/28 21:40:36 INFO DAGScheduler: Final stage: ResultStage 8 (foreachPartition at AnomalyDetector.java:63)
18/09/28 21:40:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5, ShuffleMapStage 6, ShuffleMapStage 7, ShuffleMapStage 4)
18/09/28 21:40:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
18/09/28 21:40:36 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[14] at mapToPair at AnomalyDetector.java:58), which has no missing parents
18/09/28 21:40:36 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.3 KB, free 1749.3 MB)
18/09/28 21:40:36 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.1 KB, free 1749.3 MB)
18/09/28 21:40:36 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 3.1 KB, free: 1749.3 MB)
18/09/28 21:40:36 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1039
18/09/28 21:40:36 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[14] at mapToPair at AnomalyDetector.java:58) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
18/09/28 21:40:36 INFO TaskSchedulerImpl: Adding task set 4.0 with 10 tasks
18/09/28 21:40:36 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:36 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 15, localhost, executor driver, partition 1, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:36 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 16, localhost, executor driver, partition 2, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:36 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 17, localhost, executor driver, partition 3, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:36 INFO Executor: Running task 0.0 in stage 4.0 (TID 14)
18/09/28 21:40:36 INFO Executor: Running task 2.0 in stage 4.0 (TID 16)
18/09/28 21:40:36 INFO Executor: Running task 1.0 in stage 4.0 (TID 15)
18/09/28 21:40:36 INFO Executor: Running task 3.0 in stage 4.0 (TID 17)
18/09/28 21:40:36 INFO KafkaRDD: Beginning offset 1 is the same as ending offset skipping monitoring20 9
18/09/28 21:40:36 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping monitoring20 6
18/09/28 21:40:36 INFO MemoryStore: Block rdd_13_2 stored as bytes in memory (estimated size 4.0 B, free 1749.3 MB)
18/09/28 21:40:36 INFO MemoryStore: Block rdd_13_0 stored as bytes in memory (estimated size 4.0 B, free 1749.3 MB)
18/09/28 21:40:36 INFO BlockManagerInfo: Added rdd_13_2 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1749.3 MB)
18/09/28 21:40:36 INFO BlockManagerInfo: Added rdd_13_0 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1749.3 MB)
18/09/28 21:40:36 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping monitoring20 4
18/09/28 21:40:36 INFO MemoryStore: Block rdd_13_3 stored as bytes in memory (estimated size 4.0 B, free 1749.3 MB)
18/09/28 21:40:36 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping monitoring20 3
18/09/28 21:40:36 INFO BlockManagerInfo: Added rdd_13_3 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1749.3 MB)
18/09/28 21:40:36 INFO Executor: Finished task 2.0 in stage 4.0 (TID 16). 740 bytes result sent to driver
18/09/28 21:40:36 INFO MemoryStore: Block rdd_13_1 stored as bytes in memory (estimated size 4.0 B, free 1749.3 MB)
18/09/28 21:40:36 INFO BlockManagerInfo: Added rdd_13_1 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1749.3 MB)
18/09/28 21:40:36 INFO Executor: Finished task 0.0 in stage 4.0 (TID 14). 740 bytes result sent to driver
18/09/28 21:40:36 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 18, localhost, executor driver, partition 4, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:36 INFO Executor: Running task 4.0 in stage 4.0 (TID 18)
18/09/28 21:40:36 INFO TaskSetManager: Starting task 5.0 in stage 4.0 (TID 19, localhost, executor driver, partition 5, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:36 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 14) in 23 ms on localhost (executor driver) (1/10)
18/09/28 21:40:36 INFO Executor: Running task 5.0 in stage 4.0 (TID 19)
18/09/28 21:40:36 INFO Executor: Finished task 1.0 in stage 4.0 (TID 15). 697 bytes result sent to driver
18/09/28 21:40:36 INFO TaskSetManager: Starting task 6.0 in stage 4.0 (TID 20, localhost, executor driver, partition 6, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:36 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 16) in 26 ms on localhost (executor driver) (2/10)
18/09/28 21:40:36 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping monitoring20 8
18/09/28 21:40:36 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 15) in 27 ms on localhost (executor driver) (3/10)
18/09/28 21:40:36 INFO MemoryStore: Block rdd_13_4 stored as bytes in memory (estimated size 4.0 B, free 1749.3 MB)
18/09/28 21:40:36 INFO Executor: Running task 6.0 in stage 4.0 (TID 20)
18/09/28 21:40:36 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping monitoring20 7
18/09/28 21:40:36 INFO MemoryStore: Block rdd_13_5 stored as bytes in memory (estimated size 4.0 B, free 1749.3 MB)
18/09/28 21:40:36 INFO BlockManagerInfo: Added rdd_13_4 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1749.3 MB)
18/09/28 21:40:36 INFO Executor: Finished task 3.0 in stage 4.0 (TID 17). 697 bytes result sent to driver
18/09/28 21:40:36 INFO BlockManagerInfo: Added rdd_13_5 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1749.3 MB)
18/09/28 21:40:36 INFO KafkaRDD: Beginning offset 25983 is the same as ending offset skipping monitoring20 0
18/09/28 21:40:36 INFO MemoryStore: Block rdd_13_6 stored as bytes in memory (estimated size 4.0 B, free 1749.3 MB)
18/09/28 21:40:36 INFO TaskSetManager: Starting task 7.0 in stage 4.0 (TID 21, localhost, executor driver, partition 7, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:36 INFO BlockManagerInfo: Added rdd_13_6 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1749.3 MB)
18/09/28 21:40:36 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 17) in 33 ms on localhost (executor driver) (4/10)
18/09/28 21:40:36 INFO Executor: Running task 7.0 in stage 4.0 (TID 21)
18/09/28 21:40:36 INFO Executor: Finished task 5.0 in stage 4.0 (TID 19). 740 bytes result sent to driver
18/09/28 21:40:36 INFO Executor: Finished task 4.0 in stage 4.0 (TID 18). 697 bytes result sent to driver
18/09/28 21:40:36 INFO TaskSetManager: Starting task 8.0 in stage 4.0 (TID 22, localhost, executor driver, partition 8, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:36 INFO Executor: Running task 8.0 in stage 4.0 (TID 22)
18/09/28 21:40:36 INFO TaskSetManager: Finished task 5.0 in stage 4.0 (TID 19) in 17 ms on localhost (executor driver) (5/10)
18/09/28 21:40:36 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping monitoring20 2
18/09/28 21:40:36 INFO Executor: Finished task 6.0 in stage 4.0 (TID 20). 697 bytes result sent to driver
18/09/28 21:40:36 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping monitoring20 1
18/09/28 21:40:36 INFO TaskSetManager: Starting task 9.0 in stage 4.0 (TID 23, localhost, executor driver, partition 9, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:36 INFO MemoryStore: Block rdd_13_7 stored as bytes in memory (estimated size 4.0 B, free 1749.3 MB)
18/09/28 21:40:36 INFO MemoryStore: Block rdd_13_8 stored as bytes in memory (estimated size 4.0 B, free 1749.3 MB)
18/09/28 21:40:36 INFO BlockManagerInfo: Added rdd_13_7 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1749.3 MB)
18/09/28 21:40:36 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 18) in 28 ms on localhost (executor driver) (6/10)
18/09/28 21:40:36 INFO Executor: Running task 9.0 in stage 4.0 (TID 23)
18/09/28 21:40:36 INFO BlockManagerInfo: Added rdd_13_8 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1749.3 MB)
18/09/28 21:40:36 INFO TaskSetManager: Finished task 6.0 in stage 4.0 (TID 20) in 17 ms on localhost (executor driver) (7/10)
18/09/28 21:40:36 INFO Executor: Finished task 8.0 in stage 4.0 (TID 22). 740 bytes result sent to driver
18/09/28 21:40:36 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping monitoring20 5
18/09/28 21:40:36 INFO MemoryStore: Block rdd_13_9 stored as bytes in memory (estimated size 4.0 B, free 1749.3 MB)
18/09/28 21:40:36 INFO Executor: Finished task 7.0 in stage 4.0 (TID 21). 740 bytes result sent to driver
18/09/28 21:40:36 INFO BlockManagerInfo: Added rdd_13_9 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1749.3 MB)
18/09/28 21:40:36 INFO TaskSetManager: Finished task 8.0 in stage 4.0 (TID 22) in 13 ms on localhost (executor driver) (8/10)
18/09/28 21:40:36 INFO TaskSetManager: Finished task 7.0 in stage 4.0 (TID 21) in 20 ms on localhost (executor driver) (9/10)
18/09/28 21:40:36 INFO Executor: Finished task 9.0 in stage 4.0 (TID 23). 697 bytes result sent to driver
18/09/28 21:40:36 INFO TaskSetManager: Finished task 9.0 in stage 4.0 (TID 23) in 15 ms on localhost (executor driver) (10/10)
18/09/28 21:40:36 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
18/09/28 21:40:36 INFO DAGScheduler: ShuffleMapStage 4 (mapToPair at AnomalyDetector.java:58) finished in 0,067 s
18/09/28 21:40:36 INFO DAGScheduler: looking for newly runnable stages
18/09/28 21:40:36 INFO DAGScheduler: running: Set()
18/09/28 21:40:36 INFO DAGScheduler: waiting: Set(ResultStage 8)
18/09/28 21:40:36 INFO DAGScheduler: failed: Set()
18/09/28 21:40:36 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[17] at mapWithState at AnomalyDetector.java:61), which has no missing parents
18/09/28 21:40:36 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.3 KB, free 1749.3 MB)
18/09/28 21:40:36 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.2 KB, free 1749.3 MB)
18/09/28 21:40:36 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 3.2 KB, free: 1749.3 MB)
18/09/28 21:40:36 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1039
18/09/28 21:40:36 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 8 (MapPartitionsRDD[17] at mapWithState at AnomalyDetector.java:61) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/09/28 21:40:36 INFO TaskSchedulerImpl: Adding task set 8.0 with 4 tasks
18/09/28 21:40:36 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 7868 bytes)
18/09/28 21:40:36 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 25, localhost, executor driver, partition 1, PROCESS_LOCAL, 7868 bytes)
18/09/28 21:40:36 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 26, localhost, executor driver, partition 2, PROCESS_LOCAL, 7868 bytes)
18/09/28 21:40:36 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 27, localhost, executor driver, partition 3, PROCESS_LOCAL, 7868 bytes)
18/09/28 21:40:36 INFO Executor: Running task 0.0 in stage 8.0 (TID 24)
18/09/28 21:40:36 INFO Executor: Running task 2.0 in stage 8.0 (TID 26)
18/09/28 21:40:36 INFO Executor: Running task 3.0 in stage 8.0 (TID 27)
18/09/28 21:40:36 INFO Executor: Running task 1.0 in stage 8.0 (TID 25)
18/09/28 21:40:36 INFO BlockManager: Found block rdd_10_2 locally
18/09/28 21:40:36 INFO BlockManager: Found block rdd_10_0 locally
18/09/28 21:40:36 INFO BlockManager: Found block rdd_10_1 locally
18/09/28 21:40:36 INFO BlockManager: Found block rdd_10_3 locally
18/09/28 21:40:36 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 10 blocks
18/09/28 21:40:36 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 10 blocks
18/09/28 21:40:36 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 10 blocks
18/09/28 21:40:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/09/28 21:40:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/09/28 21:40:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/09/28 21:40:36 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 10 blocks
18/09/28 21:40:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/09/28 21:40:36 INFO MemoryStore: Block rdd_16_0 stored as values in memory (estimated size 3.2 KB, free 1749.3 MB)
18/09/28 21:40:36 INFO MemoryStore: Block rdd_16_1 stored as values in memory (estimated size 3.2 KB, free 1749.3 MB)
18/09/28 21:40:36 INFO MemoryStore: Block rdd_16_3 stored as values in memory (estimated size 3.2 KB, free 1749.3 MB)
18/09/28 21:40:36 INFO BlockManagerInfo: Added rdd_16_0 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 3.2 KB, free: 1749.3 MB)
18/09/28 21:40:36 INFO BlockManagerInfo: Added rdd_16_1 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 3.2 KB, free: 1749.3 MB)
18/09/28 21:40:36 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/09/28 21:40:36 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/09/28 21:40:36 INFO BlockManagerInfo: Added rdd_16_3 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 3.2 KB, free: 1749.3 MB)
18/09/28 21:40:36 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/09/28 21:40:36 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-5
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/09/28 21:40:36 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-6
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/09/28 21:40:36 INFO AppInfoParser: Kafka version : 0.10.0.1
18/09/28 21:40:36 INFO AppInfoParser: Kafka version : 0.10.0.1
18/09/28 21:40:36 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/09/28 21:40:36 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/09/28 21:40:36 INFO KafkaProducer: Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/09/28 21:40:36 INFO KafkaProducer: Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/09/28 21:40:36 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-7
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/09/28 21:40:36 INFO AppInfoParser: Kafka version : 0.10.0.1
18/09/28 21:40:36 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/09/28 21:40:36 INFO KafkaProducer: Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/09/28 21:40:36 INFO Executor: 1 block locks were not released by TID = 25:
[rdd_10_1]
18/09/28 21:40:36 INFO Executor: 1 block locks were not released by TID = 24:
[rdd_10_0]
18/09/28 21:40:36 INFO Executor: Finished task 0.0 in stage 8.0 (TID 24). 1052 bytes result sent to driver
18/09/28 21:40:36 INFO Executor: 1 block locks were not released by TID = 27:
[rdd_10_3]
18/09/28 21:40:36 INFO Executor: Finished task 1.0 in stage 8.0 (TID 25). 1052 bytes result sent to driver
18/09/28 21:40:36 INFO Executor: Finished task 3.0 in stage 8.0 (TID 27). 1052 bytes result sent to driver
18/09/28 21:40:36 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 24) in 34 ms on localhost (executor driver) (1/4)
18/09/28 21:40:36 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 27) in 32 ms on localhost (executor driver) (2/4)
18/09/28 21:40:36 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 25) in 33 ms on localhost (executor driver) (3/4)
18/09/28 21:40:36 INFO CheckpointWriter: Deleting file:/C:/Users/serez/Desktop/bigdata-training-master-cb197815c41507f3ead62de529732ac73879a99a/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1538159830000
18/09/28 21:40:36 INFO CheckpointWriter: Checkpoint for time 1538160020000 ms saved to file 'file:/C:/Users/serez/Desktop/bigdata-training-master-cb197815c41507f3ead62de529732ac73879a99a/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1538160030000', took 6245 bytes and 152 ms
18/09/28 21:40:36 INFO DStreamGraph: Clearing checkpoint data for time 1538160020000 ms
18/09/28 21:40:36 INFO DStreamGraph: Cleared checkpoint data for time 1538160020000 ms
18/09/28 21:40:36 INFO ReceivedBlockTracker: Deleting batches: 
18/09/28 21:40:36 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/C:/Users/serez/Desktop/bigdata-training-master-cb197815c41507f3ead62de529732ac73879a99a/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1538159820000: 
18/09/28 21:40:36 INFO InputInfoTracker: remove old batch metadata: 
18/09/28 21:40:36 INFO MemoryStore: Block rdd_16_2 stored as values in memory (estimated size 240.3 MB, free 1509.0 MB)
18/09/28 21:40:36 INFO BlockManagerInfo: Added rdd_16_2 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 240.3 MB, free: 1509.0 MB)
18/09/28 21:40:36 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/09/28 21:40:36 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-8
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/09/28 21:40:36 INFO AppInfoParser: Kafka version : 0.10.0.1
18/09/28 21:40:36 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/09/28 21:40:36 INFO KafkaProducer: Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/09/28 21:40:36 INFO Executor: 1 block locks were not released by TID = 26:
[rdd_10_2]
18/09/28 21:40:36 INFO Executor: Finished task 2.0 in stage 8.0 (TID 26). 1052 bytes result sent to driver
18/09/28 21:40:36 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 26) in 795 ms on localhost (executor driver) (4/4)
18/09/28 21:40:36 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
18/09/28 21:40:36 INFO DAGScheduler: ResultStage 8 (foreachPartition at AnomalyDetector.java:63) finished in 0,802 s
18/09/28 21:40:36 INFO DAGScheduler: Job 1 finished: foreachPartition at AnomalyDetector.java:63, took 0,883412 s
18/09/28 21:40:36 INFO JobScheduler: Finished job streaming job 1538160030000 ms.0 from job set of time 1538160030000 ms
18/09/28 21:40:36 INFO JobScheduler: Total delay: 6,934 s for time 1538160030000 ms (execution: 0,890 s)
18/09/28 21:40:36 INFO MapPartitionsRDD: Removing RDD 11 from persistence list
18/09/28 21:40:36 INFO BlockManager: Removing RDD 11
18/09/28 21:40:36 INFO JobGenerator: Checkpointing graph for time 1538160030000 ms
18/09/28 21:40:36 INFO DStreamGraph: Updating checkpoint data for time 1538160030000 ms
18/09/28 21:40:36 INFO DStreamGraph: Updated checkpoint data for time 1538160030000 ms
18/09/28 21:40:36 INFO CheckpointWriter: Submitted checkpoint of time 1538160030000 ms to writer queue
18/09/28 21:40:36 INFO CheckpointWriter: Saving checkpoint for time 1538160030000 ms to file 'file:/C:/Users/serez/Desktop/bigdata-training-master-cb197815c41507f3ead62de529732ac73879a99a/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1538160030000'
18/09/28 21:40:37 INFO CheckpointWriter: Checkpoint for time 1538160030000 ms saved to file 'file:/C:/Users/serez/Desktop/bigdata-training-master-cb197815c41507f3ead62de529732ac73879a99a/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1538160030000', took 6243 bytes and 79 ms
18/09/28 21:40:37 INFO DStreamGraph: Clearing checkpoint data for time 1538160030000 ms
18/09/28 21:40:37 INFO DStreamGraph: Cleared checkpoint data for time 1538160030000 ms
18/09/28 21:40:37 INFO ReceivedBlockTracker: Deleting batches: 
18/09/28 21:40:37 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/C:/Users/serez/Desktop/bigdata-training-master-cb197815c41507f3ead62de529732ac73879a99a/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1538159830000: 
18/09/28 21:40:37 INFO InputInfoTracker: remove old batch metadata: 
18/09/28 21:40:40 INFO JobScheduler: Added jobs for time 1538160040000 ms
18/09/28 21:40:40 INFO JobGenerator: Checkpointing graph for time 1538160040000 ms
18/09/28 21:40:40 INFO DStreamGraph: Updating checkpoint data for time 1538160040000 ms
18/09/28 21:40:40 INFO JobScheduler: Starting job streaming job 1538160040000 ms.0 from job set of time 1538160040000 ms
18/09/28 21:40:40 INFO DStreamGraph: Updated checkpoint data for time 1538160040000 ms
18/09/28 21:40:40 INFO CheckpointWriter: Submitted checkpoint of time 1538160040000 ms to writer queue
18/09/28 21:40:40 INFO CheckpointWriter: Saving checkpoint for time 1538160040000 ms to file 'file:/C:/Users/serez/Desktop/bigdata-training-master-cb197815c41507f3ead62de529732ac73879a99a/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1538160040000'
18/09/28 21:40:40 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:63
18/09/28 21:40:40 INFO DAGScheduler: Registering RDD 20 (mapToPair at AnomalyDetector.java:58)
18/09/28 21:40:40 INFO DAGScheduler: Got job 2 (foreachPartition at AnomalyDetector.java:63) with 4 output partitions
18/09/28 21:40:40 INFO DAGScheduler: Final stage: ResultStage 14 (foreachPartition at AnomalyDetector.java:63)
18/09/28 21:40:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12, ShuffleMapStage 9, ShuffleMapStage 13, ShuffleMapStage 10, ShuffleMapStage 11)
18/09/28 21:40:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
18/09/28 21:40:40 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[20] at mapToPair at AnomalyDetector.java:58), which has no missing parents
18/09/28 21:40:40 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 5.3 KB, free 1509.0 MB)
18/09/28 21:40:40 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.1 KB, free 1509.0 MB)
18/09/28 21:40:40 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 3.1 KB, free: 1509.0 MB)
18/09/28 21:40:40 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1039
18/09/28 21:40:40 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[20] at mapToPair at AnomalyDetector.java:58) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
18/09/28 21:40:40 INFO TaskSchedulerImpl: Adding task set 13.0 with 10 tasks
18/09/28 21:40:40 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:40 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 29, localhost, executor driver, partition 1, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:40 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 30, localhost, executor driver, partition 2, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:40 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 31, localhost, executor driver, partition 3, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:40 INFO Executor: Running task 1.0 in stage 13.0 (TID 29)
18/09/28 21:40:40 INFO Executor: Running task 0.0 in stage 13.0 (TID 28)
18/09/28 21:40:40 INFO Executor: Running task 3.0 in stage 13.0 (TID 31)
18/09/28 21:40:40 INFO Executor: Running task 2.0 in stage 13.0 (TID 30)
18/09/28 21:40:40 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping monitoring20 4
18/09/28 21:40:40 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping monitoring20 6
18/09/28 21:40:40 INFO KafkaRDD: Beginning offset 1 is the same as ending offset skipping monitoring20 9
18/09/28 21:40:40 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping monitoring20 3
18/09/28 21:40:40 INFO MemoryStore: Block rdd_19_1 stored as bytes in memory (estimated size 4.0 B, free 1509.0 MB)
18/09/28 21:40:40 INFO BlockManagerInfo: Added rdd_19_1 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1509.0 MB)
18/09/28 21:40:40 INFO MemoryStore: Block rdd_19_0 stored as bytes in memory (estimated size 4.0 B, free 1509.0 MB)
18/09/28 21:40:40 INFO MemoryStore: Block rdd_19_3 stored as bytes in memory (estimated size 4.0 B, free 1509.0 MB)
18/09/28 21:40:40 INFO MemoryStore: Block rdd_19_2 stored as bytes in memory (estimated size 4.0 B, free 1509.0 MB)
18/09/28 21:40:40 INFO BlockManagerInfo: Added rdd_19_0 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1509.0 MB)
18/09/28 21:40:40 INFO BlockManagerInfo: Added rdd_19_3 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1509.0 MB)
18/09/28 21:40:40 INFO BlockManagerInfo: Added rdd_19_2 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1509.0 MB)
18/09/28 21:40:40 INFO Executor: Finished task 1.0 in stage 13.0 (TID 29). 697 bytes result sent to driver
18/09/28 21:40:40 INFO TaskSetManager: Starting task 4.0 in stage 13.0 (TID 32, localhost, executor driver, partition 4, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:40 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 29) in 11 ms on localhost (executor driver) (1/10)
18/09/28 21:40:40 INFO Executor: Running task 4.0 in stage 13.0 (TID 32)
18/09/28 21:40:40 INFO Executor: Finished task 2.0 in stage 13.0 (TID 30). 740 bytes result sent to driver
18/09/28 21:40:40 INFO TaskSetManager: Starting task 5.0 in stage 13.0 (TID 33, localhost, executor driver, partition 5, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:40 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 30) in 13 ms on localhost (executor driver) (2/10)
18/09/28 21:40:40 INFO Executor: Running task 5.0 in stage 13.0 (TID 33)
18/09/28 21:40:40 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping monitoring20 8
18/09/28 21:40:40 INFO MemoryStore: Block rdd_19_4 stored as bytes in memory (estimated size 4.0 B, free 1509.0 MB)
18/09/28 21:40:40 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping monitoring20 7
18/09/28 21:40:40 INFO BlockManagerInfo: Added rdd_19_4 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1509.0 MB)
18/09/28 21:40:40 INFO MemoryStore: Block rdd_19_5 stored as bytes in memory (estimated size 4.0 B, free 1509.0 MB)
18/09/28 21:40:40 INFO BlockManagerInfo: Added rdd_19_5 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1509.0 MB)
18/09/28 21:40:40 INFO Executor: Finished task 0.0 in stage 13.0 (TID 28). 697 bytes result sent to driver
18/09/28 21:40:40 INFO TaskSetManager: Starting task 6.0 in stage 13.0 (TID 34, localhost, executor driver, partition 6, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:40 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 28) in 22 ms on localhost (executor driver) (3/10)
18/09/28 21:40:40 INFO Executor: Running task 6.0 in stage 13.0 (TID 34)
18/09/28 21:40:40 INFO KafkaRDD: Beginning offset 25983 is the same as ending offset skipping monitoring20 0
18/09/28 21:40:40 INFO Executor: Finished task 3.0 in stage 13.0 (TID 31). 697 bytes result sent to driver
18/09/28 21:40:40 INFO MemoryStore: Block rdd_19_6 stored as bytes in memory (estimated size 4.0 B, free 1509.0 MB)
18/09/28 21:40:40 INFO BlockManagerInfo: Added rdd_19_6 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1509.0 MB)
18/09/28 21:40:40 INFO TaskSetManager: Starting task 7.0 in stage 13.0 (TID 35, localhost, executor driver, partition 7, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:40 INFO TaskSetManager: Finished task 3.0 in stage 13.0 (TID 31) in 28 ms on localhost (executor driver) (4/10)
18/09/28 21:40:40 INFO Executor: Running task 7.0 in stage 13.0 (TID 35)
18/09/28 21:40:40 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping monitoring20 2
18/09/28 21:40:40 INFO MemoryStore: Block rdd_19_7 stored as bytes in memory (estimated size 4.0 B, free 1509.0 MB)
18/09/28 21:40:40 INFO BlockManagerInfo: Added rdd_19_7 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1509.0 MB)
18/09/28 21:40:40 INFO Executor: Finished task 6.0 in stage 13.0 (TID 34). 783 bytes result sent to driver
18/09/28 21:40:40 INFO TaskSetManager: Starting task 8.0 in stage 13.0 (TID 36, localhost, executor driver, partition 8, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:40 INFO Executor: Running task 8.0 in stage 13.0 (TID 36)
18/09/28 21:40:40 INFO TaskSetManager: Finished task 6.0 in stage 13.0 (TID 34) in 14 ms on localhost (executor driver) (5/10)
18/09/28 21:40:40 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping monitoring20 1
18/09/28 21:40:40 INFO MemoryStore: Block rdd_19_8 stored as bytes in memory (estimated size 4.0 B, free 1509.0 MB)
18/09/28 21:40:40 INFO BlockManagerInfo: Added rdd_19_8 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1509.0 MB)
18/09/28 21:40:40 INFO Executor: Finished task 4.0 in stage 13.0 (TID 32). 697 bytes result sent to driver
18/09/28 21:40:40 INFO TaskSetManager: Starting task 9.0 in stage 13.0 (TID 37, localhost, executor driver, partition 9, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:40 INFO TaskSetManager: Finished task 4.0 in stage 13.0 (TID 32) in 31 ms on localhost (executor driver) (6/10)
18/09/28 21:40:40 INFO Executor: Running task 9.0 in stage 13.0 (TID 37)
18/09/28 21:40:40 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping monitoring20 5
18/09/28 21:40:40 INFO Executor: Finished task 5.0 in stage 13.0 (TID 33). 697 bytes result sent to driver
18/09/28 21:40:40 INFO MemoryStore: Block rdd_19_9 stored as bytes in memory (estimated size 4.0 B, free 1509.0 MB)
18/09/28 21:40:40 INFO BlockManagerInfo: Added rdd_19_9 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1509.0 MB)
18/09/28 21:40:40 INFO TaskSetManager: Finished task 5.0 in stage 13.0 (TID 33) in 37 ms on localhost (executor driver) (7/10)
18/09/28 21:40:40 INFO Executor: Finished task 7.0 in stage 13.0 (TID 35). 697 bytes result sent to driver
18/09/28 21:40:40 INFO TaskSetManager: Finished task 7.0 in stage 13.0 (TID 35) in 26 ms on localhost (executor driver) (8/10)
18/09/28 21:40:40 INFO Executor: Finished task 8.0 in stage 13.0 (TID 36). 740 bytes result sent to driver
18/09/28 21:40:40 INFO TaskSetManager: Finished task 8.0 in stage 13.0 (TID 36) in 23 ms on localhost (executor driver) (9/10)
18/09/28 21:40:40 INFO Executor: Finished task 9.0 in stage 13.0 (TID 37). 697 bytes result sent to driver
18/09/28 21:40:40 INFO TaskSetManager: Finished task 9.0 in stage 13.0 (TID 37) in 17 ms on localhost (executor driver) (10/10)
18/09/28 21:40:40 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
18/09/28 21:40:40 INFO DAGScheduler: ShuffleMapStage 13 (mapToPair at AnomalyDetector.java:58) finished in 0,066 s
18/09/28 21:40:40 INFO DAGScheduler: looking for newly runnable stages
18/09/28 21:40:40 INFO DAGScheduler: running: Set()
18/09/28 21:40:40 INFO DAGScheduler: waiting: Set(ResultStage 14)
18/09/28 21:40:40 INFO DAGScheduler: failed: Set()
18/09/28 21:40:40 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[23] at mapWithState at AnomalyDetector.java:61), which has no missing parents
18/09/28 21:40:40 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 6.5 KB, free 1509.0 MB)
18/09/28 21:40:40 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1509.0 MB)
18/09/28 21:40:40 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 3.3 KB, free: 1509.0 MB)
18/09/28 21:40:40 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1039
18/09/28 21:40:40 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 14 (MapPartitionsRDD[23] at mapWithState at AnomalyDetector.java:61) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/09/28 21:40:40 INFO TaskSchedulerImpl: Adding task set 14.0 with 4 tasks
18/09/28 21:40:40 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 7893 bytes)
18/09/28 21:40:40 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 39, localhost, executor driver, partition 1, PROCESS_LOCAL, 7893 bytes)
18/09/28 21:40:40 INFO TaskSetManager: Starting task 2.0 in stage 14.0 (TID 40, localhost, executor driver, partition 2, PROCESS_LOCAL, 7893 bytes)
18/09/28 21:40:40 INFO TaskSetManager: Starting task 3.0 in stage 14.0 (TID 41, localhost, executor driver, partition 3, PROCESS_LOCAL, 7893 bytes)
18/09/28 21:40:40 INFO Executor: Running task 0.0 in stage 14.0 (TID 38)
18/09/28 21:40:40 INFO Executor: Running task 1.0 in stage 14.0 (TID 39)
18/09/28 21:40:40 INFO BlockManager: Found block rdd_16_0 locally
18/09/28 21:40:40 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 10 blocks
18/09/28 21:40:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/09/28 21:40:40 INFO MemoryStore: Block rdd_22_0 stored as values in memory (estimated size 4.0 KB, free 1509.0 MB)
18/09/28 21:40:40 INFO Executor: Running task 2.0 in stage 14.0 (TID 40)
18/09/28 21:40:40 INFO Executor: Running task 3.0 in stage 14.0 (TID 41)
18/09/28 21:40:40 INFO BlockManagerInfo: Added rdd_22_0 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 KB, free: 1509.0 MB)
18/09/28 21:40:40 INFO BlockManager: Found block rdd_16_2 locally
18/09/28 21:40:40 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 10 blocks
18/09/28 21:40:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/09/28 21:40:40 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/09/28 21:40:40 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-9
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/09/28 21:40:40 INFO BlockManager: Found block rdd_16_3 locally
18/09/28 21:40:40 INFO BlockManager: Found block rdd_16_1 locally
18/09/28 21:40:40 INFO AppInfoParser: Kafka version : 0.10.0.1
18/09/28 21:40:40 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/09/28 21:40:40 INFO KafkaProducer: Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/09/28 21:40:40 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 10 blocks
18/09/28 21:40:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/09/28 21:40:40 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 10 blocks
18/09/28 21:40:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/09/28 21:40:40 INFO MemoryStore: Block rdd_22_1 stored as values in memory (estimated size 4.0 KB, free 1509.0 MB)
18/09/28 21:40:40 INFO MemoryStore: Block rdd_22_3 stored as values in memory (estimated size 4.0 KB, free 1509.0 MB)
18/09/28 21:40:40 INFO Executor: 1 block locks were not released by TID = 38:
[rdd_16_0]
18/09/28 21:40:40 INFO BlockManagerInfo: Added rdd_22_1 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 KB, free: 1509.0 MB)
18/09/28 21:40:40 INFO Executor: Finished task 0.0 in stage 14.0 (TID 38). 1052 bytes result sent to driver
18/09/28 21:40:40 INFO BlockManagerInfo: Added rdd_22_3 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 KB, free: 1509.0 MB)
18/09/28 21:40:40 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/09/28 21:40:40 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 38) in 53 ms on localhost (executor driver) (1/4)
18/09/28 21:40:40 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/09/28 21:40:40 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-10
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/09/28 21:40:40 INFO AppInfoParser: Kafka version : 0.10.0.1
18/09/28 21:40:40 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/09/28 21:40:40 INFO KafkaProducer: Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/09/28 21:40:40 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-11
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/09/28 21:40:40 INFO AppInfoParser: Kafka version : 0.10.0.1
18/09/28 21:40:40 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/09/28 21:40:40 INFO KafkaProducer: Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/09/28 21:40:40 INFO Executor: 1 block locks were not released by TID = 41:
[rdd_16_3]
18/09/28 21:40:40 INFO Executor: 1 block locks were not released by TID = 39:
[rdd_16_1]
18/09/28 21:40:40 INFO Executor: Finished task 3.0 in stage 14.0 (TID 41). 1009 bytes result sent to driver
18/09/28 21:40:40 INFO Executor: Finished task 1.0 in stage 14.0 (TID 39). 1052 bytes result sent to driver
18/09/28 21:40:40 INFO TaskSetManager: Finished task 3.0 in stage 14.0 (TID 41) in 63 ms on localhost (executor driver) (2/4)
18/09/28 21:40:40 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 39) in 64 ms on localhost (executor driver) (3/4)
18/09/28 21:40:40 INFO CheckpointWriter: Deleting file:/C:/Users/serez/Desktop/bigdata-training-master-cb197815c41507f3ead62de529732ac73879a99a/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1538159840000
18/09/28 21:40:40 INFO CheckpointWriter: Checkpoint for time 1538160040000 ms saved to file 'file:/C:/Users/serez/Desktop/bigdata-training-master-cb197815c41507f3ead62de529732ac73879a99a/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1538160040000', took 6271 bytes and 211 ms
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 85
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 55
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 68
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 88
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 95
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 65
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 77
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 84
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 94
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 74
18/09/28 21:40:40 INFO BlockManagerInfo: Removed broadcast_2_piece0 on DESKTOP-30M8NBP.mshome.net:61066 in memory (size: 3.1 KB, free: 1509.0 MB)
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 86
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 69
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 59
18/09/28 21:40:40 INFO BlockManagerInfo: Removed broadcast_3_piece0 on DESKTOP-30M8NBP.mshome.net:61066 in memory (size: 3.2 KB, free: 1509.0 MB)
18/09/28 21:40:40 INFO BlockManagerInfo: Removed broadcast_4_piece0 on DESKTOP-30M8NBP.mshome.net:61066 in memory (size: 3.1 KB, free: 1509.0 MB)
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 63
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 91
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 97
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 57
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 99
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 56
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 75
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 93
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 98
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 71
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 83
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 92
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 62
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 80
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 53
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 64
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 78
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 89
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 70
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 51
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 79
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 76
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 87
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 81
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 52
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 58
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 66
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 60
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 73
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 72
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 67
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 96
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 82
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 54
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 50
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 90
18/09/28 21:40:40 INFO ContextCleaner: Cleaned accumulator 61
18/09/28 21:40:40 INFO MemoryStore: Block rdd_22_2 stored as values in memory (estimated size 240.3 MB, free 1268.7 MB)
18/09/28 21:40:40 INFO BlockManagerInfo: Added rdd_22_2 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 240.3 MB, free: 1268.7 MB)
18/09/28 21:40:40 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/09/28 21:40:40 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-12
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/09/28 21:40:40 INFO AppInfoParser: Kafka version : 0.10.0.1
18/09/28 21:40:40 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/09/28 21:40:40 INFO KafkaProducer: Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/09/28 21:40:40 INFO Executor: 1 block locks were not released by TID = 40:
[rdd_16_2]
18/09/28 21:40:40 INFO Executor: Finished task 2.0 in stage 14.0 (TID 40). 1095 bytes result sent to driver
18/09/28 21:40:40 INFO TaskSetManager: Finished task 2.0 in stage 14.0 (TID 40) in 857 ms on localhost (executor driver) (4/4)
18/09/28 21:40:40 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
18/09/28 21:40:40 INFO DAGScheduler: ResultStage 14 (foreachPartition at AnomalyDetector.java:63) finished in 0,867 s
18/09/28 21:40:40 INFO DAGScheduler: Job 2 finished: foreachPartition at AnomalyDetector.java:63, took 0,943732 s
18/09/28 21:40:40 INFO JobScheduler: Finished job streaming job 1538160040000 ms.0 from job set of time 1538160040000 ms
18/09/28 21:40:40 INFO JobScheduler: Total delay: 0,985 s for time 1538160040000 ms (execution: 0,948 s)
18/09/28 21:40:40 INFO MapPartitionsRDD: Removing RDD 17 from persistence list
18/09/28 21:40:40 INFO BlockManager: Removing RDD 17
18/09/28 21:40:40 INFO JobGenerator: Checkpointing graph for time 1538160040000 ms
18/09/28 21:40:40 INFO DStreamGraph: Updating checkpoint data for time 1538160040000 ms
18/09/28 21:40:40 INFO DStreamGraph: Updated checkpoint data for time 1538160040000 ms
18/09/28 21:40:40 INFO CheckpointWriter: Submitted checkpoint of time 1538160040000 ms to writer queue
18/09/28 21:40:40 INFO CheckpointWriter: Saving checkpoint for time 1538160040000 ms to file 'file:/C:/Users/serez/Desktop/bigdata-training-master-cb197815c41507f3ead62de529732ac73879a99a/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1538160040000'
18/09/28 21:40:41 INFO CheckpointWriter: Deleting file:/C:/Users/serez/Desktop/bigdata-training-master-cb197815c41507f3ead62de529732ac73879a99a/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1538159850000
18/09/28 21:40:41 INFO CheckpointWriter: Checkpoint for time 1538160040000 ms saved to file 'file:/C:/Users/serez/Desktop/bigdata-training-master-cb197815c41507f3ead62de529732ac73879a99a/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1538160040000', took 6267 bytes and 82 ms
18/09/28 21:40:41 INFO DStreamGraph: Clearing checkpoint data for time 1538160040000 ms
18/09/28 21:40:41 INFO DStreamGraph: Cleared checkpoint data for time 1538160040000 ms
18/09/28 21:40:41 INFO ReceivedBlockTracker: Deleting batches: 
18/09/28 21:40:41 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/C:/Users/serez/Desktop/bigdata-training-master-cb197815c41507f3ead62de529732ac73879a99a/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1538159840000: 
18/09/28 21:40:41 INFO InputInfoTracker: remove old batch metadata: 
18/09/28 21:40:50 INFO JobScheduler: Added jobs for time 1538160050000 ms
18/09/28 21:40:50 INFO JobGenerator: Checkpointing graph for time 1538160050000 ms
18/09/28 21:40:50 INFO DStreamGraph: Updating checkpoint data for time 1538160050000 ms
18/09/28 21:40:50 INFO JobScheduler: Starting job streaming job 1538160050000 ms.0 from job set of time 1538160050000 ms
18/09/28 21:40:50 INFO DStreamGraph: Updated checkpoint data for time 1538160050000 ms
18/09/28 21:40:50 INFO CheckpointWriter: Submitted checkpoint of time 1538160050000 ms to writer queue
18/09/28 21:40:50 INFO CheckpointWriter: Saving checkpoint for time 1538160050000 ms to file 'file:/C:/Users/serez/Desktop/bigdata-training-master-cb197815c41507f3ead62de529732ac73879a99a/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1538160050000'
18/09/28 21:40:50 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:63
18/09/28 21:40:50 INFO DAGScheduler: Registering RDD 26 (mapToPair at AnomalyDetector.java:58)
18/09/28 21:40:50 INFO DAGScheduler: Got job 3 (foreachPartition at AnomalyDetector.java:63) with 4 output partitions
18/09/28 21:40:50 INFO DAGScheduler: Final stage: ResultStage 21 (foreachPartition at AnomalyDetector.java:63)
18/09/28 21:40:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15, ShuffleMapStage 19, ShuffleMapStage 16, ShuffleMapStage 20, ShuffleMapStage 17, ShuffleMapStage 18)
18/09/28 21:40:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 19)
18/09/28 21:40:50 INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[26] at mapToPair at AnomalyDetector.java:58), which has no missing parents
18/09/28 21:40:50 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 5.3 KB, free 1268.7 MB)
18/09/28 21:40:50 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.1 KB, free 1268.7 MB)
18/09/28 21:40:50 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 3.1 KB, free: 1268.7 MB)
18/09/28 21:40:50 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1039
18/09/28 21:40:50 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[26] at mapToPair at AnomalyDetector.java:58) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
18/09/28 21:40:50 INFO TaskSchedulerImpl: Adding task set 19.0 with 10 tasks
18/09/28 21:40:50 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 42, localhost, executor driver, partition 0, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:50 INFO TaskSetManager: Starting task 1.0 in stage 19.0 (TID 43, localhost, executor driver, partition 1, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:50 INFO TaskSetManager: Starting task 2.0 in stage 19.0 (TID 44, localhost, executor driver, partition 2, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:50 INFO TaskSetManager: Starting task 3.0 in stage 19.0 (TID 45, localhost, executor driver, partition 3, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:50 INFO Executor: Running task 0.0 in stage 19.0 (TID 42)
18/09/28 21:40:50 INFO Executor: Running task 1.0 in stage 19.0 (TID 43)
18/09/28 21:40:50 INFO Executor: Running task 3.0 in stage 19.0 (TID 45)
18/09/28 21:40:50 INFO Executor: Running task 2.0 in stage 19.0 (TID 44)
18/09/28 21:40:50 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping monitoring20 6
18/09/28 21:40:50 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping monitoring20 4
18/09/28 21:40:50 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping monitoring20 3
18/09/28 21:40:50 INFO KafkaRDD: Beginning offset 1 is the same as ending offset skipping monitoring20 9
18/09/28 21:40:50 INFO MemoryStore: Block rdd_25_1 stored as bytes in memory (estimated size 4.0 B, free 1268.7 MB)
18/09/28 21:40:50 INFO MemoryStore: Block rdd_25_2 stored as bytes in memory (estimated size 4.0 B, free 1268.7 MB)
18/09/28 21:40:50 INFO MemoryStore: Block rdd_25_3 stored as bytes in memory (estimated size 4.0 B, free 1268.7 MB)
18/09/28 21:40:50 INFO MemoryStore: Block rdd_25_0 stored as bytes in memory (estimated size 4.0 B, free 1268.7 MB)
18/09/28 21:40:50 INFO BlockManagerInfo: Added rdd_25_1 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1268.7 MB)
18/09/28 21:40:50 INFO BlockManagerInfo: Added rdd_25_2 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1268.7 MB)
18/09/28 21:40:50 INFO BlockManagerInfo: Added rdd_25_3 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1268.7 MB)
18/09/28 21:40:50 INFO BlockManagerInfo: Added rdd_25_0 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1268.7 MB)
18/09/28 21:40:50 INFO Executor: Finished task 1.0 in stage 19.0 (TID 43). 740 bytes result sent to driver
18/09/28 21:40:50 INFO TaskSetManager: Starting task 4.0 in stage 19.0 (TID 46, localhost, executor driver, partition 4, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:50 INFO TaskSetManager: Finished task 1.0 in stage 19.0 (TID 43) in 10 ms on localhost (executor driver) (1/10)
18/09/28 21:40:50 INFO Executor: Running task 4.0 in stage 19.0 (TID 46)
18/09/28 21:40:50 INFO Executor: Finished task 0.0 in stage 19.0 (TID 42). 697 bytes result sent to driver
18/09/28 21:40:50 INFO Executor: Finished task 3.0 in stage 19.0 (TID 45). 740 bytes result sent to driver
18/09/28 21:40:50 INFO TaskSetManager: Starting task 5.0 in stage 19.0 (TID 47, localhost, executor driver, partition 5, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:50 INFO Executor: Running task 5.0 in stage 19.0 (TID 47)
18/09/28 21:40:50 INFO TaskSetManager: Starting task 6.0 in stage 19.0 (TID 48, localhost, executor driver, partition 6, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:50 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 42) in 13 ms on localhost (executor driver) (2/10)
18/09/28 21:40:50 INFO Executor: Running task 6.0 in stage 19.0 (TID 48)
18/09/28 21:40:50 INFO TaskSetManager: Finished task 3.0 in stage 19.0 (TID 45) in 13 ms on localhost (executor driver) (3/10)
18/09/28 21:40:50 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping monitoring20 8
18/09/28 21:40:50 INFO MemoryStore: Block rdd_25_4 stored as bytes in memory (estimated size 4.0 B, free 1268.7 MB)
18/09/28 21:40:50 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping monitoring20 7
18/09/28 21:40:50 INFO KafkaRDD: Beginning offset 25983 is the same as ending offset skipping monitoring20 0
18/09/28 21:40:50 INFO BlockManagerInfo: Added rdd_25_4 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1268.7 MB)
18/09/28 21:40:50 INFO MemoryStore: Block rdd_25_5 stored as bytes in memory (estimated size 4.0 B, free 1268.7 MB)
18/09/28 21:40:50 INFO MemoryStore: Block rdd_25_6 stored as bytes in memory (estimated size 4.0 B, free 1268.7 MB)
18/09/28 21:40:50 INFO BlockManagerInfo: Added rdd_25_5 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1268.7 MB)
18/09/28 21:40:50 INFO BlockManagerInfo: Added rdd_25_6 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1268.7 MB)
18/09/28 21:40:50 INFO Executor: Finished task 2.0 in stage 19.0 (TID 44). 740 bytes result sent to driver
18/09/28 21:40:50 INFO TaskSetManager: Starting task 7.0 in stage 19.0 (TID 49, localhost, executor driver, partition 7, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:50 INFO Executor: Running task 7.0 in stage 19.0 (TID 49)
18/09/28 21:40:50 INFO TaskSetManager: Finished task 2.0 in stage 19.0 (TID 44) in 20 ms on localhost (executor driver) (4/10)
18/09/28 21:40:50 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping monitoring20 2
18/09/28 21:40:50 INFO Executor: Finished task 5.0 in stage 19.0 (TID 47). 740 bytes result sent to driver
18/09/28 21:40:50 INFO MemoryStore: Block rdd_25_7 stored as bytes in memory (estimated size 4.0 B, free 1268.7 MB)
18/09/28 21:40:50 INFO BlockManagerInfo: Added rdd_25_7 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1268.7 MB)
18/09/28 21:40:50 INFO TaskSetManager: Starting task 8.0 in stage 19.0 (TID 50, localhost, executor driver, partition 8, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:50 INFO TaskSetManager: Finished task 5.0 in stage 19.0 (TID 47) in 13 ms on localhost (executor driver) (5/10)
18/09/28 21:40:50 INFO Executor: Running task 8.0 in stage 19.0 (TID 50)
18/09/28 21:40:50 INFO Executor: Finished task 6.0 in stage 19.0 (TID 48). 740 bytes result sent to driver
18/09/28 21:40:50 INFO TaskSetManager: Starting task 9.0 in stage 19.0 (TID 51, localhost, executor driver, partition 9, PROCESS_LOCAL, 7727 bytes)
18/09/28 21:40:50 INFO TaskSetManager: Finished task 6.0 in stage 19.0 (TID 48) in 15 ms on localhost (executor driver) (6/10)
18/09/28 21:40:50 INFO Executor: Running task 9.0 in stage 19.0 (TID 51)
18/09/28 21:40:50 INFO Executor: Finished task 7.0 in stage 19.0 (TID 49). 740 bytes result sent to driver
18/09/28 21:40:50 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping monitoring20 1
18/09/28 21:40:50 INFO MemoryStore: Block rdd_25_8 stored as bytes in memory (estimated size 4.0 B, free 1268.7 MB)
18/09/28 21:40:50 INFO BlockManagerInfo: Added rdd_25_8 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1268.7 MB)
18/09/28 21:40:50 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping monitoring20 5
18/09/28 21:40:50 INFO TaskSetManager: Finished task 7.0 in stage 19.0 (TID 49) in 12 ms on localhost (executor driver) (7/10)
18/09/28 21:40:50 INFO MemoryStore: Block rdd_25_9 stored as bytes in memory (estimated size 4.0 B, free 1268.7 MB)
18/09/28 21:40:50 INFO BlockManagerInfo: Added rdd_25_9 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.0 B, free: 1268.7 MB)
18/09/28 21:40:50 INFO Executor: Finished task 4.0 in stage 19.0 (TID 46). 740 bytes result sent to driver
18/09/28 21:40:50 INFO TaskSetManager: Finished task 4.0 in stage 19.0 (TID 46) in 23 ms on localhost (executor driver) (8/10)
18/09/28 21:40:50 INFO Executor: Finished task 8.0 in stage 19.0 (TID 50). 697 bytes result sent to driver
18/09/28 21:40:50 INFO TaskSetManager: Finished task 8.0 in stage 19.0 (TID 50) in 13 ms on localhost (executor driver) (9/10)
18/09/28 21:40:50 INFO Executor: Finished task 9.0 in stage 19.0 (TID 51). 740 bytes result sent to driver
18/09/28 21:40:50 INFO TaskSetManager: Finished task 9.0 in stage 19.0 (TID 51) in 11 ms on localhost (executor driver) (10/10)
18/09/28 21:40:50 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
18/09/28 21:40:50 INFO DAGScheduler: ShuffleMapStage 19 (mapToPair at AnomalyDetector.java:58) finished in 0,045 s
18/09/28 21:40:50 INFO DAGScheduler: looking for newly runnable stages
18/09/28 21:40:50 INFO DAGScheduler: running: Set()
18/09/28 21:40:50 INFO DAGScheduler: waiting: Set(ResultStage 21)
18/09/28 21:40:50 INFO DAGScheduler: failed: Set()
18/09/28 21:40:50 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[29] at mapWithState at AnomalyDetector.java:61), which has no missing parents
18/09/28 21:40:50 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 6.8 KB, free 1268.7 MB)
18/09/28 21:40:50 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1268.7 MB)
18/09/28 21:40:50 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 3.3 KB, free: 1268.7 MB)
18/09/28 21:40:50 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1039
18/09/28 21:40:50 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 21 (MapPartitionsRDD[29] at mapWithState at AnomalyDetector.java:61) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/09/28 21:40:50 INFO TaskSchedulerImpl: Adding task set 21.0 with 4 tasks
18/09/28 21:40:50 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 52, localhost, executor driver, partition 0, PROCESS_LOCAL, 7918 bytes)
18/09/28 21:40:50 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 53, localhost, executor driver, partition 1, PROCESS_LOCAL, 7918 bytes)
18/09/28 21:40:50 INFO TaskSetManager: Starting task 2.0 in stage 21.0 (TID 54, localhost, executor driver, partition 2, PROCESS_LOCAL, 7918 bytes)
18/09/28 21:40:50 INFO TaskSetManager: Starting task 3.0 in stage 21.0 (TID 55, localhost, executor driver, partition 3, PROCESS_LOCAL, 7918 bytes)
18/09/28 21:40:50 INFO Executor: Running task 0.0 in stage 21.0 (TID 52)
18/09/28 21:40:50 INFO Executor: Running task 2.0 in stage 21.0 (TID 54)
18/09/28 21:40:50 INFO Executor: Running task 3.0 in stage 21.0 (TID 55)
18/09/28 21:40:50 INFO Executor: Running task 1.0 in stage 21.0 (TID 53)
18/09/28 21:40:50 INFO BlockManager: Found block rdd_22_2 locally
18/09/28 21:40:50 INFO BlockManager: Found block rdd_22_1 locally
18/09/28 21:40:50 INFO BlockManager: Found block rdd_22_0 locally
18/09/28 21:40:50 INFO BlockManager: Found block rdd_22_3 locally
18/09/28 21:40:50 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 10 blocks
18/09/28 21:40:50 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 10 blocks
18/09/28 21:40:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/09/28 21:40:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/09/28 21:40:50 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 10 blocks
18/09/28 21:40:50 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 10 blocks
18/09/28 21:40:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/09/28 21:40:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/09/28 21:40:50 INFO MemoryStore: Block rdd_28_3 stored as values in memory (estimated size 4.8 KB, free 1268.7 MB)
18/09/28 21:40:50 INFO MemoryStore: Block rdd_28_1 stored as values in memory (estimated size 4.8 KB, free 1268.7 MB)
18/09/28 21:40:50 INFO MemoryStore: Block rdd_28_0 stored as values in memory (estimated size 4.8 KB, free 1268.7 MB)
18/09/28 21:40:50 INFO BlockManagerInfo: Added rdd_28_3 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.8 KB, free: 1268.7 MB)
18/09/28 21:40:50 INFO BlockManagerInfo: Added rdd_28_1 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.8 KB, free: 1268.7 MB)
18/09/28 21:40:50 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/09/28 21:40:50 INFO BlockManagerInfo: Added rdd_28_0 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 4.8 KB, free: 1268.7 MB)
18/09/28 21:40:50 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/09/28 21:40:50 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/09/28 21:40:50 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-13
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/09/28 21:40:50 INFO AppInfoParser: Kafka version : 0.10.0.1
18/09/28 21:40:50 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/09/28 21:40:50 INFO KafkaProducer: Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/09/28 21:40:50 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-15
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/09/28 21:40:50 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-14
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/09/28 21:40:50 INFO Executor: 1 block locks were not released by TID = 55:
[rdd_22_3]
18/09/28 21:40:50 INFO AppInfoParser: Kafka version : 0.10.0.1
18/09/28 21:40:50 INFO AppInfoParser: Kafka version : 0.10.0.1
18/09/28 21:40:50 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/09/28 21:40:50 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/09/28 21:40:50 INFO KafkaProducer: Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/09/28 21:40:50 INFO KafkaProducer: Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/09/28 21:40:50 INFO Executor: Finished task 3.0 in stage 21.0 (TID 55). 1052 bytes result sent to driver
18/09/28 21:40:50 INFO TaskSetManager: Finished task 3.0 in stage 21.0 (TID 55) in 16 ms on localhost (executor driver) (1/4)
18/09/28 21:40:50 INFO Executor: 1 block locks were not released by TID = 53:
[rdd_22_1]
18/09/28 21:40:50 INFO Executor: 1 block locks were not released by TID = 52:
[rdd_22_0]
18/09/28 21:40:50 INFO Executor: Finished task 1.0 in stage 21.0 (TID 53). 1052 bytes result sent to driver
18/09/28 21:40:50 INFO Executor: Finished task 0.0 in stage 21.0 (TID 52). 1009 bytes result sent to driver
18/09/28 21:40:50 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 53) in 17 ms on localhost (executor driver) (2/4)
18/09/28 21:40:50 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 52) in 18 ms on localhost (executor driver) (3/4)
18/09/28 21:40:50 INFO CheckpointWriter: Deleting file:/C:/Users/serez/Desktop/bigdata-training-master-cb197815c41507f3ead62de529732ac73879a99a/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1538159860000
18/09/28 21:40:50 INFO CheckpointWriter: Checkpoint for time 1538160050000 ms saved to file 'file:/C:/Users/serez/Desktop/bigdata-training-master-cb197815c41507f3ead62de529732ac73879a99a/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1538160050000', took 6275 bytes and 129 ms
18/09/28 21:40:50 INFO MemoryStore: Block rdd_28_2 stored as values in memory (estimated size 240.3 MB, free 1028.4 MB)
18/09/28 21:40:50 INFO BlockManagerInfo: Added rdd_28_2 in memory on DESKTOP-30M8NBP.mshome.net:61066 (size: 240.3 MB, free: 1028.4 MB)
18/09/28 21:40:50 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/09/28 21:40:50 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-16
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/09/28 21:40:50 INFO AppInfoParser: Kafka version : 0.10.0.1
18/09/28 21:40:50 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/09/28 21:40:50 INFO KafkaProducer: Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/09/28 21:40:50 INFO Executor: 1 block locks were not released by TID = 54:
[rdd_22_2]
18/09/28 21:40:50 INFO Executor: Finished task 2.0 in stage 21.0 (TID 54). 1052 bytes result sent to driver
18/09/28 21:40:50 INFO TaskSetManager: Finished task 2.0 in stage 21.0 (TID 54) in 687 ms on localhost (executor driver) (4/4)
18/09/28 21:40:50 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
18/09/28 21:40:50 INFO DAGScheduler: ResultStage 21 (foreachPartition at AnomalyDetector.java:63) finished in 0,695 s
18/09/28 21:40:50 INFO DAGScheduler: Job 3 finished: foreachPartition at AnomalyDetector.java:63, took 0,752972 s
18/09/28 21:40:50 INFO JobScheduler: Finished job streaming job 1538160050000 ms.0 from job set of time 1538160050000 ms
18/09/28 21:40:50 INFO JobScheduler: Total delay: 0,796 s for time 1538160050000 ms (execution: 0,762 s)
18/09/28 21:40:50 INFO MapPartitionsRDD: Removing RDD 23 from persistence list
18/09/28 21:40:50 INFO BlockManager: Removing RDD 23
18/09/28 21:40:50 INFO JobGenerator: Checkpointing graph for time 1538160050000 ms
18/09/28 21:40:50 INFO DStreamGraph: Updating checkpoint data for time 1538160050000 ms
18/09/28 21:40:50 INFO DStreamGraph: Updated checkpoint data for time 1538160050000 ms
18/09/28 21:40:50 INFO CheckpointWriter: Submitted checkpoint of time 1538160050000 ms to writer queue
18/09/28 21:40:50 INFO CheckpointWriter: Saving checkpoint for time 1538160050000 ms to file 'file:/C:/Users/serez/Desktop/bigdata-training-master-cb197815c41507f3ead62de529732ac73879a99a/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1538160050000'
18/09/28 21:40:50 INFO CheckpointWriter: Deleting file:/C:/Users/serez/Desktop/bigdata-training-master-cb197815c41507f3ead62de529732ac73879a99a/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1538159870000
18/09/28 21:40:50 INFO CheckpointWriter: Checkpoint for time 1538160050000 ms saved to file 'file:/C:/Users/serez/Desktop/bigdata-training-master-cb197815c41507f3ead62de529732ac73879a99a/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1538160050000', took 6271 bytes and 86 ms
18/09/28 21:40:50 INFO DStreamGraph: Clearing checkpoint data for time 1538160050000 ms
18/09/28 21:40:50 INFO DStreamGraph: Cleared checkpoint data for time 1538160050000 ms
18/09/28 21:40:50 INFO ReceivedBlockTracker: Deleting batches: 
18/09/28 21:40:50 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 1 old log files in file:/C:/Users/serez/Desktop/bigdata-training-master-cb197815c41507f3ead62de529732ac73879a99a/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1538159850000: file:/C:/Users/serez/Desktop/bigdata-training-master-cb197815c41507f3ead62de529732ac73879a99a/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata/log-1538159780773-1538159840773
18/09/28 21:40:50 INFO InputInfoTracker: remove old batch metadata: 
18/09/28 21:40:50 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Cleared log files in file:/C:/Users/serez/Desktop/bigdata-training-master-cb197815c41507f3ead62de529732ac73879a99a/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1538159850000

Process finished with exit code -1
